<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Nic Freeman" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="MPS350/4111 Bayesian Statistics, Sheffield University, October 28, 2025." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>MPS350/4111 — Metropolis-Hastings</title>
<link rel="stylesheet" type="text/css" href="sans-serif-lwarp-sagebrush.css" />
<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
// \left, \right delimiters: https://github.com/mathjax/MathJax/issues/2535
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
  subequations: "0",
  section: "",
  loader: {
    load: ['[tex]/tagformat', '[tex]/textmacros'],
  },
  startup: {
    ready() {
      // These would be replaced by import commands if you wanted to make
      // a proper extension.
      const Configuration = MathJax._.input.tex.Configuration.Configuration;
      const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
      const Macro = MathJax._.input.tex.Symbol.Macro;
      const TexError = MathJax._.input.tex.TexError.default;
      const ParseUtil = MathJax._.input.tex.ParseUtil.default;
      const expandable = MathJax._.util.Options.expandable;

       // Insert the replacement string into the TeX string, and check
       // that there haven't been too many maxro substitutions (prevents
       // infinite loops).
       const useArgument = (parser, text) => {
         parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
         parser.i = 0;
         if (++parser.macroCount > parser.configuration.options.maxMacros) {
           throw new TexError('MaxMacroSub1',
           'MathJax maximum macro substitution count exceeded; ' +
           'is there a recursive macro call?');
         }
       }

       // Create the command map for:
       //     \ifstar, \ifnextchar, \ifblank, \ifstrequal, \gsub, \seteqnumber
       new CommandMap('Lwarp-macros', {
         ifstar: 'IfstarFunction',
         ifnextchar: 'IfnextcharFunction',
         ifblank: 'IfblankFunction',
         ifstrequal: 'IfstrequalFunction',
         gsubstitute: 'GsubstituteFunction',
         seteqnumber: 'SeteqnumberFunction'
       }, {
         // This function implements an ifstar macro.
         IfstarFunction(parser, name) {
            const resultstar = parser.GetArgument(name);
            const resultnostar = parser.GetArgument(name);
            const star = parser.GetStar();                 // true if there is a *
            useArgument(parser, star ? resultstar : resultnostar);
         },

         // This function implements an ifnextchar macro.
         IfnextcharFunction(parser, name) {
           let whichchar = parser.GetArgument(name);
           if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
             // $ syntax highlighting
             whichchar = String.fromCodePoint(parseInt(whichchar));
           }
           const resultnextchar = parser.GetArgument(name);
           const resultnotnextchar = parser.GetArgument(name);
           const gotchar = (parser.GetNext() === whichchar);
           useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
         },

         // This function implements an ifblank macro.
         IfblankFunction(parser, name) {
           const blankarg = parser.GetArgument(name);
           const resultblank = parser.GetArgument(name);
           const resultnotblank = parser.GetArgument(name);
           const isblank = (blankarg.trim() == "");
           useArgument(parser, isblank ? resultblank : resultnotblank);
         },

         // This function implements an ifstrequal macro.
         IfstrequalFunction(parser, name) {
           const strequalfirst = parser.GetArgument(name);
           const strequalsecond = parser.GetArgument(name);
           const resultequal = parser.GetArgument(name);
           const resultnotequal = parser.GetArgument(name);
           const isequal = (strequalfirst == strequalsecond);
           useArgument(parser, isequal ? resultequal : resultnotequal);
         },

         // This function implements a gsub macro.
         GsubstituteFunction(parser, name) {
           const gsubfirst = parser.GetArgument(name);
           const gsubsecond = parser.GetArgument(name);
           const gsubthird = parser.GetArgument(name);
           let gsubresult=gsubfirst.replace(gsubsecond, gsubthird);
           useArgument(parser, gsubresult);
         },

         // This function modifies the equation numbers.
         SeteqnumberFunction(parser, name) {
             // Get the macro parameters
             const star = parser.GetStar();                  // true if there is a *
             const optBrackets = parser.GetBrackets(name);   // contents of optional brackets
             const newsubequations = parser.GetArgument(name); // the subequations argument
             const neweqsection = parser.GetArgument(name); // the eq section argument
             const neweqnumber = parser.GetArgument(name);   // the eq number argument
             MathJax.config.subequations=newsubequations ;   // a string with boolean meaning
             MathJax.config.section=neweqsection ;           // a string with numeric meaning
             parser.tags.counter = parser.tags.allCounter = neweqnumber ;
         }

       });

       // Create the Lwarp-macros package
       Configuration.create('Lwarp-macros', {
         handler: {macro: ['Lwarp-macros']}
       });

       MathJax.startup.defaultReady();

       // For forward references:
       MathJax.startup.input[0].preFilters.add(({math}) => {
         if (math.inputData.recompile){
             MathJax.config.subequations = math.inputData.recompile.subequations;
             MathJax.config.section = math.inputData.recompile.section;
         }
       });
       MathJax.startup.input[0].postFilters.add(({math}) => {
         if (math.inputData.recompile){
             math.inputData.recompile.subequations = MathJax.config.subequations;
             math.inputData.recompile.section = MathJax.config.section;
         }
       });

         // For \left, \right with unicode-math:
         const {DelimiterMap} = MathJax._.input.tex.SymbolMap;
         const {Symbol} = MathJax._.input.tex.Symbol;
         const {MapHandler} = MathJax._.input.tex.MapHandler;
         const delimiter = MapHandler.getMap('delimiter');
         delimiter.add('\\lBrack', new Symbol('\\lBrack', '\u27E6'));
         delimiter.add('\\rBrack', new Symbol('\\rBrack', '\u27E7'));
         delimiter.add('\\lAngle', new Symbol('\\lAngle', '\u27EA'));
         delimiter.add('\\rAngle', new Symbol('\\rAngle', '\u27EB'));
         delimiter.add('\\lbrbrak', new Symbol('\\lbrbrak', '\u2772'));
         delimiter.add('\\rbrbrak', new Symbol('\\rbrbrak', '\u2773'));
         delimiter.add('\\lbag', new Symbol('\\lbag', '\u27C5'));
         delimiter.add('\\rbag', new Symbol('\\rbag', '\u27C6'));
         delimiter.add('\\llparenthesis', new Symbol('\\llparenthesis', '\u2987'));
         delimiter.add('\\rrparenthesis', new Symbol('\\rrparenthesis', '\u2988'));
         delimiter.add('\\llangle', new Symbol('\\llangle', '\u2989'));
         delimiter.add('\\rrangle', new Symbol('\\rrangle', '\u298A'));
         delimiter.add('\\Lbrbrak', new Symbol('\\Lbrbrak', '\u27EC'));
         delimiter.add('\\Rbrbrak', new Symbol('\\Rbrbrak', '\u27ED'));
         delimiter.add('\\lBrace', new Symbol('\\lBrace', '\u2983'));
         delimiter.add('\\rBrace', new Symbol('\\rBrace', '\u2984'));
         delimiter.add('\\lParen', new Symbol('\\lParen', '\u2985'));
         delimiter.add('\\rParen', new Symbol('\\rParen', '\u2986'));
         delimiter.add('\\lbrackubar', new Symbol('\\lbrackubar', '\u298B'));
         delimiter.add('\\rbrackubar', new Symbol('\\rbrackubar', '\u298C'));
         delimiter.add('\\lbrackultick', new Symbol('\\lbrackultick', '\u298D'));
         delimiter.add('\\rbracklrtick', new Symbol('\\rbracklrtick', '\u298E'));
         delimiter.add('\\lbracklltick', new Symbol('\\lbracklltick', '\u298F'));
         delimiter.add('\\rbrackurtick', new Symbol('\\rbrackurtick', '\u2990'));
         delimiter.add('\\langledot', new Symbol('\\langledot', '\u2991'));
         delimiter.add('\\rangledot', new Symbol('\\rangledot', '\u2992'));
         delimiter.add('\\lparenless', new Symbol('\\lparenless', '\u2993'));
         delimiter.add('\\rparengtr', new Symbol('\\rparengtr', '\u2994'));
         delimiter.add('\\Lparengtr', new Symbol('\\Lparengtr', '\u2995'));
         delimiter.add('\\Rparenless', new Symbol('\\Rparenless', '\u2996'));
         delimiter.add('\\lblkbrbrak', new Symbol('\\lblkbrbrak', '\u2997'));
         delimiter.add('\\rblkbrbrak', new Symbol('\\rblkbrbrak', '\u2998'));
         delimiter.add('\\lvzigzag', new Symbol('\\lvzigzag', '\u29D8'));
         delimiter.add('\\rvzigzag', new Symbol('\\rvzigzag', '\u29D9'));
         delimiter.add('\\Lvzigzag', new Symbol('\\Lvzigzag', '\u29DA'));
         delimiter.add('\\Rvzigzag', new Symbol('\\Rvzigzag', '\u29DB'));
         delimiter.add('\\lcurvyangle', new Symbol('\\lcurvyangle', '\u29FC'));
         delimiter.add('\\rcurvyangle', new Symbol('\\rcurvyangle', '\u29FD'));
         delimiter.add('\\Vvert', new Symbol('\\Vvert', '\u2980'));
   }     // ready
 },      // startup

 tex: {
   packages: {'[+]': ['tagformat', 'Lwarp-macros', 'textmacros']},
   tags: "ams",
        tagformat: {
            number: function (n) {
                if(MathJax.config.subequations==0)
                    return(MathJax.config.section + n);
                else
                    return(MathJax.config.section + String.fromCharCode(96+n));
            },
        },
 }
}
</script>

<script
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4222H8D03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4222H8D03');
</script>
<!-- Google tag (gtag.js) -->


</head>
<body>



<a id="notes-autopage-227"></a>
<nav class="topnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

<header>

<p>
last updated: October 28, 2025
</p>

</header>



<div class="bodyandsidetoc">
<div class="sidetoccontainer">



<nav class="sidetoc">



<div class="sidetoctitle">

<p>
<span class="sidetocthetitle">Bayesian Statistics</span>
</p>

<p>
Contents
</p>
</div>



<div class="sidetoccontents">

<p>
<a href="notes.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Introduction.html#autosec-5" class="tocchapter" >
<span class="sectionnumber">0</span>&#x2003;Introduction</a>
</p>



<p>
<a href="Introduction.html#autosec-6" class="tocsection" >
<span class="sectionnumber">0.1</span>&#x2003;Organization</a>
</p>



<p>
<a href="Outline-course.html#autosec-10" class="tocsection" >
<span class="sectionnumber">0.2</span>&#x2003;Outline of the course</a>
</p>



<p>
<a href="Conditioning.html#autosec-12" class="tocchapter" >
<span class="sectionnumber">1</span>&#x2003;Conditioning</a>
</p>



<p>
<a href="Conditioning.html#autosec-13" class="tocsection" >
<span class="sectionnumber">1.1</span>&#x2003;Random variables</a>
</p>



<p>
<a href="Equality-in-distribution.html#autosec-18" class="tocsection" >
<span class="sectionnumber">1.2</span>&#x2003;Equality in distribution</a>
</p>



<p>
<a href="Families-random-variables.html#autosec-28" class="tocsection" >
<span class="sectionnumber">1.3</span>&#x2003;Families of random variables</a>
</p>



<p>
<a href="Conditioning-on-location.html#autosec-32" class="tocsection" >
<span class="sectionnumber">1.4</span>&#x2003;Conditioning on location</a>
</p>



<p>
<a href="Conditioning-correlations.html#autosec-40" class="tocsection" >
<span class="sectionnumber">1.5</span>&#x2003;Conditioning and correlations</a>
</p>



<p>
<a href="Conditioning-on-events-with-zero-probability.html#autosec-47" class="tocsection" >
<span class="sectionnumber">1.6</span>&#x2003;Conditioning on events with zero probability</a>
</p>



<p>
<a href="Families-with-random-parameters.html#autosec-54" class="tocsection" >
<span class="sectionnumber">1.7</span>&#x2003;Families with random parameters</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conditioning.html#autosec-57" class="tocsection" >
<span class="sectionnumber">1.8</span>&#x2003;Exercises on Chapter 1</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-62" class="tocchapter" >
<span class="sectionnumber">2</span>&#x2003;Bayesian models: discrete data</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-63" class="tocsection" >
<span class="sectionnumber">2.1</span>&#x2003;Models with random parameters</a>
</p>



<p>
<a href="Discrete-Bayesian-models.html#autosec-67" class="tocsection" >
<span class="sectionnumber">2.2</span>&#x2003;Discrete Bayesian models</a>
</p>



<p>
<a href="The-posterior-distribution.html#autosec-72" class="tocsection" >
<span class="sectionnumber">2.3</span>&#x2003;The posterior distribution</a>
</p>



<p>
<a href="Bayesian-updates.html#autosec-80" class="tocsection" >
<span class="sectionnumber">2.4</span>&#x2003;Bayesian updates</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_discrete.html#autosec-85" class="tocsection" >
<span class="sectionnumber">2.5</span>&#x2003;Exercises on Chapter 2</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-88" class="tocchapter" >
<span class="sectionnumber">3</span>&#x2003;Bayesian models: continuous data</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-89" class="tocsection" >
<span class="sectionnumber">3.1</span>&#x2003;Continuous Bayesian models</a>
</p>



<p>
<a href="Notation-independent-data.html#autosec-95" class="tocsection" >
<span class="sectionnumber">3.2</span>&#x2003;Notation: independent data</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_continuous.html#autosec-105" class="tocsection" >
<span class="sectionnumber">3.3</span>&#x2003;Exercises on Chapter 3</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-108" class="tocchapter" >
<span class="sectionnumber">4</span>&#x2003;Conjugate priors</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-110" class="tocsection" >
<span class="sectionnumber">4.1</span>&#x2003;Notation: proportionality</a>
</p>



<p>
<a href="Two-more-examples-conjugate-pairs.html#autosec-120" class="tocsection" >
<span class="sectionnumber">4.2</span>&#x2003;Two more examples of conjugate pairs</a>
</p>



<p>
<a href="Conjugate-pairs-exponential-family.html#autosec-130" class="tocsection" >
<span class="sectionnumber">4.3</span>&#x2003;Conjugate pairs and the exponential family \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="What-if.html#autosec-135" class="tocsection" >
<span class="sectionnumber">4.4</span>&#x2003;What if?</a>
</p>



<p>
<a href="The-normal-distribution-with-unknown-mean-variance.html#autosec-148" class="tocsection" >
<span class="sectionnumber">4.5</span>&#x2003;The normal distribution with unknown mean and variance</a>
</p>



<p>
<a href="The-limitations-conjugate-pairs.html#autosec-156" class="tocsection" >
<span class="sectionnumber">4.6</span>&#x2003;The limitations of conjugate pairs</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conjugate_priors.html#autosec-158" class="tocsection" >
<span class="sectionnumber">4.7</span>&#x2003;Exercises on Chapter 4</a>
</p>



<p>
<a href="The-prior.html#autosec-161" class="tocchapter" >
<span class="sectionnumber">5</span>&#x2003;The prior</a>
</p>



<p>
<a href="The-prior.html#autosec-162" class="tocsection" >
<span class="sectionnumber">5.1</span>&#x2003;Elicitation</a>
</p>



<p>
<a href="Uninformative-priors.html#autosec-170" class="tocsection" >
<span class="sectionnumber">5.2</span>&#x2003;Uninformative priors</a>
</p>



<p>
<a href="Reference-priors.html#autosec-177" class="tocsection" >
<span class="sectionnumber">5.3</span>&#x2003;Reference priors</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-prior.html#autosec-183" class="tocsection" >
<span class="sectionnumber">5.4</span>&#x2003;Exercises on Chapter 5</a>
</p>



<p>
<a href="Bayesian-Notation.html#autosec-186" class="tocchapter" >
<span class="sectionnumber">6</span>&#x2003;Bayesian Notation</a>
</p>



<p>
<a href="Bayesian-Notation.html#autosec-190" class="tocsection" >
<span class="sectionnumber">6.1</span>&#x2003;Exercises on Chapter 6</a>
</p>



<p>
<a href="The-posterior.html#autosec-192" class="tocchapter" >
<span class="sectionnumber">7</span>&#x2003;The posterior</a>
</p>



<p>
<a href="The-posterior.html#autosec-193" class="tocsection" >
<span class="sectionnumber">7.1</span>&#x2003;Credible intervals</a>
</p>



<p>
<a href="The-connection-maximum-likelihood.html#autosec-204" class="tocsection" >
<span class="sectionnumber">7.2</span>&#x2003;The connection to maximum likelihood</a>
</p>



<p>
<a href="Hypothesis-testing-odds-ratios-Bayes-factors.html#autosec-210" class="tocsection" >
<span class="sectionnumber">7.3</span>&#x2003;Hypothesis testing, odds ratios and Bayes factors</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-posterior.html#autosec-220" class="tocsection" >
<span class="sectionnumber">7.4</span>&#x2003;Exercises on Chapter 7</a>
</p>



<p>
<a href="Computational-methods.html#autosec-223" class="tocchapter" >
<span class="sectionnumber">8</span>&#x2003;Computational methods</a>
</p>



<p>
<a href="Computational-methods.html#autosec-224" class="tocsection" >
<span class="sectionnumber">8.1</span>&#x2003;Approximate Bayesian computation \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="Metropolis-Hastings.html#autosec-227" class="tocsection" >
<span class="sectionnumber">8.2</span>&#x2003;Metropolis-Hastings</a>
</p>



<p>
<a href="Markov-Chain-Monte-Carlo.html#autosec-241" class="tocsection" >
<span class="sectionnumber">8.3</span>&#x2003;Markov Chain Monte Carlo</a>
</p>



<p>
<a href="Gibbs-sampling.html#autosec-246" class="tocsection" >
<span class="sectionnumber">8.4</span>&#x2003;Gibbs sampling</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-computational.html#autosec-253" class="tocsection" >
<span class="sectionnumber">8.5</span>&#x2003;Exercises on Chapter 8</a>
</p>



<p>
<a href="Reference-Sheets.html#autosec-256" class="tocchapter" >
<span class="sectionnumber">A</span>&#x2003;Reference Sheets</a>
</p>



<p>
<a href="Advice-revision-exams.html#autosec-264" class="tocchapter" >
<span class="sectionnumber">B</span>&#x2003;Advice for revision/exams</a>
</p>



<p>
<a href="Solutions-exercises.html#autosec-267" class="tocchapter" >
<span class="sectionnumber">C</span>&#x2003;Solutions to exercises</a>
</p>



</div>

</nav>

</div>



<main class="bodycontainer">



<section class="textbody">

<h1>Bayesian Statistics</h1>

<!--MathJax customizations:-->
<div data-nosnippet
      style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\require {colortbl}\)

\(\let \LWRorigcolumncolor \columncolor \)

\(\renewcommand {\columncolor }[2][named]{\LWRorigcolumncolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigrowcolor \rowcolor \)

\(\renewcommand {\rowcolor }[2][named]{\LWRorigrowcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigcellcolor \cellcolor \)

\(\renewcommand {\cellcolor }[2][named]{\LWRorigcellcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\require {mathtools}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vcentcolon }{\mathrel {\unicode {x2236}}}\)

\(\renewcommand {\intertext }[2][]{\text {#2}\notag \\}\)

\(\newenvironment {fleqn}[1][]{}{}\)

\(\newenvironment {ceqn}{}{}\)

\(\newenvironment {darray}[2][c]{\begin {array}[#1]{#2}}{\end {array}}\)

\(\newcommand {\dmulticolumn }[3]{#3}\)

\(\newcommand {\LWRnrnostar }[1][0.5ex]{\\[#1]}\)

\(\newcommand {\nr }{\ifstar \LWRnrnostar \LWRnrnostar }\)

\(\newcommand {\mrel }[1]{\begin {aligned}#1\end {aligned}}\)

\(\newcommand {\underrel }[2]{\underset {#2}{#1}}\)

\(\newcommand {\medmath }[1]{#1}\)

\(\newcommand {\medop }[1]{#1}\)

\(\newcommand {\medint }[1]{#1}\)

\(\newcommand {\medintcorr }[1]{#1}\)

\(\newcommand {\mfrac }[2]{\frac {#1}{#2}}\)

\(\newcommand {\mbinom }[2]{\binom {#1}{#2}}\)

\(\newenvironment {mmatrix}{\begin {matrix}}{\end {matrix}}\)

\(\newcommand {\displaybreak }[1][]{}\)

\( \def \offsyl {(\oslash )} \def \msconly {(\Delta )} \)

\( \DeclareMathOperator {\var }{var} \DeclareMathOperator {\cov }{cov} \DeclareMathOperator {\Bin }{Bin} \DeclareMathOperator {\Geo }{Geometric} \DeclareMathOperator {\Beta
}{Beta} \DeclareMathOperator {\Unif }{Uniform} \DeclareMathOperator {\Gam }{Gamma} \DeclareMathOperator {\Normal }{N} \DeclareMathOperator {\Exp }{Exp} \DeclareMathOperator
{\Cauchy }{Cauchy} \DeclareMathOperator {\Bern }{Bernoulli} \DeclareMathOperator {\Poisson }{Poisson} \DeclareMathOperator {\Weibull }{Weibull} \DeclareMathOperator {\IGam
}{IGamma} \DeclareMathOperator {\NGam }{NGamma} \DeclareMathOperator {\ChiSquared }{ChiSquared} \DeclareMathOperator {\Pareto }{Pareto} \DeclareMathOperator {\NBin }{NegBin}
\DeclareMathOperator {\Studentt }{Student-t} \DeclareMathOperator *{\argmax }{arg\,max} \DeclareMathOperator *{\argmin }{arg\,min} \)

\( \def \to {\rightarrow } \def \iff {\Leftrightarrow } \def \ra {\Rightarrow } \def \sw {\subseteq } \def \mc {\mathcal } \def \mb {\mathbb } \def \sc {\setminus } \def \wt
{\widetilde } \def \v {\textbf } \def \E {\mb {E}} \def \P {\mb {P}} \def \R {\mb {R}} \def \C {\mb {C}} \def \N {\mb {N}} \def \Q {\mb {Q}} \def \Z {\mb {Z}} \def \B {\mb {B}}
\def \~{\sim } \def \-{\,;\,} \def \qed {$\blacksquare $} \CustomizeMathJax {\def \1{\unicode {x1D7D9}}} \def \cadlag {c\&grave;{a}dl\&grave;{a}g} \def \p {\partial } \def \l
{\left } \def \r {\right } \def \Om {\Omega } \def \om {\omega } \def \eps {\epsilon } \def \de {\delta } \def \ov {\overline } \def \sr {\stackrel } \def \Lp {\mc {L}^p} \def
\Lq {\mc {L}^p} \def \Lone {\mc {L}^1} \def \Ltwo {\mc {L}^2} \def \toae {\sr {\rm a.e.}{\to }} \def \toas {\sr {\rm a.s.}{\to }} \def \top {\sr {\mb {\P }}{\to }} \def \tod {\sr
{\rm d}{\to }} \def \toLp {\sr {\Lp }{\to }} \def \toLq {\sr {\Lq }{\to }} \def \eqae {\sr {\rm a.e.}{=}} \def \eqas {\sr {\rm a.s.}{=}} \def \eqd {\sr {\rm d}{=}} \def \approxd
{\sr {\rm d}{\approx }} \def \Sa {(S1)\xspace } \def \Sb {(S2)\xspace } \def \Sc {(S3)\xspace } \)

</div>

<!--
...... section Metropolis-Hastings ......
-->
<h4 id="autosec-228"><span class="sectionnumber">8.2&#x2003;</span>Metropolis-Hastings</h4>
<a id="notes-autopage-228"></a>
<a id="notes-autofile-36"></a>

<a id="s:metropolis_hastings"></a>

<p>
In order to perform Bayesian inference computationally, the main requirement is that we can obtain samples from the posterior distribution \(\Theta |_{\{X=x\}}\). We know the p.d.f.&nbsp;from Theorem <a
href="Bayesian-updates.html#t:bayes_thm_discrete_data">2.4.1</a>/<a href="Bayesian-models-continuous-data.html#t:bayes_thm_continuous_data">3.1.2</a>, but this doesn’t allow us to take
samples quickly or easily. The most popular strategies for sampling are based on the Metropolis-Hastings algorithm. We will describe the algorithm in this section, and explain its application to Bayesian inference in
Section <a href="Markov-Chain-Monte-Carlo.html#s:mcmc">8.3</a>.
</p>
<!--
...... subsection The Metropolis-Hastings algorithm ......
-->
<h5 id="autosec-229"><span class="sectionnumber">8.2.1&#x2003;</span>The Metropolis-Hastings algorithm</h5>
<a id="notes-autopage-229"></a>



<a id="s:mh_general"></a>

<p>
The Metropolis-Hastings algorithm is a general technique for producing samples from a distribution. We will describe it in the case where we take samples of a continuous random variable \(Y\) with
p.d.f.&nbsp;\(f_Y\) and range \(R_Y\sw \R ^d\). The key ingredient of the algorithm is a joint distribution \((Y,Q)\), where \(Q|_{\{Y=y\}}\) is well defined for all \(y\in R_Y\), both with the same range as
\(Y\).
</p>
<div class="theorembodyexample">

<ul class="list" style="list-style-type:none">



<a id="autoid-166"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Example 8.2.1</span></span> <a id="autoid-167" ></a ><a id="ex:mh_ingredient_normal_walk"></a> A common choice is to take
\(Q=Y+\Normal (0,\sigma ^2)\) where \(\sigma &gt;0\) is a constant.
</p>


</li>

</ul>

</div>

<p>
The <em>Metropolis-Hastings algorithm</em> is the following. For now, it won’t be obvious why this algorithm generates samples of \(Y\), but we will address this point soon after. Let \(y_0\) be a point within
\(R_Y\). Then, given \(y_m\) we define \(y_{m+1}\) as follows.
</p>
<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> Generate a <em>proposal point</em> \(\tilde {y}\) from the distribution of \(Q|_{\{Y=y_m\}}\).
</p>


</li>
<li>


<p>
<span class="listmarker">2.</span> Calculate the value of
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{0}\)</span>
<!--
                                                           (                         )
                                                           fQ|{Y =ỹ} (ym )fY (ỹ)
                                               α = min 1,                                                                        (8.1)                                         --><a id="eq:mh_alpha"></a><!--
                                                          fQ|{Y =ym } (ỹ)fY (ym )
-->
<p>


\begin{equation}
\label {eq:mh_alpha} \alpha =\min \l \{1,\,\frac {f_{Q|_{\{Y=\tilde {y}\}}}(y_m)f_Y(\tilde {y})}{f_{Q|_{\{Y=y_m\}}}(\tilde {y})f_Y(y_m)}\r \}
\end{equation}


</p>
</li>
<li>


<p>
<span class="listmarker">3.</span> Then, set
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{1}\)</span>
<!--
                                                     
                                                     ỹ       with probability α,
                                                     
                                            ym+1 =                                                                              (8.2)                                        --><a id="eq:mh_update"></a><!--
                                                     ym       with probability 1 − α.
                                                     

-->
<p>


\begin{equation}
\label {eq:mh_update} y_{m+1}=\begin{cases} \tilde {y} &amp; \text { with probability }\alpha , \\ y_m &amp; \text { with probability }1-\alpha . \end {cases}
\end{equation}


</p>
<p>


</p>
</li>
</ul>

<p>
The distribution \(Q|_{\{Y=y\}}\) is called the <em>proposal</em> distribution, based on its role in steps 1 and 2. The two cases in step 3 are usually referred to as <em>acceptance</em> (when \(y_{m+1}=\tilde
{y}\)) and <em>rejection</em> (when \(y_{m+1}=y_m\)). The key point is that the algorithm only needs samples from the proposal distribution; we can run it without needing to sample of the distribution of \(Y\)
directly! The Metropolis-Hastings algorithm is useful in cases where the distribution of \(Y\) is unknown or is too complicated to efficiently sample from.
</p>
<div class="theorembodytheorem">

<ul class="list" style="list-style-type:none">



<a id="autoid-168"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Theorem 8.2.2</span></span> <a id="autoid-169" ></a ><a id="t:mh_convergence"></a> Let \((y_m)\) be the random sequence
obtained from the Metropolis-Hastings algorithm. Then for all \(A\sw R_Y\) we have \(\P [y_m\in A]\to \P [Y\in A]\) as \(m\to \infty \).
</p>


</li>

</ul>

</div>

<p>
Theorem <a href="Metropolis-Hastings.html#t:mh_convergence">8.2.2</a> says that if we run the MH algorithm for a long time, so that \(m\) becomes large, the random value of \(y_m\) will have a similar
distribution to \(Y\). We won’t be able to prove Theorem <a href="Metropolis-Hastings.html#t:mh_convergence">8.2.2</a> in this course but we will give a detailed idea of why it is true in Section <a
href="Metropolis-Hastings.html#s:mh_heuristics">8.2.3</a> (which is off-syllabus). As you might expect, this will involve the precise form of <span class="textup">(<a
href="Metropolis-Hastings.html#eq:mh_alpha">8.1</a>)</span>.
</p>

<p>
From Lemma <a href="Conditioning-on-events-with-zero-probability.html#l:rv_from_conditioning_abs_cts">1.6.1</a> we can rewrite equation <span class="textup">(<a
href="Metropolis-Hastings.html#eq:mh_alpha">8.1</a>)</span> as \(\alpha =\min \l (1,\frac {f_{Y,Q}(\tilde {y},y_m)}{f_{Y,Q}(y_m,\tilde {y})}\r )\). This is a nicer formula, but the
convention that you will find in all textbooks is to write the form <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_alpha">8.1</a>)</span>. The reason for this will become clear in Section
<a href="Metropolis-Hastings.html#s:mh_symmetric">8.2.2</a>.
</p>
<div class="theorembodyexample">

<ul class="list" style="list-style-type:none">



<a id="autoid-170"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Example 8.2.3</span></span> <a id="autoid-171" ></a ><a id="ex:mh"></a> Here’s some examples of the random sequence \((y_m)\)
generated by the MH algorithm, in the case \(Y\sim \Cauchy (0,1)\) with \(Q=Y+\Normal (0,1)\) as in Example <a href="Metropolis-Hastings.html#ex:mh_ingredient_normal_walk">8.2.1</a>.
</p>
<div class="center">

<p>


<a href="mh_samples.png" target="_blank" ><img
      src="mh_samples.png"
      style="
      width:390pt;
      "
      class="inlineimage"
      alt="(image)"
></a>
</p>
</div>

<p>
We’ve shown five sample runs of \((y_m)_{m=1}^{100}\), starting from zero in each case. You can see that sometimes for a few steps of time passes whilst a path does not move – that is when the proposal \(\wt
{y}\) is rejected a few times in a row. When the paths do move, each movement is an (independent) \(\Normal (0,1)\) random variable.
</p>

<p>
Next we run the MH algorithm \(500\) times, and in each case we record the value of \(y_{100}\). Theorem <a href="Metropolis-Hastings.html#t:mh_convergence">8.2.2</a> tells us that each \(y_{100}\)
should be approximately a sample of \(\Cauchy (0,1)\), so by taking \(500\) samples we should be able to see the shape of the distribution. We plot these values as a histogram and compare to the p.d.f.&nbsp;of
\(\Cauchy (0,1)\), giving
</p>
<div class="center">

<p>


<a href="mh_hist_short.png" target="_blank" ><img
      src="mh_hist_short.png"
      style="
      width:390pt;
      "
      class="inlineimage"
      alt="(image)"
></a>
</p>
</div>

<p>
We can see that the histogram is a reasonable match for \(f_{\Cauchy (0,1)}\), so the MH algorithm is behaving as Theorem <a href="Metropolis-Hastings.html#t:mh_convergence">8.2.2</a> predicts. If
we let the MH algorithm have more steps, so that we consider \(y_{1000}\) instead of \(y_{100}\), then we obtain a better approximation:
</p>
<div class="center">

<p>


<a href="mh_hist_long.png" target="_blank" ><img
      src="mh_hist_long.png"
      style="
      width:390pt;
      "
      class="inlineimage"
      alt="(image)"
></a>
</p>
</div>

<p>
Of course, we could also obtain a better approximation to the distribution of \(Y\sim \Cauchy (0,1)\) by taking more samples. The code that generated the plots above is given to you in Exercise <a
href="Exercises-on-Chapter-ref-c-computational.html#ps:mh_modifications"><b>8.1</b></a>, and used in other exercises at the end of this chapter.
</p>


</li>

</ul>

</div>

<p>
In statistics you will often hear the terminology ‘\(y_m\) has converged’ used to mean that \(m\) is large enough that \(y_m\) has approximately the same distribution as \(Y\). This is a misuse of terminology, but
it is common and quite helpful in practice. The period before is sometimes known as ‘burn in’.
</p>
<!--
...... subsection The Metropolis algorithm ......
-->
<h5 id="autosec-236"><span class="sectionnumber">8.2.2&#x2003;</span>The Metropolis algorithm</h5>
<a id="notes-autopage-236"></a>



<a id="s:mh_symmetric"></a>

<p>
A common technique when using the MH algorithm is to choose \(Q\) in such a way that
</p>

<span class="hidden"> \(\seteqnumber{0}{8.}{2}\)</span>

<!--

                                                 fQ|{Y =y} (ỹ) = fY |{Q=ỹ} (y)                                              (8.3)                                 --><a id="eq:mh_sym_YQ"></a><!--

-->

<p>


\begin{equation}
\label {eq:mh_sym_YQ} f_{Q|_{\{Y=y\}}}(\tilde {y})=f_{Y|_{\{Q=\tilde {y}\}}}(y)
\end{equation}


</p>

<p>
for all \(y\) and \(\tilde {y}\). The point of doing so is that it greatly simplifies the formula <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_alpha">8.1</a>)</span> for \(\alpha \),
because the terms on top and bottom involving conditional densities then cancel. The algorithm for updating \(y_m\) then becomes:
</p>
<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> Generate a <em>candidate point</em> \(\tilde {y}\) from the distribution of \(Q|_{\{Y=y_m\}}\).
</p>


</li>
<li>


<p>
<span class="listmarker">2.</span> Calculate the value of
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{3}\)</span>
<!--
                                                                                                d                d
                                                                                       Q|{Y =y} = y + N(0, σ 2 ) = N(y, σ 2 ),



-->



<p>


\begin{align*}
Q|_{\{Y=y\}}&amp;\eqd y+\Normal (0,\sigma ^2)\eqd \Normal (y,\sigma ^2),
\end{align*}
Hence
</p>

<p>
\[f_{Q|_{\{Y=y\}}}(\tilde {y})=\frac {1}{\sqrt {2\pi \sigma ^2}}e^{-\frac {(y-\tilde {y})^2}{2\sigma ^2}}=f_{Q|_{\{Y=\tilde {y}\}}}(y).\]
</p>

<p>
More generally, if \(Y\) has range \(\R ^d\) then <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_sym_YQ">8.3</a>)</span> will hold whenever \(Q=Y+Z\) where \(Z\) is a continuous
random variable with a distribution that is symmetric about zero i.e.&nbsp;\(f_Z(z)=f_Z(-z)\). Proving this fact is Exercise <a
href="Exercises-on-Chapter-ref-c-computational.html#ps:mh_sym_rws"><b>8.6</b></a>.
</p>

<p>
This case is known as the <em>random-walk Metropolis</em> algorithm.
</p>


</li>

</ul>

</div>
<!--
...... subsection Why does Metropolis-Hastings work?                      ......
-->
<h5 id="autosec-238"><span class="sectionnumber">8.2.3&#x2003;</span>Why does Metropolis-Hastings work? \(\offsyl \)</h5>
<a id="notes-autopage-238"></a>



<a id="s:mh_heuristics"></a>

<p>
In order to explain why the MH algorithm for \((Y,Q)\) generates samples of \(Y\), we will need some of the terminology that has been introduced in earlier courses on Markov chains. These courses are
recommended pre-requisites to this course, but they are not compulsory pre-requisites, so this section is off-syllabus. We will sketch out parts of it in lectures, if there is time.
</p>

<p>
The sequence \((y_m)\) defined by the MH algorithm in Section <a href="Metropolis-Hastings.html#s:mh_general">8.2.1</a> is an example of a Markov chain with state space \(R=R_Y\), the range of \(Y\).
In earlier courses you have studied Markov chains with discrete (i.e.&nbsp;finite or countable) state spaces, but in this case the state space is uncountable, because \(Y\) is a continuous random variable. Processes of
this type are known as Markov chains in <em>continuous space</em>.
</p>

<p>
The key ingredients of a Markov chain with a finite or countable state space are its transition probabilities, which record the probabilities of moving between various states. In continuous space the equivalent
concept is the function
</p>

<span class="hidden"> \(\seteqnumber{0}{8.}{4}\)</span>

<!--

                                                                                                                                           (8.5)                              --><a id="eq:transition_function"></a><!--
                                                                            
                                                p(x, A) = P Xm+1 |{Xm =x} ∈ A ,

-->

<p>


\begin{equation}
\label {eq:transition_function} p(x,A)=\P \l [X_{m+1}|_{\{X_m=x\}}\in A\r ],
\end{equation}


</p>

<p>
which is known as a <em>transition function</em> for the Markov chain \((X_m)\). It gives the probability of moving to a state within \(A\), from state \(x\), where \(A\sw R\) and \(R\) is the state space of the
chain. You will sometimes see the right hand side of this equation written as \(\P [X_{m+1}\in A|X_m=x]\), with the same meaning.
</p>

<p>
We say that a continuous random variable \(X\) with p.d.f.&nbsp;\(f_X(x)\) is a <em>stationary distribution</em> for the chain \((X_m)\) if when \(X_m\eqd X\) we have also that \(X_{m+1}\eqd X\). In
symbols, this requirement means that \(\P [X\in A]=\P [X_{m+1}|_{\{X_m=X\}}\in A]\), or equivalently
</p>

<span class="hidden"> \(\seteqnumber{0}{8.}{5}\)</span>

<!--
                                                            Z
                                            P[X ∈ A] =              p(x, A)fX (x) dx                                             (8.6)                                   --><a id="eq:stationary_dist_cts_space"></a><!--
                                                                R

-->

<p>


\begin{equation}
\label {eq:stationary_dist_cts_space} \P [X\in A]= \int _{R}p(x,A)f_X(x)\,dx
\end{equation}


</p>

<p>
for all \(A\sw R\). The expression on the right hand side here comes from <span class="textup">(<a href="Metropolis-Hastings.html#eq:transition_function">8.5</a>)</span>, using that \(\P
[X_{m+1}|_{\{X_m=X\}}\in A]=\E [p(X,A)]\).
</p>

<p>
The definitions of periodicity, irreducibility and the various types of recurrence can be upgraded into continuous space in a natural way. Moreover, there is a convergence theorem for Markov chains in discrete space,
which gives conditions (similar to those for discrete space) for the chain to converge to a unique stationary distribution, as time becomes large. We will not cover these ideas here, but note that our condition in
Section <a href="Metropolis-Hastings.html#s:mh_general">8.2.1</a> that \(Q|_{\{Y=y\}}\) is a continuous random variable with range \(R_Y\) means that the sequence \((y_m)\) might jump to anywhere
within \(R_Y\) on any step of time. Under that condition the convergence theorem applies and it is known that the chain \((y_m)\) will converge to a unique stationary distribution. The stationary distribution will
be a continuous random variable and will satisfy <span class="textup">(<a href="Metropolis-Hastings.html#eq:stationary_dist_cts_space">8.6</a>)</span>.
</p>

<p>
We will show here that the transition function given by the MH algorithm satisfies <span class="textup">(<a href="Metropolis-Hastings.html#eq:stationary_dist_cts_space">8.6</a>)</span> with
stationary distribution \(Y\). When this fact is combined with the convergence theorem for continuous space Markov chains, it leads to Theorem <a
href="Metropolis-Hastings.html#t:mh_convergence">8.2.2</a> – but we will only cover the calculation of the stationary distribution here. The transition function given by the MH algorithm is
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{6}\)</span>



<!--

                                                                     p(x, A) = P Bernoulli(αx,Q|{Y =x} ) = 1 and Q|{Y =x} ∈ A + 1{x∈A} P Bernoulli(αx,Q|{Y =x} ) = 0
                                                                                                                                                                  

                                                                             = E Bernoulli(αx,Q|{Y =x} )1{Q|{Y =x} ∈A} + 1{x∈A} E 1 − Bernoulli(αx,Q|{Y =x} )
                                                                                                                                                           
                                                                               Z                                 Z
                                                                      (8.7) =      αx,y fQ|{Y =x} (y) dy + 1{x∈A} (1 − αx,y )fQ|{Y =x} (y) dy                              --><a id="eq:mh_transition_function"></a><!--
                                                                                A                               R




-->



<p>


\begin{align}
p(x,A) &amp;=\P \l [\Bern (\alpha _{x,Q|_{\{Y=x\}}})=1\text { and }Q|_{\{Y=x\}}\in A\r ] +\1_{\{x\in A\}}\P \l [\Bern (\alpha _{x,Q|_{\{Y=x\}}})=0\r ] \notag \\ &amp;=\E \l
[\Bern (\alpha _{x,Q|_{\{Y=x\}}})\1_{\{Q|_{\{Y=x\}}\in A\}}\r ]+\1_{\{x\in A\}}\E \l [1-\Bern (\alpha _{x,Q|_{\{Y=x\}}})\r ] \notag \\ &amp;=\int _A \alpha
_{x,y}f_{Q|_{\{Y=x\}}}(y)\,dy+\1_{\{x\in A\}}\int _R(1-\alpha _{x,y})f_{Q|_{\{Y=x\}}}(y)\,dy \label {eq:mh_transition_function}
\end{align}
where
</p>

<span class="hidden"> \(\seteqnumber{0}{8.}{7}\)</span>

<!--
                                                        !
                                  fQ|{Y =y} (x)fY (y)
                    αx,y = min 1,                                                   (8.8)                                                                                             --><a id="eq:mh_alpha_xy"></a><!--
                                  fQ|{Y =x} (y)fY (x)

-->

<p>


\begin{equation}
\label {eq:mh_alpha_xy} \alpha _{x,y}=\min \l (1,\frac {f_{Q|_{\{Y=y\}}}(x)f_Y(y)}{f_{Q|_{\{Y=x\}}}(y)f_Y(x)}\r )
\end{equation}


</p>

<p>
is such that \(\alpha _{y_m,\tilde {y}}\) is precisely <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_alpha">8.1</a>)</span>. The MH algorithm will have stationary distribution
\(Y\) if and only if for all \(A\sw R\),
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{8}\)</span>



<!--
                                                                                                                    Z
                                                                                                     P[Y ∈ A] =         p(x, A)fY (x) dy               (8.9)                      --><a id="eq:mh_Y_stationary"></a><!--
                                                                                                                    R




-->



<p>


\begin{align}
\P [Y\in A] &amp;=\int _R p(x,A)f_Y(x)\,dy \label {eq:mh_Y_stationary}
\end{align}
The rest of the argument will concentrate on proving that <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_transition_function">8.7</a>)</span> and <span class="textup">(<a
href="Metropolis-Hastings.html#eq:mh_alpha_xy">8.8</a>)</span> imply that <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_Y_stationary">8.9</a>)</span> holds.
</p>

<p>
The choice of \(\alpha \) in <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_alpha_xy">8.8</a>)</span> is key. Our next goal is to show that
</p>

<span class="hidden"> \(\seteqnumber{0}{8.}{9}\)</span>

<!--

                                           αx,y fQ|{Y =x} (y)fY (x) = αy,x fQ|{Y =y} (x)fY (y),                                               (8.10)                          --><a id="eq:mh_detailed_balance"></a><!--

-->

<p>


\begin{equation}
\label {eq:mh_detailed_balance} \alpha _{x,y}f_{Q|_{\{Y=x\}}}(y)f_Y(x)=\alpha _{y,x}f_{Q|_{\{Y=y\}}}(x)f_Y(y),
\end{equation}


</p>

<p>
which by Lemma <a href="Conditioning-on-events-with-zero-probability.html#l:rv_from_conditioning_abs_cts">1.6.1</a> is equivalent to
</p>

<span class="hidden"> \(\seteqnumber{0}{8.}{10}\)</span>

<!--

                                                 αx,y fY,Q (x, y) = αy,x fY,Q (y, x).                                                      (8.11)                           --><a id="eq:mh_detailed_balance_2"></a><!--

-->

<p>


\begin{equation}
\label {eq:mh_detailed_balance_2} \alpha _{x,y}f_{Y,Q}(x,y)=\alpha _{y,x}f_{Y,Q}(y,x).
\end{equation}


</p>

<p>
Using <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_alpha_xy">8.8</a>)</span>, this equation can be checked by considering two cases:
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">•</span> if \(f_{Y,Q}(x,y)\leq f_{Y,Q}(y,x)\) then \(\alpha _{x,y}=1\) and \(\alpha _{y,x}=\frac {f_{Y,Q}(y,x)}{f_{Y,Q}(x,y)}\);
</p>


</li>
<li>


<p>
<span class="listmarker">•</span> if \(f_{Y,Q}(x,y)\geq f_{Y,Q}(y,x)\) then \(\alpha _{x,y}=\frac {f_{Y,Q}(x,y)}{f_{Y,Q}(y,x)}\) and \(\alpha _{y,x}=1\).
</p>
</li>
</ul>

<p>
In both cases, <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_detailed_balance_2">8.11</a>)</span> holds.
</p>
<div class="theorembodyremark">

<ul class="list" style="list-style-type:none">



<a id="autoid-174"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Remark 8.2.5</span></span> <a id="autoid-175" ></a >Recall the heuristic interpretation of probability density functions: \(f_P(p)\)
represents how likely \(P\) is to be close to \(p\). From the MH algorithm, this means that the left hand side of <span class="textup">(<a
href="Metropolis-Hastings.html#eq:mh_detailed_balance">8.10</a>)</span> represents the likelihood of \(y_{m+1}\approx x\) given that \(y_m\approx y\), where \(y\) is sampled from \(Y\), The right
hand side of <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_detailed_balance">8.10</a>)</span> represents the same concept but <em>with time run in reverse</em>, that is the
likelihood of \(y_{m+1}\approx y\) given that \(y_m\approx x\), where \(x\) is sampled from \(Y\). The choice of \(\alpha _{x,y}\) in <span class="textup">(<a
href="Metropolis-Hastings.html#eq:mh_alpha_xy">8.8</a>)</span> ensures that these quantities are equal.
</p>

<p>
Equation <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_detailed_balance">8.10</a>)</span> is closely related to <em>detailed balance</em> equations, which you have seen in earlier
courses for discrete space chains. Loosely, <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_detailed_balance">8.10</a>)</span> gives detailed balance equations for the chain conditional
on the event that a proposal is accepted. The quantity \(\alpha _{x,y}\) controls how likely a proposal for the jump \(x\mapsto y\) is to be accepted, or equivalently how likely the chain is to stand still rather
than move to \(y\). Because \(\alpha _{x,y}\) depends on \(y\), this also controls how likely <em>all</em> of the various possible moves are, which in turn controls the stationary distribution.
</p>


</li>

</ul>

</div>

<p>
We will now show that <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_Y_stationary">8.9</a>)</span> holds. We have
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{11}\)</span>



<!--
                                                          Z                         Z Z                                   Z Z
                                                               p(x, A)fY (x) dy =       αx,y fQ|{Y =x} (y)fY (x) dy dx +        1{x∈A} (1 − αx,y )fQ|{Y =x} fY (x) dy dx
                                                           R                        ZR ZA                         Z Z      R  R

                                                                               =        αx,y fY,Q (x, y) dy dx +        (1 − αx,y )fY,Q (x, y) dy dx
                                                                                  R
                                                                                 Z Z  A                            A
                                                                                                                  Z Z R                      Z Z
                                                                               =        αy,x fY,Q (y, x) dy dx +        fY,Q (x, y) dy dx −          αx,y fY,Q (x, y) dy dx
                                                                                 ZR Z A                            A R                 Z Z A R
                                                                               =        αy,x fY,Q (y, x) dx dy + P[Y ∈ A, Q ∈ R] −             αx,y fY,Q (x, y) dy dx
                                                                                     A   R                                               A   R

                                                                               = P[Y ∈ A]



-->



<p>


\begin{align*}
\int _R p(x,A)f_Y(x)\,dy &amp;=\int _R\int _A \alpha _{x,y}f_{Q|_{\{Y=x\}}}(y)f_Y(x)\,dy\,dx + \int _R\int _R\1_{\{x\in A\}}(1-\alpha _{x,y})f_{Q|_{\{Y=x\}}}f_Y(x)\,dy\,dx \\
&amp;=\int _R\int _A \alpha _{x,y}f_{Y,Q}(x,y)\,dy\,dx + \int _A\int _R(1-\alpha _{x,y})f_{Y,Q}(x,y)\,dy\,dx \\ &amp;=\int _R\int _A \alpha _{y,x}f_{Y,Q}(y,x)\,dy\,dx +\int
_A\int _R f_{Y,Q}(x,y)\,dy\,dx -\int _A\int _R \alpha _{x,y}f_{Y,Q}(x,y)\,dy\,dx \\ &amp;=\int _A\int _R \alpha _{y,x}f_{Y,Q}(y,x)\,dx\,dy +\P [Y\in A, Q\in R] -\int _A\int _R
\alpha _{x,y}f_{Y,Q}(x,y)\,dy\,dx \\ &amp;=\P [Y\in A]
\end{align*}
In the first line of the above we use <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_transition_function">8.7</a>)</span> to expand \(p(x,A)\). To obtain the second line we use
Lemma <a href="Conditioning-on-events-with-zero-probability.html#l:rv_from_conditioning_abs_cts">1.6.1</a>. To obtain the third line we use <span class="textup">(<a
href="Metropolis-Hastings.html#eq:mh_detailed_balance_2">8.11</a>)</span> for the first term, and for other terms we simply split the integral into two. In the fourth line we exchange the order of
integration in the first term, and note that the second term can be expressed as a probability. The final line follows because the first and third terms cancel (re-label \(x\) and \(y\) as each other in the first term to
obtain the third) and because \(\P [Q\in R]=1\). We thus obtain <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_Y_stationary">8.9</a>)</span>, as required.
</p>
<div class="theorembodyremark">

<ul class="list" style="list-style-type:none">



<a id="autoid-176"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Remark 8.2.6</span></span> <a id="autoid-177" ></a >It is possible to weaken the conditions on \((Y,Q)\) and allow cases where the
range of \(Q|_{\{Y=y\}}\) is a subset of the range of \(Y\). In this case it becomes necessary that the random sequence \((y_n)\) defined by the algorithm satisfies the condition \(\P [\exists n\in \N ,
y_n\in A]=1\) whenever \(\P [Y\in A]&gt;0\), regardless of the starting point of the chain \((y_n)\). This condition is known as <em>Harris recurrence</em>.
</p>

<p>
The same algorithm can also produce samples from discrete distributions. In this case we must replace the p.d.f&nbsp;\(f_Y\) by the p.m.f.&nbsp;\(p_Y\), and similarly for the conditional parts in <span
class="textup">(<a href="Metropolis-Hastings.html#eq:mh_alpha">8.1</a>)</span>, but otherwise we proceed exactly as before. We have focused on continuous prior and posterior distributions, with the
consequence that we won’t need the discrete case of Metropolis-Hastings within this course.
</p>


</li>

</ul>

</div>

</section>

</main>

</div>

<footer>

<p>
Copyright Nic Freeman, Sheffield University, last updated October 28, 2025
</p>

</footer>



<nav class="botnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

</body>
</html>
