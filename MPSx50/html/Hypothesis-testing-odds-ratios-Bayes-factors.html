<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Nic Freeman" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="MPS350/4111 Bayesian Statistics, Sheffield University, November 4, 2025." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>MPS350/4111 — Hypothesis testing, odds ratios and Bayes factors</title>
<link rel="stylesheet" type="text/css" href="sans-serif-lwarp-sagebrush.css" />
<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
// \left, \right delimiters: https://github.com/mathjax/MathJax/issues/2535
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
  subequations: "0",
  section: "",
  loader: {
    load: ['[tex]/tagformat', '[tex]/textmacros'],
  },
  startup: {
    ready() {
      // These would be replaced by import commands if you wanted to make
      // a proper extension.
      const Configuration = MathJax._.input.tex.Configuration.Configuration;
      const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
      const Macro = MathJax._.input.tex.Symbol.Macro;
      const TexError = MathJax._.input.tex.TexError.default;
      const ParseUtil = MathJax._.input.tex.ParseUtil.default;
      const expandable = MathJax._.util.Options.expandable;

       // Insert the replacement string into the TeX string, and check
       // that there haven't been too many maxro substitutions (prevents
       // infinite loops).
       const useArgument = (parser, text) => {
         parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
         parser.i = 0;
         if (++parser.macroCount > parser.configuration.options.maxMacros) {
           throw new TexError('MaxMacroSub1',
           'MathJax maximum macro substitution count exceeded; ' +
           'is there a recursive macro call?');
         }
       }

       // Create the command map for:
       //     \ifstar, \ifnextchar, \ifblank, \ifstrequal, \gsub, \seteqnumber
       new CommandMap('Lwarp-macros', {
         ifstar: 'IfstarFunction',
         ifnextchar: 'IfnextcharFunction',
         ifblank: 'IfblankFunction',
         ifstrequal: 'IfstrequalFunction',
         gsubstitute: 'GsubstituteFunction',
         seteqnumber: 'SeteqnumberFunction'
       }, {
         // This function implements an ifstar macro.
         IfstarFunction(parser, name) {
            const resultstar = parser.GetArgument(name);
            const resultnostar = parser.GetArgument(name);
            const star = parser.GetStar();                 // true if there is a *
            useArgument(parser, star ? resultstar : resultnostar);
         },

         // This function implements an ifnextchar macro.
         IfnextcharFunction(parser, name) {
           let whichchar = parser.GetArgument(name);
           if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
             // $ syntax highlighting
             whichchar = String.fromCodePoint(parseInt(whichchar));
           }
           const resultnextchar = parser.GetArgument(name);
           const resultnotnextchar = parser.GetArgument(name);
           const gotchar = (parser.GetNext() === whichchar);
           useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
         },

         // This function implements an ifblank macro.
         IfblankFunction(parser, name) {
           const blankarg = parser.GetArgument(name);
           const resultblank = parser.GetArgument(name);
           const resultnotblank = parser.GetArgument(name);
           const isblank = (blankarg.trim() == "");
           useArgument(parser, isblank ? resultblank : resultnotblank);
         },

         // This function implements an ifstrequal macro.
         IfstrequalFunction(parser, name) {
           const strequalfirst = parser.GetArgument(name);
           const strequalsecond = parser.GetArgument(name);
           const resultequal = parser.GetArgument(name);
           const resultnotequal = parser.GetArgument(name);
           const isequal = (strequalfirst == strequalsecond);
           useArgument(parser, isequal ? resultequal : resultnotequal);
         },

         // This function implements a gsub macro.
         GsubstituteFunction(parser, name) {
           const gsubfirst = parser.GetArgument(name);
           const gsubsecond = parser.GetArgument(name);
           const gsubthird = parser.GetArgument(name);
           let gsubresult=gsubfirst.replace(gsubsecond, gsubthird);
           useArgument(parser, gsubresult);
         },

         // This function modifies the equation numbers.
         SeteqnumberFunction(parser, name) {
             // Get the macro parameters
             const star = parser.GetStar();                  // true if there is a *
             const optBrackets = parser.GetBrackets(name);   // contents of optional brackets
             const newsubequations = parser.GetArgument(name); // the subequations argument
             const neweqsection = parser.GetArgument(name); // the eq section argument
             const neweqnumber = parser.GetArgument(name);   // the eq number argument
             MathJax.config.subequations=newsubequations ;   // a string with boolean meaning
             MathJax.config.section=neweqsection ;           // a string with numeric meaning
             parser.tags.counter = parser.tags.allCounter = neweqnumber ;
         }

       });

       // Create the Lwarp-macros package
       Configuration.create('Lwarp-macros', {
         handler: {macro: ['Lwarp-macros']}
       });

       MathJax.startup.defaultReady();

       // For forward references:
       MathJax.startup.input[0].preFilters.add(({math}) => {
         if (math.inputData.recompile){
             MathJax.config.subequations = math.inputData.recompile.subequations;
             MathJax.config.section = math.inputData.recompile.section;
         }
       });
       MathJax.startup.input[0].postFilters.add(({math}) => {
         if (math.inputData.recompile){
             math.inputData.recompile.subequations = MathJax.config.subequations;
             math.inputData.recompile.section = MathJax.config.section;
         }
       });

         // For \left, \right with unicode-math:
         const {DelimiterMap} = MathJax._.input.tex.SymbolMap;
         const {Symbol} = MathJax._.input.tex.Symbol;
         const {MapHandler} = MathJax._.input.tex.MapHandler;
         const delimiter = MapHandler.getMap('delimiter');
         delimiter.add('\\lBrack', new Symbol('\\lBrack', '\u27E6'));
         delimiter.add('\\rBrack', new Symbol('\\rBrack', '\u27E7'));
         delimiter.add('\\lAngle', new Symbol('\\lAngle', '\u27EA'));
         delimiter.add('\\rAngle', new Symbol('\\rAngle', '\u27EB'));
         delimiter.add('\\lbrbrak', new Symbol('\\lbrbrak', '\u2772'));
         delimiter.add('\\rbrbrak', new Symbol('\\rbrbrak', '\u2773'));
         delimiter.add('\\lbag', new Symbol('\\lbag', '\u27C5'));
         delimiter.add('\\rbag', new Symbol('\\rbag', '\u27C6'));
         delimiter.add('\\llparenthesis', new Symbol('\\llparenthesis', '\u2987'));
         delimiter.add('\\rrparenthesis', new Symbol('\\rrparenthesis', '\u2988'));
         delimiter.add('\\llangle', new Symbol('\\llangle', '\u2989'));
         delimiter.add('\\rrangle', new Symbol('\\rrangle', '\u298A'));
         delimiter.add('\\Lbrbrak', new Symbol('\\Lbrbrak', '\u27EC'));
         delimiter.add('\\Rbrbrak', new Symbol('\\Rbrbrak', '\u27ED'));
         delimiter.add('\\lBrace', new Symbol('\\lBrace', '\u2983'));
         delimiter.add('\\rBrace', new Symbol('\\rBrace', '\u2984'));
         delimiter.add('\\lParen', new Symbol('\\lParen', '\u2985'));
         delimiter.add('\\rParen', new Symbol('\\rParen', '\u2986'));
         delimiter.add('\\lbrackubar', new Symbol('\\lbrackubar', '\u298B'));
         delimiter.add('\\rbrackubar', new Symbol('\\rbrackubar', '\u298C'));
         delimiter.add('\\lbrackultick', new Symbol('\\lbrackultick', '\u298D'));
         delimiter.add('\\rbracklrtick', new Symbol('\\rbracklrtick', '\u298E'));
         delimiter.add('\\lbracklltick', new Symbol('\\lbracklltick', '\u298F'));
         delimiter.add('\\rbrackurtick', new Symbol('\\rbrackurtick', '\u2990'));
         delimiter.add('\\langledot', new Symbol('\\langledot', '\u2991'));
         delimiter.add('\\rangledot', new Symbol('\\rangledot', '\u2992'));
         delimiter.add('\\lparenless', new Symbol('\\lparenless', '\u2993'));
         delimiter.add('\\rparengtr', new Symbol('\\rparengtr', '\u2994'));
         delimiter.add('\\Lparengtr', new Symbol('\\Lparengtr', '\u2995'));
         delimiter.add('\\Rparenless', new Symbol('\\Rparenless', '\u2996'));
         delimiter.add('\\lblkbrbrak', new Symbol('\\lblkbrbrak', '\u2997'));
         delimiter.add('\\rblkbrbrak', new Symbol('\\rblkbrbrak', '\u2998'));
         delimiter.add('\\lvzigzag', new Symbol('\\lvzigzag', '\u29D8'));
         delimiter.add('\\rvzigzag', new Symbol('\\rvzigzag', '\u29D9'));
         delimiter.add('\\Lvzigzag', new Symbol('\\Lvzigzag', '\u29DA'));
         delimiter.add('\\Rvzigzag', new Symbol('\\Rvzigzag', '\u29DB'));
         delimiter.add('\\lcurvyangle', new Symbol('\\lcurvyangle', '\u29FC'));
         delimiter.add('\\rcurvyangle', new Symbol('\\rcurvyangle', '\u29FD'));
         delimiter.add('\\Vvert', new Symbol('\\Vvert', '\u2980'));
   }     // ready
 },      // startup

 tex: {
   packages: {'[+]': ['tagformat', 'Lwarp-macros', 'textmacros']},
   tags: "ams",
        tagformat: {
            number: function (n) {
                if(MathJax.config.subequations==0)
                    return(MathJax.config.section + n);
                else
                    return(MathJax.config.section + String.fromCharCode(96+n));
            },
        },
 }
}
</script>

<script
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4222H8D03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4222H8D03');
</script>
<!-- Google tag (gtag.js) -->


</head>
<body>



<a id="notes-autopage-210"></a>
<nav class="topnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

<header>

<p>
last updated: November 4, 2025
</p>

</header>



<div class="bodyandsidetoc">
<div class="sidetoccontainer">



<nav class="sidetoc">



<div class="sidetoctitle">

<p>
<span class="sidetocthetitle">Bayesian Statistics</span>
</p>

<p>
Contents
</p>
</div>



<div class="sidetoccontents">

<p>
<a href="notes.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Introduction.html#autosec-5" class="tocchapter" >
<span class="sectionnumber">0</span>&#x2003;Introduction</a>
</p>



<p>
<a href="Introduction.html#autosec-6" class="tocsection" >
<span class="sectionnumber">0.1</span>&#x2003;Organization</a>
</p>



<p>
<a href="Outline-course.html#autosec-10" class="tocsection" >
<span class="sectionnumber">0.2</span>&#x2003;Outline of the course</a>
</p>



<p>
<a href="Conditioning.html#autosec-12" class="tocchapter" >
<span class="sectionnumber">1</span>&#x2003;Conditioning</a>
</p>



<p>
<a href="Conditioning.html#autosec-13" class="tocsection" >
<span class="sectionnumber">1.1</span>&#x2003;Random variables</a>
</p>



<p>
<a href="Equality-in-distribution.html#autosec-18" class="tocsection" >
<span class="sectionnumber">1.2</span>&#x2003;Equality in distribution</a>
</p>



<p>
<a href="Families-random-variables.html#autosec-28" class="tocsection" >
<span class="sectionnumber">1.3</span>&#x2003;Families of random variables</a>
</p>



<p>
<a href="Conditioning-on-location.html#autosec-32" class="tocsection" >
<span class="sectionnumber">1.4</span>&#x2003;Conditioning on location</a>
</p>



<p>
<a href="Conditioning-correlations.html#autosec-40" class="tocsection" >
<span class="sectionnumber">1.5</span>&#x2003;Conditioning and correlations</a>
</p>



<p>
<a href="Conditioning-on-events-with-zero-probability.html#autosec-47" class="tocsection" >
<span class="sectionnumber">1.6</span>&#x2003;Conditioning on events with zero probability</a>
</p>



<p>
<a href="Families-with-random-parameters.html#autosec-54" class="tocsection" >
<span class="sectionnumber">1.7</span>&#x2003;Families with random parameters</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conditioning.html#autosec-57" class="tocsection" >
<span class="sectionnumber">1.8</span>&#x2003;Exercises on Chapter 1</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-62" class="tocchapter" >
<span class="sectionnumber">2</span>&#x2003;Bayesian models: discrete data</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-63" class="tocsection" >
<span class="sectionnumber">2.1</span>&#x2003;Models with random parameters</a>
</p>



<p>
<a href="Discrete-Bayesian-models.html#autosec-67" class="tocsection" >
<span class="sectionnumber">2.2</span>&#x2003;Discrete Bayesian models</a>
</p>



<p>
<a href="The-posterior-distribution.html#autosec-72" class="tocsection" >
<span class="sectionnumber">2.3</span>&#x2003;The posterior distribution</a>
</p>



<p>
<a href="Bayesian-updates.html#autosec-80" class="tocsection" >
<span class="sectionnumber">2.4</span>&#x2003;Bayesian updates</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_discrete.html#autosec-85" class="tocsection" >
<span class="sectionnumber">2.5</span>&#x2003;Exercises on Chapter 2</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-88" class="tocchapter" >
<span class="sectionnumber">3</span>&#x2003;Bayesian models: continuous data</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-89" class="tocsection" >
<span class="sectionnumber">3.1</span>&#x2003;Continuous Bayesian models</a>
</p>



<p>
<a href="Notation-independent-data.html#autosec-95" class="tocsection" >
<span class="sectionnumber">3.2</span>&#x2003;Notation: independent data</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_continuous.html#autosec-105" class="tocsection" >
<span class="sectionnumber">3.3</span>&#x2003;Exercises on Chapter 3</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-108" class="tocchapter" >
<span class="sectionnumber">4</span>&#x2003;Conjugate priors</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-110" class="tocsection" >
<span class="sectionnumber">4.1</span>&#x2003;Notation: proportionality</a>
</p>



<p>
<a href="Two-more-examples-conjugate-pairs.html#autosec-120" class="tocsection" >
<span class="sectionnumber">4.2</span>&#x2003;Two more examples of conjugate pairs</a>
</p>



<p>
<a href="Conjugate-pairs-exponential-family.html#autosec-130" class="tocsection" >
<span class="sectionnumber">4.3</span>&#x2003;Conjugate pairs and the exponential family \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="What-if.html#autosec-135" class="tocsection" >
<span class="sectionnumber">4.4</span>&#x2003;What if?</a>
</p>



<p>
<a href="The-normal-distribution-with-unknown-mean-variance.html#autosec-148" class="tocsection" >
<span class="sectionnumber">4.5</span>&#x2003;The normal distribution with unknown mean and variance</a>
</p>



<p>
<a href="The-limitations-conjugate-pairs.html#autosec-156" class="tocsection" >
<span class="sectionnumber">4.6</span>&#x2003;The limitations of conjugate pairs</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conjugate_priors.html#autosec-158" class="tocsection" >
<span class="sectionnumber">4.7</span>&#x2003;Exercises on Chapter 4</a>
</p>



<p>
<a href="The-prior.html#autosec-161" class="tocchapter" >
<span class="sectionnumber">5</span>&#x2003;The prior</a>
</p>



<p>
<a href="The-prior.html#autosec-162" class="tocsection" >
<span class="sectionnumber">5.1</span>&#x2003;Elicitation</a>
</p>



<p>
<a href="Uninformative-priors.html#autosec-171" class="tocsection" >
<span class="sectionnumber">5.2</span>&#x2003;Uninformative priors</a>
</p>



<p>
<a href="Reference-priors.html#autosec-178" class="tocsection" >
<span class="sectionnumber">5.3</span>&#x2003;Reference priors</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-prior.html#autosec-184" class="tocsection" >
<span class="sectionnumber">5.4</span>&#x2003;Exercises on Chapter 5</a>
</p>



<p>
<a href="Bayesian-Notation.html#autosec-187" class="tocchapter" >
<span class="sectionnumber">6</span>&#x2003;Bayesian Notation</a>
</p>



<p>
<a href="Bayesian-Notation.html#autosec-191" class="tocsection" >
<span class="sectionnumber">6.1</span>&#x2003;Exercises on Chapter 6</a>
</p>



<p>
<a href="The-posterior.html#autosec-193" class="tocchapter" >
<span class="sectionnumber">7</span>&#x2003;The posterior</a>
</p>



<p>
<a href="The-posterior.html#autosec-194" class="tocsection" >
<span class="sectionnumber">7.1</span>&#x2003;Credible intervals</a>
</p>



<p>
<a href="The-connection-maximum-likelihood.html#autosec-205" class="tocsection" >
<span class="sectionnumber">7.2</span>&#x2003;The connection to maximum likelihood</a>
</p>



<p>
<a href="Hypothesis-testing-odds-ratios-Bayes-factors.html#autosec-211" class="tocsection" >
<span class="sectionnumber">7.3</span>&#x2003;Hypothesis testing, odds ratios and Bayes factors</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-posterior.html#autosec-221" class="tocsection" >
<span class="sectionnumber">7.4</span>&#x2003;Exercises on Chapter 7</a>
</p>



<p>
<a href="Computational-methods.html#autosec-224" class="tocchapter" >
<span class="sectionnumber">8</span>&#x2003;Computational methods</a>
</p>



<p>
<a href="Computational-methods.html#autosec-225" class="tocsection" >
<span class="sectionnumber">8.1</span>&#x2003;Approximate Bayesian computation \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="Metropolis-Hastings.html#autosec-228" class="tocsection" >
<span class="sectionnumber">8.2</span>&#x2003;Metropolis-Hastings</a>
</p>



<p>
<a href="Markov-Chain-Monte-Carlo.html#autosec-242" class="tocsection" >
<span class="sectionnumber">8.3</span>&#x2003;Markov Chain Monte Carlo</a>
</p>



<p>
<a href="Gibbs-sampling.html#autosec-247" class="tocsection" >
<span class="sectionnumber">8.4</span>&#x2003;Gibbs sampling</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-computational.html#autosec-254" class="tocsection" >
<span class="sectionnumber">8.5</span>&#x2003;Exercises on Chapter 8</a>
</p>



<p>
<a href="Reference-Sheets.html#autosec-257" class="tocchapter" >
<span class="sectionnumber">A</span>&#x2003;Reference Sheets</a>
</p>



<p>
<a href="Advice-revision-exams.html#autosec-265" class="tocchapter" >
<span class="sectionnumber">B</span>&#x2003;Advice for revision/exams</a>
</p>



<p>
<a href="Solutions-exercises.html#autosec-268" class="tocchapter" >
<span class="sectionnumber">C</span>&#x2003;Solutions to exercises</a>
</p>



</div>

</nav>

</div>



<main class="bodycontainer">



<section class="textbody">

<h1>Bayesian Statistics</h1>

<!--MathJax customizations:-->
<div data-nosnippet
      style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\require {colortbl}\)

\(\let \LWRorigcolumncolor \columncolor \)

\(\renewcommand {\columncolor }[2][named]{\LWRorigcolumncolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigrowcolor \rowcolor \)

\(\renewcommand {\rowcolor }[2][named]{\LWRorigrowcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigcellcolor \cellcolor \)

\(\renewcommand {\cellcolor }[2][named]{\LWRorigcellcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\require {mathtools}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vcentcolon }{\mathrel {\unicode {x2236}}}\)

\(\renewcommand {\intertext }[2][]{\text {#2}\notag \\}\)

\(\newenvironment {fleqn}[1][]{}{}\)

\(\newenvironment {ceqn}{}{}\)

\(\newenvironment {darray}[2][c]{\begin {array}[#1]{#2}}{\end {array}}\)

\(\newcommand {\dmulticolumn }[3]{#3}\)

\(\newcommand {\LWRnrnostar }[1][0.5ex]{\\[#1]}\)

\(\newcommand {\nr }{\ifstar \LWRnrnostar \LWRnrnostar }\)

\(\newcommand {\mrel }[1]{\begin {aligned}#1\end {aligned}}\)

\(\newcommand {\underrel }[2]{\underset {#2}{#1}}\)

\(\newcommand {\medmath }[1]{#1}\)

\(\newcommand {\medop }[1]{#1}\)

\(\newcommand {\medint }[1]{#1}\)

\(\newcommand {\medintcorr }[1]{#1}\)

\(\newcommand {\mfrac }[2]{\frac {#1}{#2}}\)

\(\newcommand {\mbinom }[2]{\binom {#1}{#2}}\)

\(\newenvironment {mmatrix}{\begin {matrix}}{\end {matrix}}\)

\(\newcommand {\displaybreak }[1][]{}\)

\( \def \offsyl {(\oslash )} \def \msconly {(\Delta )} \)

\( \DeclareMathOperator {\var }{var} \DeclareMathOperator {\cov }{cov} \DeclareMathOperator {\Bin }{Bin} \DeclareMathOperator {\Geo }{Geometric} \DeclareMathOperator {\Beta
}{Beta} \DeclareMathOperator {\Unif }{Uniform} \DeclareMathOperator {\Gam }{Gamma} \DeclareMathOperator {\Normal }{N} \DeclareMathOperator {\Exp }{Exp} \DeclareMathOperator
{\Cauchy }{Cauchy} \DeclareMathOperator {\Bern }{Bernoulli} \DeclareMathOperator {\Poisson }{Poisson} \DeclareMathOperator {\Weibull }{Weibull} \DeclareMathOperator {\IGam
}{IGamma} \DeclareMathOperator {\NGam }{NGamma} \DeclareMathOperator {\ChiSquared }{ChiSquared} \DeclareMathOperator {\Pareto }{Pareto} \DeclareMathOperator {\NBin }{NegBin}
\DeclareMathOperator {\Studentt }{Student-t} \DeclareMathOperator *{\argmax }{arg\,max} \DeclareMathOperator *{\argmin }{arg\,min} \)

\( \def \to {\rightarrow } \def \iff {\Leftrightarrow } \def \ra {\Rightarrow } \def \sw {\subseteq } \def \mc {\mathcal } \def \mb {\mathbb } \def \sc {\setminus } \def \wt
{\widetilde } \def \v {\textbf } \def \E {\mb {E}} \def \P {\mb {P}} \def \R {\mb {R}} \def \C {\mb {C}} \def \N {\mb {N}} \def \Q {\mb {Q}} \def \Z {\mb {Z}} \def \B {\mb {B}}
\def \~{\sim } \def \-{\,;\,} \def \qed {$\blacksquare $} \CustomizeMathJax {\def \1{\unicode {x1D7D9}}} \def \cadlag {c\&grave;{a}dl\&grave;{a}g} \def \p {\partial } \def \l
{\left } \def \r {\right } \def \Om {\Omega } \def \om {\omega } \def \eps {\epsilon } \def \de {\delta } \def \ov {\overline } \def \sr {\stackrel } \def \Lp {\mc {L}^p} \def
\Lq {\mc {L}^p} \def \Lone {\mc {L}^1} \def \Ltwo {\mc {L}^2} \def \toae {\sr {\rm a.e.}{\to }} \def \toas {\sr {\rm a.s.}{\to }} \def \top {\sr {\mb {\P }}{\to }} \def \tod {\sr
{\rm d}{\to }} \def \toLp {\sr {\Lp }{\to }} \def \toLq {\sr {\Lq }{\to }} \def \eqae {\sr {\rm a.e.}{=}} \def \eqas {\sr {\rm a.s.}{=}} \def \eqd {\sr {\rm d}{=}} \def \approxd
{\sr {\rm d}{\approx }} \def \Sa {(S1)\xspace } \def \Sb {(S2)\xspace } \def \Sc {(S3)\xspace } \)

</div>

<!--
...... section Hypothesis testing, odds ratios and Bayes factors ......
-->
<h4 id="autosec-211"><span class="sectionnumber">7.3&#x2003;</span>Hypothesis testing, odds ratios and Bayes factors</h4>
<a id="notes-autopage-211"></a>
<a id="notes-autofile-33"></a>

<a id="s:hyp_testing"></a>

<p>
Hypothesis testing is surprisingly simple within the Bayesian framework. We first need to introduce the way to present the results.
</p>
<div class="theorembodydefinition">

<ul class="list" style="list-style-type:none">



<a id="autoid-151"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Definition 7.3.1</span></span> <a id="autoid-152" ></a ><a id="d:odds_ratios"></a> Let \(A\) and \(B\) be events such that \(\P
[A\cup B]=1\) and \(A\cap B=\emptyset \). The <em>odds ratio</em> of \(A\) against \(B\) is
</p>

<p>
\[O_{A,B}=\frac {\P [A]}{\P [B]}.\]
</p>

<p>
It expresses how much more likely \(A\) is than \(B\). For example, \(O_{A,B}=2\) means that \(A\) is twice as likely to occur than \(B\); if \(O_{A,B}=1\) then \(A\) and \(B\) are equally likely.
</p>


</li>

</ul>

</div>

<p>
Take a Bayesian model \((X,\Theta )\) with parameter space \(\Pi \). We split the parameter space into two pieces: \(\Pi =\Pi _0\cup \Pi _1\) where \(\Pi _0\cap \Pi _1=\emptyset \). We think of two
competing hypothesis:
</p>
<span class="hidden"> \(\seteqnumber{0}{7.}{4}\)</span>



<!--

                                                                                                 H0 : that θ ∈ Π0 ,

                                                                                                 H1 : that θ ∈ Π1 ,



-->



<p>


\begin{align*}
H_0&amp;:\text { that }\theta \in \Pi _0, \\ H_1&amp;:\text { that }\theta \in \Pi _1,
\end{align*}
where \(\theta \) represents the true value of the parameter i.e.&nbsp;the value for which our model should (at least, as a good approximation) match up with reality.
</p>
<div class="theorembodydefinition">

<ul class="list" style="list-style-type:none">



<a id="autoid-153"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Definition 7.3.2</span></span> <a id="autoid-154" ></a >The <em>prior odds</em> of \(H_0\) against \(H_1\) is defined to be
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{4}\)</span>

<!--

                                                                        P[Θ ∈ Π0 ]
                                                                                   .                                                                        (7.5)         --><a id="eq:prior_odds"></a><!--
                                                                        P[Θ ∈ Π1 ]

-->

<p>


\begin{equation}
\label {eq:prior_odds} \frac {\P [\Theta \in \Pi _0]}{\P [\Theta \in \Pi _1]}.
\end{equation}


</p>

<p>
Given the data \(x\), the <em>posterior odds</em> of \(H_0\) against \(H_1\) is defined to be
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{5}\)</span>

<!--

                                                                  P[Θ|{X=x} ∈ Π0 ]
                                                                                   .                                                                (7.6)            --><a id="eq:posterior_odds"></a><!--
                                                                  P[Θ|{X=x} ∈ Π1 ]

-->

<p>


\begin{equation}
\label {eq:posterior_odds} \frac {\P [\Theta |_{\{X=x\}}\in \Pi _0]}{\P [\Theta |_{\{X=x\}}\in \Pi _1]}.
\end{equation}


</p>

<p>
We might also refer to <span class="textup">(<a href="Hypothesis-testing-odds-ratios-Bayes-factors.html#eq:prior_odds">7.5</a>)</span> as the ‘prior odds of \(\Pi _0\) against \(\Pi _1\)’, and
similarly for <span class="textup">(<a href="Hypothesis-testing-odds-ratios-Bayes-factors.html#eq:posterior_odds">7.6</a>)</span>.
</p>


</li>

</ul>

</div>

<p>
Note that the prior odds involve the prior \(\Theta \), and the posterior odds involve the posterior \(\Theta |_{\{X=x\}}\), but otherwise the formulae are identical. We assume implicitly that \(\P [\Theta \in
\Pi _0]\) and \(\P [\Theta \in \Pi _1]\) are both non-zero, which by Theorems <a href="Bayesian-updates.html#t:bayes_thm_discrete_data">2.4.1</a> and <a
href="Bayesian-models-continuous-data.html#t:bayes_thm_continuous_data">3.1.2</a> implies that the same is true for \(\Theta |_{\{X=x\}}\). Note also that the prior and posterior odds are only well
defined for proper prior and posterior distributions, or else we cannot make sense of the probabilities above.
</p>

<p>
It is often helpful to get a feel for how much the data has influenced the result of the test. For these purposes we also define the <em>Bayes factor</em>
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{6}\)</span>

<!--

                                                                       posterior odds
                                                                 B=                   .                                                                (7.7)            --><a id="eq:bayes_factor"></a><!--
                                                                         prior odds

-->

<p>


\begin{equation}
\label {eq:bayes_factor} B=\frac {\text {posterior odds}}{\text {prior odds}}.
\end{equation}


</p>

<p>
Our next lemma shows why \(B\) is important. It is equal to the ratio of the likelihoods of the event \(\{X=x\}\), i.e.&nbsp;of the data that we have, conditional on \(\Theta \in \Pi _0\) and \(\Theta \in \Pi
_1\). In other words, \(B\) is the ratio of the likelihood of \(H_0\) compared to \(H_1\).
</p>
<div class="theorembodylemma">

<ul class="list" style="list-style-type:none">



<a id="autoid-155"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Lemma 7.3.3</span></span> <a id="autoid-156" ></a ><a id="l:bayes_factor_likelihood_ratio"></a> In the notation above, the
Bayes factor satisfies \(B=\frac {L_{X|_{\{\Theta \in \Pi _0\}}}(x)}{L_{X|_{\{\Theta \in \Pi _1\}}}(x)}\) where \(L\) denotes the likelihood function.
</p>


</li>

</ul>

</div>

<p>
<span class="textsc">Proof:</span><span style="width:5.5pt; display:inline-block"><!----></span> We split the proof into two cases, depending on whether the Bayesian model is discrete or
absolutely continuous. In the discrete case we have
</p>

<p>
\[B =\frac {\P [\Theta |_{\{X=x\}}\in \Pi _0]\P [\Theta \in H_1]}{\P [\Theta |_{\{X=x\}}\in \Pi _1]\P [\Theta \in H_0]} =\frac {\frac {\P [\Theta \in \Pi _0, X=x]}{\P [X=x]}\P
[\Theta \in H_1]}{\frac {\P [\Theta \in \Pi _1, X=x]}{\P [X=x]}\P [\Theta \in H_0]} =\frac {\frac {\P [\Theta \in \Pi _0,X=x]}{\P [\theta \in \Pi _0]}}{\frac {\P [\Theta \in \Pi
_1,X=x]}{\P [\theta \in \Pi _1]}} =\frac {\P [X|_{\{\Theta \in \Pi _0\}}=x]}{\P [X|_{\{\Theta \in \Pi _1\}}=x]}. \]
</p>

<p>
We have used equation <span class="textup">(<a href="Conditioning-on-location.html#eq:rv_conditioned_dist">1.4</a>)</span> from Lemma <a
href="Conditioning-on-location.html#l:rv_from_conditioning_pve">1.4.1</a> several times here. The continuous case is left for you, in Exercise <a
href="Exercises-on-Chapter-ref-c-posterior.html#ps:bayes_factor_likelihood_ratio_abs_cts"><b>7.8</b></a> &#x2003;&#x2003;&#x220E;
</p>

<p>
As a rough guide to translating the Bayes factor into common language, the following table<sup>1</sup><a id="notes-autopage-214"></a> is sometimes used:
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{7}\)</span>

<!--

                                  Bayes factor   Interpretation: evidence in favour of \(H_0\) over \(H_1\)
                                     1 to 3.2    Indecisive / not worth more than a bare mention
                                    3.2 to 10    Substantial                                                                                (7.8)                  --><a id="eq:bayes_factor_table"></a><!--
                                    10 to 100    Strong
                                   above 100     Decisive

-->

<p>


\begin{equation}
\label {eq:bayes_factor_table} \begin{tabular}{c|l} Bayes factor &amp; Interpretation: evidence in favour of $H_0$ over $H_1$ \\ \hline 1 to 3.2 &amp; Indecisive / not worth more
than a bare mention \\ 3.2 to 10 &amp; Substantial \\ 10 to 100 &amp; Strong \\ above 100 &amp; Decisive \\ \end {tabular}
\end{equation}


</p>

<p>
Note that a high value of \(B\) only says that \(H_0\) should be preferred over \(H_1\). It does not tell us anything objective about how good our model \((M_\theta )\) is; it only tells us that \(X|_{\{\Theta
\in \Pi _0\}}\) is a better fit for \(x\) than \(X|_{\{\Theta \in \Pi _1\}}\) is.
</p>

<p>
Values of the Bayes factor below \(1\) suggest evidence in favour of \(H_1\) over \(H_0\). In such a case we can swap the roles of \(H_0\) and \(H_1\), which corresponds to the Bayes factor changing from \(B\) to
\(1/B\), and we can then use the same table to discuss the weight of evidence in favour of \(H_1\) over \(H_0\).
</p>
<div role="note" class="footnotes">

<a id="notes-autopage-215"></a>

<p>
<sup>1</sup>&nbsp;From Kass &amp; Raftery (1995).
</p>



</div>



<div class="theorembodyexample">

<ul class="list" style="list-style-type:none">



<a id="autoid-157"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Example 7.3.4</span></span> <a id="autoid-158" ></a >Returning to Example <a
href="The-normal-distribution-with-unknown-mean-variance.html#ex:speed_camera_2">4.5.3</a>, suppose that we wished to test the hypothesis that the speed camera is, on average, overestimating the
speed to cars. Recall that in this example:
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">•</span> Our model was the \(N(\mu ,\frac {1}{\tau })\), for the speed recorded by the camera when a car travels at exactly 30mph.
</p>


</li>
<li>


<p>
<span class="listmarker">•</span> We used a weak prior \((\mu ,\tau )\sim \NGam (30,\frac {1}{10^2},1,\frac 15)\).
</p>


</li>
<li>


<p>
<span class="listmarker">•</span> We found the posterior \((\mu ,\tau )\sim \NGam (30.14, 10.01, 6.00, 1.24)\).
</p>
</li>
</ul>

<p>
Both the posterior and prior density functions are plotted in Example <a href="The-normal-distribution-with-unknown-mean-variance.html#ex:speed_camera_2">4.5.3</a>.
</p>

<p>
Recall that if \((\mu ,\tau )\sim \NGam (m,p,a,b)\) then \(\mu |\tau \sim \Normal (m,\frac {1}{p\tau })\), so the marginal mean of \(\mu \) is \(m\). Hence, the speed camera on average overestimates
the speed when \(\mu &gt;30\), and underestimates on average when \(\mu &lt;30\). The probability that \(\mu \) is exactly \(30\) is zero, because our posterior \(\NGam \) is a continuous distribution, so we
will simply ignore that possibility. We don’t care about the location of \(\tau \) here so we simply allow it to take any value \(\tau \in (0,\infty )\). This gives us hypothesis
</p>
<span class="hidden"> \(\seteqnumber{0}{7.}{8}\)</span>



<!--

                                                                                       H0 : that (µ, τ ) ∈ Π0 = (30, ∞) × (0, ∞),

                                                                                       H1 : that (µ, τ ) ∈ Π1 = (−∞, 30) × (0, ∞).



-->



<p>


\begin{align*}
H_0&amp;:\text { that }(\mu ,\tau )\in \Pi _0=(30,\infty )\times (0,\infty ), \\ H_1&amp;:\text { that }(\mu ,\tau )\in \Pi _1=(-\infty ,30)\times (0,\infty ).
\end{align*}
We want to compute the Bayes factor \(B\). We’ll start with the posterior odds ratio. We have
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{8}\)</span>

<!--
                                                                                             Z ∞Z ∞
                                                                        P[(µ, τ ) ∈ Π0 ] =            fNGamma(30.14,10.01,6.00,1.24) (µ, τ ) dτ dµ ≈ 0.82,
                                                                                             30   0

-->

<p>


\begin{equation*}
\P [(\mu ,\tau )\in \Pi _0]=\int _{30}^\infty \int _0^\infty f_{\NGam (30.14, 10.01, 6.00, 1.24)}(\mu ,\tau )\,d\tau \,d\mu \approx 0.82,
\end{equation*}


</p>

<p>
computed numerically and rounded to two decimal places. Note that \(\P [(\mu ,\tau )\in \Pi _1]=1-\P [(\mu ,\tau )\in \Pi _0]\), which gives a posterior odds ratio of
</p>

<p>
\[\frac {\P [\Theta |_{\{X=x\}}\in H_0]}{\P [\Theta |_{\{X=x\}}\in H_1]}=\frac {0.82}{1-0.82}=4.56\]
</p>

<p>
again rounded to two decimal places. The prior odds ratio, calculated via the same procedure, is exactly \(1\). This occurs because of the symmetry of the prior \(\NGam (30,\frac {1}{10^2},1,\frac 15)\)
distribution (this symmetry is visible in the sketch in Example <a href="The-normal-distribution-with-unknown-mean-variance.html#ex:speed_camera_2">4.5.3</a>) gives that \(\P [\NGam (30,\frac
{1}{10^2},1,\frac 15)\in \Pi _1]=\P [\NGam (30,\frac {1}{10^2},1,\frac 15)\in \Pi _0]=\frac 12\). Hence the Bayes factor for this hypothesis test is
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{8}\)</span>

<!--

                                                                                                            4.56
                                                                                                      B=         = 4.56.                                                                                           (7.9)
                                                                                                            1.00

-->

<p>


\begin{equation}
B=\frac {4.56}{1.00}=4.56.
\end{equation}


</p>

<p>
Based on table <span class="textup">(<a href="Hypothesis-testing-odds-ratios-Bayes-factors.html#eq:bayes_factor_table">7.8</a>)</span>, we have substantial evidence that the speed camera is
overestimating speeds.
</p>

<p>
A potential problem with our test is that we have not cared about <em>how much</em> the camera is overestimating speeds. The (marginal) mean of \(\mu \) in our posterior distribution is \(30.14\), which is
only slightly larger than the true speed \(30\), and this suggests that the error is fairly small. We would need to be careful about communicating the result of our test, to avoid giving the wrong impression.
</p>

<p>
Note that we have used a small amount of Bayesian shorthand in this example, by writing \(\mu \) and \(\tau \) for both random variables and samples of these random variables.
</p>


</li>

</ul>

</div>
<!--
...... subsection Comparison to classical hypothesis testing ......
-->
<h5 id="autosec-216"><span class="sectionnumber">7.3.1&#x2003;</span>Comparison to classical hypothesis testing</h5>
<a id="notes-autopage-216"></a>



<a id="s:hyp_class_vs_hyp_bayes"></a>

<p>
The endpoint of a Bayesian hypothesis test is usually a Bayes factor \(B\) which can then be interpreted, using table <span class="textup">(<a
href="Hypothesis-testing-odds-ratios-Bayes-factors.html#eq:bayes_factor_table">7.8</a>)</span> or similar, into common language that describes the strength of evidence in favour of \(H_0\) over
\(H_1\). There is no ‘pass’ or ‘fail’ outcome, just a comparison between two situations.
</p>

<p>
You will have seen a different method of carrying out a hypothesis test before, looking something like this.
</p>
<div class="theorembodydefinition">

<ul class="list" style="list-style-type:none">



<a id="autoid-159"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Definition 7.3.5</span></span> <a id="autoid-160" ></a ><a id="d:classical_hypothesis_test"></a> \(\offsyl \) The <em>classical
hypothesis test</em> is the following procedure:
</p>
<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> Choose a model family \((M_\theta )_{\theta \in \Pi }\), choose a value \(\theta _0\in \Pi \) and define \(H_0\) to be the model \(M_{\theta _0}\). This is often
written in shorthand as \(H_0:\theta =\theta _0\).
</p>


</li>
<li>


<p>
<span class="listmarker">2.</span> Calculate a value \(p\) as follows. Assume that \(H_0\) is true i.e.&nbsp;use the model \(M_{\theta _0}\) and using this model, calculate \(p\) to be the probability of
observing data that is (in some chosen sense) ‘at least as extreme’ as the data \(x\) that we actually observed.
</p>
<p>
If \(p\) is sufficiently small (in some chosen sense) then reject \(H_0\).
</p>
</li>
</ul>


</li>

</ul>

</div>

<p>
Let us think about this process carefully. Firstly, there is no need for an ‘alternative hypothesis’ in Definition <a
href="Hypothesis-testing-odds-ratios-Bayes-factors.html#d:classical_hypothesis_test">7.3.5</a>. More specifically, rejecting \(H_0\) means that we think it is unlikely that our chosen model
\(M_{\theta _0}\) would generate the data \(x\), so consequently we think it is unlikely that \(M_{\theta _0}\) is a good model.
</p>

<p>
<em>There is nothing else to say here!</em> Rejecting \(H_0\) does not mean that the ‘alternative hypothesis’ \(H_1\) that \(\theta \neq \theta _0\) is accepted (or true). If \(p\) turns out to be small it means
that either (i) \(M_{\theta _0}\) is a good model and our data \(x\) was unlikely to have occurred or, (ii) \(M_{\theta _0}\) is a bad model for our data. Neither statement tells us what a good model might look
like. Unfortunately classical hypothesis testing is very often misunderstood, and rejection of \(H_0\) is incorrectly treated as though it implies that \(H_1\) is true.
</p>

<p>
If we do not reject \(H_0\), then it means that the model \(M_{\theta _0}\) is reasonably likely to generate the data we have. This leaves open the possibility that there may be lots of other models, not necessarily
within our chosen model family, that are also reasonably likely to generate the data we have. This point is sometimes misunderstood too.
</p>

<p>
There are several other common mistakes that are based on misunderstanding the role of a \(p\)-values. For example, you may come across claims that the \(p\)-value is the probability that \(H_0\) is true, or that
\(H_1\) is false, or that it is the probability that the data occurred via ‘random chance’. None of these things match step 2 of Definition <a
href="Hypothesis-testing-odds-ratios-Bayes-factors.html#d:classical_hypothesis_test">7.3.5</a>. A further issue is <em>\(p\)-hacking</em>, which refers to carrying out repeated tests (with new
data each time) and then only reporting the experiments that rejected \(H_0\). This amounts to rejection sampling, conditioning the model on the event that it generates unusual data, which changes the model and
invalidates the test.
</p>

<p>
In summary, the main problem with Definition <a href="Hypothesis-testing-odds-ratios-Bayes-factors.html#d:classical_hypothesis_test">7.3.5</a> is that understanding the outcome of a classical
hypothesis test requires careful logic, which opens a door both to human error and to misuse. The Bayesian hypothesis test is comparatively easy to interpret.
</p>
<div class="theorembodyexample">

<ul class="list" style="list-style-type:none">



<a id="autoid-161"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Example 7.3.6</span></span> <a id="autoid-162" ></a ><a id="ex:hans_the_horse"></a> \(\offsyl \) A famous example of one of
these mistakes comes from the ‘clever Hans’ effect. Hans was a horse who appeared to be able to do arithmetic, owned by a mathematics teacher Wilhelm von Osten. Von Osten would ask Hans (by speaking out
loud) to answer to various questions and Hans would reply by tapping his hoof. The number of taps was interpreted as a numerical answer. Hans answered the vast majority of questions correctly.
</p>

<p>
To construct a hypothesis test using Definition <a href="Hypothesis-testing-odds-ratios-Bayes-factors.html#d:classical_hypothesis_test">7.3.5</a>, take a model family \(M_{\theta }\sim \Bern
(\theta )^{\otimes n}\), where the data \(x=(x_1,\ldots ,x_n)\) corresponds to \(x_i=1\) for solving the \(n^{\text {th}}\) question correctly, and \(x_i=0\) for incorrectly. We don’t know exactly how
hard the arithmetic questions were, so let us suppose that the probability of Hans solving a question correctly by guessing at random is \(\theta =\frac 12\) (this is clearly a very generous assumption for
arithmetic). So, take
</p>

<p>
\[H_0:\text { that }\theta =1/2\times (0,\infty )\text { i.e.~the horse solves the questions at random}\]
</p>

<p>
and then the model we wish to test is \(M_{\frac 12}\). The horse is asked \(n=10\) questions, and it answers them all correctly. Our model \(M_{\frac 12}\) says the probability of this is \((\frac
12)^{10}\approx 0.001=p\). We reject \(H_0\). Taking any value \(\theta \leq \frac 12\) will lead to the same conclusion.
</p>

<p>
So, we expect that our model \(M_{\theta }\) is a bad description of reality, for each \(\theta \leq \frac 12\). This does not mean that we must accept \(H_1\) and believe the horse is doing arithmetic
i.e.&nbsp;that some alternative model \(M_\theta \) is correct for some larger value of \(\theta \). In fact, what is going on here is that Hans has learnt to read the body language of Wilhelm von Osten, who
leans in forwards whilst Hans is tapping his hoof and leans back upright as soon as the correct number of taps has been reached. This was established by the psychologist Oskar Pfungst, who tested Hans and von
Osten under several different conditions in a laboratory.
</p>

<p>
In short, our model that the horse ‘solves’ questions is a bad choice. The horse <em>answers</em> questions correctly but it does not <em>solve</em> questions. To distinguish between these two situations we need a
better model than \((M_\theta )\), as Pfungst did in his laboratory. His model included (amongst other things) an extra variable for whether Hans could see von Osten.
</p>

<p>
After the investigations by Pfungst were done, von Osten refused to believe what Pfungst had discovered, and continued to show Hans around Germany. They attracted large and enthusiastic crowds, and made a
substantial amount of money from doing so – many in his audience wondered if they should accept \(H_1\).
</p>


</li>

</ul>

</div>

<figure id="autoid-163" class="figure ">
<div class="center">

<p>


<a href="hansthehorse.png" target="_blank" ><img
      src="hansthehorse.png"
      style="
      width:390pt;
      "
      class="inlineimage"
      alt="(image)"
></a>
</p>
</div>


<div class="figurecaption">
<p>
Figure&nbsp;7.1:&nbsp;Hans the horse in 1904, correctly answering arithmetic questions set by his owner Wilhem von Osten.
</p>
</div>

</figure>

</section>

</main>

</div>

<footer>

<p>
Copyright Nic Freeman, Sheffield University, last updated November 4, 2025
</p>

</footer>



<nav class="botnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

</body>
</html>
