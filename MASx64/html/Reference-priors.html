<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Nic Freeman" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="MAS364/61006 Bayesian Statistics, Sheffield University, December 4, 2024." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>MAS364/61006 — Reference priors</title>
<link rel="stylesheet" type="text/css" href="sans-serif-lwarp-sagebrush.css" />
<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
// \left, \right delimiters: https://github.com/mathjax/MathJax/issues/2535
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
  subequations: "0",
  section: "",
  loader: {
    load: ['[tex]/tagformat', '[tex]/textmacros'],
  },
  startup: {
    ready() {
      // These would be replaced by import commands if you wanted to make
      // a proper extension.
      const Configuration = MathJax._.input.tex.Configuration.Configuration;
      const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
      const Macro = MathJax._.input.tex.Symbol.Macro;
      const TexError = MathJax._.input.tex.TexError.default;
      const ParseUtil = MathJax._.input.tex.ParseUtil.default;
      const expandable = MathJax._.util.Options.expandable;

       // Insert the replacement string into the TeX string, and check
       // that there haven't been too many maxro substitutions (prevents
       // infinite loops).
       const useArgument = (parser, text) => {
         parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
         parser.i = 0;
         if (++parser.macroCount > parser.configuration.options.maxMacros) {
           throw new TexError('MaxMacroSub1',
           'MathJax maximum macro substitution count exceeded; ' +
           'is there a recursive macro call?');
         }
       }

       // Create the command map for:
       //     \ifstar, \ifnextchar, \ifblank, \ifstrequal, \gsub, \seteqnumber
       new CommandMap('Lwarp-macros', {
         ifstar: 'IfstarFunction',
         ifnextchar: 'IfnextcharFunction',
         ifblank: 'IfblankFunction',
         ifstrequal: 'IfstrequalFunction',
         gsubstitute: 'GsubstituteFunction',
         seteqnumber: 'SeteqnumberFunction'
       }, {
         // This function implements an ifstar macro.
         IfstarFunction(parser, name) {
            const resultstar = parser.GetArgument(name);
            const resultnostar = parser.GetArgument(name);
            const star = parser.GetStar();                 // true if there is a *
            useArgument(parser, star ? resultstar : resultnostar);
         },

         // This function implements an ifnextchar macro.
         IfnextcharFunction(parser, name) {
           let whichchar = parser.GetArgument(name);
           if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
             // $ syntax highlighting
             whichchar = String.fromCodePoint(parseInt(whichchar));
           }
           const resultnextchar = parser.GetArgument(name);
           const resultnotnextchar = parser.GetArgument(name);
           const gotchar = (parser.GetNext() === whichchar);
           useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
         },

         // This function implements an ifblank macro.
         IfblankFunction(parser, name) {
           const blankarg = parser.GetArgument(name);
           const resultblank = parser.GetArgument(name);
           const resultnotblank = parser.GetArgument(name);
           const isblank = (blankarg.trim() == "");
           useArgument(parser, isblank ? resultblank : resultnotblank);
         },

         // This function implements an ifstrequal macro.
         IfstrequalFunction(parser, name) {
           const strequalfirst = parser.GetArgument(name);
           const strequalsecond = parser.GetArgument(name);
           const resultequal = parser.GetArgument(name);
           const resultnotequal = parser.GetArgument(name);
           const isequal = (strequalfirst == strequalsecond);
           useArgument(parser, isequal ? resultequal : resultnotequal);
         },

         // This function implements a gsub macro.
         GsubstituteFunction(parser, name) {
           const gsubfirst = parser.GetArgument(name);
           const gsubsecond = parser.GetArgument(name);
           const gsubthird = parser.GetArgument(name);
           let gsubresult=gsubfirst.replace(gsubsecond, gsubthird);
           useArgument(parser, gsubresult);
         },

         // This function modifies the equation numbers.
         SeteqnumberFunction(parser, name) {
             // Get the macro parameters
             const star = parser.GetStar();                  // true if there is a *
             const optBrackets = parser.GetBrackets(name);   // contents of optional brackets
             const newsubequations = parser.GetArgument(name); // the subequations argument
             const neweqsection = parser.GetArgument(name); // the eq section argument
             const neweqnumber = parser.GetArgument(name);   // the eq number argument
             MathJax.config.subequations=newsubequations ;   // a string with boolean meaning
             MathJax.config.section=neweqsection ;           // a string with numeric meaning
             parser.tags.counter = parser.tags.allCounter = neweqnumber ;
         }

       });

       // Create the Lwarp-macros package
       Configuration.create('Lwarp-macros', {
         handler: {macro: ['Lwarp-macros']}
       });

       MathJax.startup.defaultReady();

       // For forward references:
       MathJax.startup.input[0].preFilters.add(({math}) => {
         if (math.inputData.recompile){
             MathJax.config.subequations = math.inputData.recompile.subequations;
             MathJax.config.section = math.inputData.recompile.section;
         }
       });
       MathJax.startup.input[0].postFilters.add(({math}) => {
         if (math.inputData.recompile){
             math.inputData.recompile.subequations = MathJax.config.subequations;
             math.inputData.recompile.section = MathJax.config.section;
         }
       });

         // For \left, \right with unicode-math:
         const {DelimiterMap} = MathJax._.input.tex.SymbolMap;
         const {Symbol} = MathJax._.input.tex.Symbol;
         const {MapHandler} = MathJax._.input.tex.MapHandler;
         const delimiter = MapHandler.getMap('delimiter');
         delimiter.add('\\lBrack', new Symbol('\\lBrack', '\u27E6'));
         delimiter.add('\\rBrack', new Symbol('\\rBrack', '\u27E7'));
         delimiter.add('\\lAngle', new Symbol('\\lAngle', '\u27EA'));
         delimiter.add('\\rAngle', new Symbol('\\rAngle', '\u27EB'));
         delimiter.add('\\lbrbrak', new Symbol('\\lbrbrak', '\u2772'));
         delimiter.add('\\rbrbrak', new Symbol('\\rbrbrak', '\u2773'));
         delimiter.add('\\lbag', new Symbol('\\lbag', '\u27C5'));
         delimiter.add('\\rbag', new Symbol('\\rbag', '\u27C6'));
         delimiter.add('\\llparenthesis', new Symbol('\\llparenthesis', '\u2987'));
         delimiter.add('\\rrparenthesis', new Symbol('\\rrparenthesis', '\u2988'));
         delimiter.add('\\llangle', new Symbol('\\llangle', '\u2989'));
         delimiter.add('\\rrangle', new Symbol('\\rrangle', '\u298A'));
         delimiter.add('\\Lbrbrak', new Symbol('\\Lbrbrak', '\u27EC'));
         delimiter.add('\\Rbrbrak', new Symbol('\\Rbrbrak', '\u27ED'));
         delimiter.add('\\lBrace', new Symbol('\\lBrace', '\u2983'));
         delimiter.add('\\rBrace', new Symbol('\\rBrace', '\u2984'));
         delimiter.add('\\lParen', new Symbol('\\lParen', '\u2985'));
         delimiter.add('\\rParen', new Symbol('\\rParen', '\u2986'));
         delimiter.add('\\lbrackubar', new Symbol('\\lbrackubar', '\u298B'));
         delimiter.add('\\rbrackubar', new Symbol('\\rbrackubar', '\u298C'));
         delimiter.add('\\lbrackultick', new Symbol('\\lbrackultick', '\u298D'));
         delimiter.add('\\rbracklrtick', new Symbol('\\rbracklrtick', '\u298E'));
         delimiter.add('\\lbracklltick', new Symbol('\\lbracklltick', '\u298F'));
         delimiter.add('\\rbrackurtick', new Symbol('\\rbrackurtick', '\u2990'));
         delimiter.add('\\langledot', new Symbol('\\langledot', '\u2991'));
         delimiter.add('\\rangledot', new Symbol('\\rangledot', '\u2992'));
         delimiter.add('\\lparenless', new Symbol('\\lparenless', '\u2993'));
         delimiter.add('\\rparengtr', new Symbol('\\rparengtr', '\u2994'));
         delimiter.add('\\Lparengtr', new Symbol('\\Lparengtr', '\u2995'));
         delimiter.add('\\Rparenless', new Symbol('\\Rparenless', '\u2996'));
         delimiter.add('\\lblkbrbrak', new Symbol('\\lblkbrbrak', '\u2997'));
         delimiter.add('\\rblkbrbrak', new Symbol('\\rblkbrbrak', '\u2998'));
         delimiter.add('\\lvzigzag', new Symbol('\\lvzigzag', '\u29D8'));
         delimiter.add('\\rvzigzag', new Symbol('\\rvzigzag', '\u29D9'));
         delimiter.add('\\Lvzigzag', new Symbol('\\Lvzigzag', '\u29DA'));
         delimiter.add('\\Rvzigzag', new Symbol('\\Rvzigzag', '\u29DB'));
         delimiter.add('\\lcurvyangle', new Symbol('\\lcurvyangle', '\u29FC'));
         delimiter.add('\\rcurvyangle', new Symbol('\\rcurvyangle', '\u29FD'));
         delimiter.add('\\Vvert', new Symbol('\\Vvert', '\u2980'));
   }     // ready
 },      // startup

 tex: {
   packages: {'[+]': ['tagformat', 'Lwarp-macros', 'textmacros']},
   tags: "ams",
        tagformat: {
            number: function (n) {
                if(MathJax.config.subequations==0)
                    return(MathJax.config.section + n);
                else
                    return(MathJax.config.section + String.fromCharCode(96+n));
            },
        },
 }
}
</script>

<script
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4222H8D03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4222H8D03');
</script>
<!-- Google tag (gtag.js) -->


</head>
<body>



<a id="notes-autopage-178"></a>
<nav class="topnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

<header>

<p>
last updated: December 4, 2024
</p>

</header>



<div class="bodyandsidetoc">
<div class="sidetoccontainer">



<nav class="sidetoc">



<div class="sidetoctitle">

<p>
<span class="sidetocthetitle">Bayesian Statistics</span>
</p>

<p>
Contents
</p>
</div>



<div class="sidetoccontents">

<p>
<a href="notes.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Introduction.html#autosec-5" class="tocchapter" >
<span class="sectionnumber">0</span>&#x2003;Introduction</a>
</p>



<p>
<a href="Introduction.html#autosec-6" class="tocsection" >
<span class="sectionnumber">0.1</span>&#x2003;Organization</a>
</p>



<p>
<a href="Outline-course.html#autosec-13" class="tocsection" >
<span class="sectionnumber">0.2</span>&#x2003;Outline of the course</a>
</p>



<p>
<a href="Conditioning.html#autosec-15" class="tocchapter" >
<span class="sectionnumber">1</span>&#x2003;Conditioning</a>
</p>



<p>
<a href="Conditioning.html#autosec-16" class="tocsection" >
<span class="sectionnumber">1.1</span>&#x2003;Random variables</a>
</p>



<p>
<a href="Equality-in-distribution.html#autosec-21" class="tocsection" >
<span class="sectionnumber">1.2</span>&#x2003;Equality in distribution</a>
</p>



<p>
<a href="Families-random-variables.html#autosec-31" class="tocsection" >
<span class="sectionnumber">1.3</span>&#x2003;Families of random variables</a>
</p>



<p>
<a href="Conditioning-on-location.html#autosec-35" class="tocsection" >
<span class="sectionnumber">1.4</span>&#x2003;Conditioning on location</a>
</p>



<p>
<a href="Conditioning-correlations.html#autosec-43" class="tocsection" >
<span class="sectionnumber">1.5</span>&#x2003;Conditioning and correlations</a>
</p>



<p>
<a href="Conditioning-on-events-with-zero-probability.html#autosec-50" class="tocsection" >
<span class="sectionnumber">1.6</span>&#x2003;Conditioning on events with zero probability</a>
</p>



<p>
<a href="Families-with-random-parameters.html#autosec-57" class="tocsection" >
<span class="sectionnumber">1.7</span>&#x2003;Families with random parameters</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conditioning.html#autosec-60" class="tocsection" >
<span class="sectionnumber">1.8</span>&#x2003;Exercises on Chapter 1</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-65" class="tocchapter" >
<span class="sectionnumber">2</span>&#x2003;Bayesian models: discrete data</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-66" class="tocsection" >
<span class="sectionnumber">2.1</span>&#x2003;Models with random parameters</a>
</p>



<p>
<a href="Discrete-Bayesian-models.html#autosec-70" class="tocsection" >
<span class="sectionnumber">2.2</span>&#x2003;Discrete Bayesian models</a>
</p>



<p>
<a href="The-posterior-distribution.html#autosec-75" class="tocsection" >
<span class="sectionnumber">2.3</span>&#x2003;The posterior distribution</a>
</p>



<p>
<a href="Bayesian-updates.html#autosec-83" class="tocsection" >
<span class="sectionnumber">2.4</span>&#x2003;Bayesian updates</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_discrete.html#autosec-87" class="tocsection" >
<span class="sectionnumber">2.5</span>&#x2003;Exercises on Chapter 2</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-90" class="tocchapter" >
<span class="sectionnumber">3</span>&#x2003;Bayesian models: continuous data</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-91" class="tocsection" >
<span class="sectionnumber">3.1</span>&#x2003;Continuous Bayesian models</a>
</p>



<p>
<a href="Notation-independent-data.html#autosec-97" class="tocsection" >
<span class="sectionnumber">3.2</span>&#x2003;Notation: independent data</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_continuous.html#autosec-107" class="tocsection" >
<span class="sectionnumber">3.3</span>&#x2003;Exercises on Chapter 3</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-110" class="tocchapter" >
<span class="sectionnumber">4</span>&#x2003;Conjugate priors</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-112" class="tocsection" >
<span class="sectionnumber">4.1</span>&#x2003;Notation: proportionality</a>
</p>



<p>
<a href="Two-more-examples-conjugate-pairs.html#autosec-122" class="tocsection" >
<span class="sectionnumber">4.2</span>&#x2003;Two more examples of conjugate pairs</a>
</p>



<p>
<a href="Conjugate-pairs-exponential-family.html#autosec-132" class="tocsection" >
<span class="sectionnumber">4.3</span>&#x2003;Conjugate pairs and the exponential family \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="What-if.html#autosec-137" class="tocsection" >
<span class="sectionnumber">4.4</span>&#x2003;What if?</a>
</p>



<p>
<a href="The-normal-distribution-with-unknown-mean-variance.html#autosec-150" class="tocsection" >
<span class="sectionnumber">4.5</span>&#x2003;The normal distribution with unknown mean and variance</a>
</p>



<p>
<a href="The-limitations-conjugate-pairs.html#autosec-158" class="tocsection" >
<span class="sectionnumber">4.6</span>&#x2003;The limitations of conjugate pairs</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conjugate_priors.html#autosec-160" class="tocsection" >
<span class="sectionnumber">4.7</span>&#x2003;Exercises on Chapter 4</a>
</p>



<p>
<a href="The-prior.html#autosec-163" class="tocchapter" >
<span class="sectionnumber">5</span>&#x2003;The prior</a>
</p>



<p>
<a href="The-prior.html#autosec-164" class="tocsection" >
<span class="sectionnumber">5.1</span>&#x2003;Elicitation</a>
</p>



<p>
<a href="Uninformative-priors.html#autosec-172" class="tocsection" >
<span class="sectionnumber">5.2</span>&#x2003;Uninformative priors</a>
</p>



<p>
<a href="Reference-priors.html#autosec-179" class="tocsection" >
<span class="sectionnumber">5.3</span>&#x2003;Reference priors</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-prior.html#autosec-185" class="tocsection" >
<span class="sectionnumber">5.4</span>&#x2003;Exercises on Chapter 5</a>
</p>



<p>
<a href="Discussion.html#autosec-188" class="tocchapter" >
<span class="sectionnumber">6</span>&#x2003;Discussion</a>
</p>



<p>
<a href="Discussion.html#autosec-189" class="tocsection" >
<span class="sectionnumber">6.1</span>&#x2003;Bayesian shorthand notation</a>
</p>



<p>
<a href="The-connection-maximum-likelihood.html#autosec-194" class="tocsection" >
<span class="sectionnumber">6.2</span>&#x2003;The connection to maximum likelihood</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-discussion.html#autosec-200" class="tocsection" >
<span class="sectionnumber">6.3</span>&#x2003;Exercises on Chapter 6</a>
</p>



<p>
<a href="Testing-parameter-estimation.html#autosec-203" class="tocchapter" >
<span class="sectionnumber">7</span>&#x2003;Testing and parameter estimation</a>
</p>



<p>
<a href="Testing-parameter-estimation.html#autosec-204" class="tocsection" >
<span class="sectionnumber">7.1</span>&#x2003;Hypothesis testing</a>
</p>



<p>
<a href="High-posterior-density-regions.html#autosec-212" class="tocsection" >
<span class="sectionnumber">7.2</span>&#x2003;High posterior density regions</a>
</p>



<p>
<a href="Point-estimates.html#autosec-221" class="tocsection" >
<span class="sectionnumber">7.3</span>&#x2003;Point estimates</a>
</p>



<p>
<a href="Comparison-classical-methods.html#autosec-226" class="tocsection" >
<span class="sectionnumber">7.4</span>&#x2003;Comparison to classical methods</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-tests.html#autosec-232" class="tocsection" >
<span class="sectionnumber">7.5</span>&#x2003;Exercises on Chapter 7</a>
</p>



<p>
<a href="Computational-methods.html#autosec-235" class="tocchapter" >
<span class="sectionnumber">8</span>&#x2003;Computational methods</a>
</p>



<p>
<a href="Computational-methods.html#autosec-236" class="tocsection" >
<span class="sectionnumber">8.1</span>&#x2003;Approximate Bayesian computation \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="Metropolis-Hastings.html#autosec-239" class="tocsection" >
<span class="sectionnumber">8.2</span>&#x2003;Metropolis-Hastings</a>
</p>



<p>
<a href="Markov-Chain-Monte-Carlo.html#autosec-253" class="tocsection" >
<span class="sectionnumber">8.3</span>&#x2003;Markov Chain Monte Carlo</a>
</p>



<p>
<a href="Gibbs-sampling.html#autosec-258" class="tocsection" >
<span class="sectionnumber">8.4</span>&#x2003;Gibbs sampling</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-computational.html#autosec-265" class="tocsection" >
<span class="sectionnumber">8.5</span>&#x2003;Exercises on Chapter 8</a>
</p>



<p>
<a href="Reference-Sheets.html#autosec-268" class="tocchapter" >
<span class="sectionnumber">A</span>&#x2003;Reference Sheets</a>
</p>



<p>
<a href="Advice-revision-exams.html#autosec-276" class="tocchapter" >
<span class="sectionnumber">B</span>&#x2003;Advice for revision/exams</a>
</p>



<p>
<a href="Solutions-exercises.html#autosec-280" class="tocchapter" >
<span class="sectionnumber">C</span>&#x2003;Solutions to exercises</a>
</p>



</div>

</nav>

</div>



<main class="bodycontainer">



<section class="textbody">

<h1>Bayesian Statistics</h1>

<!--MathJax customizations:-->
<div data-nosnippet
      style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\require {colortbl}\)

\(\let \LWRorigcolumncolor \columncolor \)

\(\renewcommand {\columncolor }[2][named]{\LWRorigcolumncolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigrowcolor \rowcolor \)

\(\renewcommand {\rowcolor }[2][named]{\LWRorigrowcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigcellcolor \cellcolor \)

\(\renewcommand {\cellcolor }[2][named]{\LWRorigcellcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\require {mathtools}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vcentcolon }{\mathrel {\unicode {x2236}}}\)

\(\renewcommand {\intertext }[2][]{\text {#2}\notag \\}\)

\(\newenvironment {fleqn}[1][]{}{}\)

\(\newenvironment {ceqn}{}{}\)

\(\newenvironment {darray}[2][c]{\begin {array}[#1]{#2}}{\end {array}}\)

\(\newcommand {\dmulticolumn }[3]{#3}\)

\(\newcommand {\LWRnrnostar }[1][0.5ex]{\\[#1]}\)

\(\newcommand {\nr }{\ifstar \LWRnrnostar \LWRnrnostar }\)

\(\newcommand {\mrel }[1]{\begin {aligned}#1\end {aligned}}\)

\(\newcommand {\underrel }[2]{\underset {#2}{#1}}\)

\(\newcommand {\medmath }[1]{#1}\)

\(\newcommand {\medop }[1]{#1}\)

\(\newcommand {\medint }[1]{#1}\)

\(\newcommand {\medintcorr }[1]{#1}\)

\(\newcommand {\mfrac }[2]{\frac {#1}{#2}}\)

\(\newcommand {\mbinom }[2]{\binom {#1}{#2}}\)

\(\newenvironment {mmatrix}{\begin {matrix}}{\end {matrix}}\)

\(\newcommand {\displaybreak }[1][]{}\)

\( \def \offsyl {(\oslash )} \def \msconly {(\Delta )} \)

\( \DeclareMathOperator {\var }{var} \DeclareMathOperator {\cov }{cov} \DeclareMathOperator {\Bin }{Bin} \DeclareMathOperator {\Geo }{Geometric} \DeclareMathOperator {\Beta
}{Beta} \DeclareMathOperator {\Unif }{Uniform} \DeclareMathOperator {\Gam }{Gamma} \DeclareMathOperator {\Normal }{N} \DeclareMathOperator {\Exp }{Exp} \DeclareMathOperator
{\Cauchy }{Cauchy} \DeclareMathOperator {\Bern }{Bernoulli} \DeclareMathOperator {\Poisson }{Poisson} \DeclareMathOperator {\Weibull }{Weibull} \DeclareMathOperator {\IGam
}{IGamma} \DeclareMathOperator {\NGam }{NGamma} \DeclareMathOperator {\ChiSquared }{ChiSquared} \DeclareMathOperator {\Pareto }{Pareto} \DeclareMathOperator {\NBin }{NegBin}
\DeclareMathOperator {\Studentt }{Student-t} \DeclareMathOperator *{\argmax }{arg\,max} \DeclareMathOperator *{\argmin }{arg\,min} \)

\( \def \to {\rightarrow } \def \iff {\Leftrightarrow } \def \ra {\Rightarrow } \def \sw {\subseteq } \def \mc {\mathcal } \def \mb {\mathbb } \def \sc {\setminus } \def \wt
{\widetilde } \def \v {\textbf } \def \E {\mb {E}} \def \P {\mb {P}} \def \R {\mb {R}} \def \C {\mb {C}} \def \N {\mb {N}} \def \Q {\mb {Q}} \def \Z {\mb {Z}} \def \B {\mb {B}}
\def \~{\sim } \def \-{\,;\,} \def \qed {$\blacksquare $} \CustomizeMathJax {\def \1{\unicode {x1D7D9}}} \def \cadlag {c\&grave;{a}dl\&grave;{a}g} \def \p {\partial } \def \l
{\left } \def \r {\right } \def \Om {\Omega } \def \om {\omega } \def \eps {\epsilon } \def \de {\delta } \def \ov {\overline } \def \sr {\stackrel } \def \Lp {\mc {L}^p} \def
\Lq {\mc {L}^p} \def \Lone {\mc {L}^1} \def \Ltwo {\mc {L}^2} \def \toae {\sr {\rm a.e.}{\to }} \def \toas {\sr {\rm a.s.}{\to }} \def \top {\sr {\mb {\P }}{\to }} \def \tod {\sr
{\rm d}{\to }} \def \toLp {\sr {\Lp }{\to }} \def \toLq {\sr {\Lq }{\to }} \def \eqae {\sr {\rm a.e.}{=}} \def \eqas {\sr {\rm a.s.}{=}} \def \eqd {\sr {\rm d}{=}} \def \approxd
{\sr {\rm d}{\approx }} \def \Sa {(S1)\xspace } \def \Sb {(S2)\xspace } \def \Sc {(S3)\xspace } \)

</div>

<!--
...... section Reference priors ......
-->
<h4 id="autosec-179"><span class="sectionnumber">5.3&#x2003;</span>Reference priors</h4>
<a id="notes-autopage-179"></a>
<a id="notes-autofile-28"></a>

<a id="s:reference_priors"></a>

<p>
An interesting response to the argument in Section <a href="Uninformative-priors.html#s:prior_philosophy">5.2.1</a> was given by the statistician Harold Jeffreys in 1946. It leads to a particular
suggestion for the choice of prior. Suppose that two different people, Alice and Bob, construct a Bayesian model, with one parameter. Alice uses the model family \((M_\theta )_{\theta \in \Pi }\) and Bob use
the model family \((M_\varphi )_{\varphi \in \Pi }\), where \(\theta \) and \(\varphi \) are related by some function \(h(\theta )=\varphi \), where \(h:\Pi \to \Pi \) with \(\Pi \sw \R \) and
\(h\) is strictly monotone increasing and differentiable. That is, they use the ‘same’ model family, but parametrize it differently.
</p>

<p>
Alice will choose a prior p.d.f.&nbsp;\(f_1\) and Bob will choose a prior p.d.f.&nbsp;\(f_2\). This means that Alice constructs a model with sampling distribution
</p>

<p>
\[f_{X_1}(x)=\int _\Pi f_{M_\theta }(x)f_1(\theta )\,d\theta \]
</p>

<p>
and Bob constructs a model with sampling distribution
</p>

<p>
\[f_{X_2}(x)=\int _\Pi f_{M_{h(\theta )}}(x)f_2(\theta )\,d\theta .\]
</p>

<p>
Alice and Bob have never met each other, and in fact they do not even know that each other exists. Neither of them knows the function \(h\).
</p>

<p>
This is where we come in. We write the statistics textbook, that both Alice and Bob will both read. They will choose their prior based on our instructions – the same instructions, for both people. Can we provide
Alice and Bob with a way to choose their individual priors that will make their models equal i.e.&nbsp;so that \(f_{X_1}(x)=f_{X_2}(x)\)?
</p>
<div class="theorembodyremark">

<ul class="list" style="list-style-type:none">



<a id="autoid-123"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Remark 5.3.1</span></span> <a id="autoid-124" ></a ><a id="r:alice_bob_meet"></a> If Alice and Bob did meet each other, then
Alice could tell Bob what her prior \(\Theta \) was and by comparing notes they could work out the function \(h\). Bob could then choose his prior to be the p.d.f.&nbsp;of \(h(\Theta )\), where \(\Theta \) is
Alice’s prior. This choice makes \(f_{X_1}(x)=f_{X_2}(x)\), see Exercise <a href="Exercises-on-Chapter-ref-c-prior.html#ps:alice_bob_meet"><b>5.7</b></a>.
</p>


</li>

</ul>

</div>

<p>
Returning to the situation where Alice and Bob do not meet, the surprising answer to the problem is: yes, this is possible. The solution is that we should tell them <em>both</em> to use the prior
</p>

<span class="hidden"> \(\seteqnumber{0}{5.}{0}\)</span>

<!--
                                                                         "                  2 #1/2
                                                                               d
                                                             f (θ) ∝ E           log(LMλ (X))                 where (Mλ ) is their chosen model family and X ∼ Mλ .
                                                                              dλ
                                                                                              (5.1)                                                                         --><a id="eq:jeffreys_prior"></a><!--

-->

<p>


\begin{equation}
\label {eq:jeffreys_prior} f(\theta )\propto \E \l [\l (\frac {d}{d\lambda }\log (L_{M_{\lambda }}(X))\r )^2\r ]^{1/2} \quad \text { where }(M_\lambda )\text { is their chosen
model family and }X\sim M_\lambda .
\end{equation}


</p>

<p>
Let us not worry about how Jeffreys found this solution, and let us just show that it really works.
</p>

<p>
<span class="textsc">Proof that the solution works: </span> \(\offsyl \) Alice writes down her prior \(f_1(\theta )\propto \E [(\frac {d}{d\theta }\log (L_{M_{\theta
}}(X)))^2]^{1/2}\) and Bob writes down his prior, \(f_2(\varphi )\propto \E [(\frac {d}{d\varphi }\log (L_{M_{\varphi }}(X)))^2]^{1/2}\). Then Alice’s model is
</p>

<p>
\[f_{X_1}(x) \propto \int _\Pi f_{M_{\theta }}(x)f_1(\theta )\,d\theta . \]
</p>

<p>
Alice doesn’t know the function \(h\), but substituting \(\theta =h(\lambda )\), her model is equal to
</p>
<span class="hidden"> \(\seteqnumber{0}{5.}{1}\)</span>



<!--
                                                                                                          Z
                                                                                            fX1 (x) ∝             fMh(λ) (x)f1 (h(λ))h0 (λ) dλ
                                                                                                          ZΠ
                                                                                                      ∝           fMh(λ) (x)f1 (h(λ))h0 (λ) dλ
                                                                                                          ZΠ
                                                                                                      ∝           fMh(θ) (x)f1 (h(θ))h0 (θ) dθ.
                                                                                                              Π




-->



<p>


\begin{align*}
f_{X_1}(x) \propto \int _\Pi f_{M_{h(\lambda )}}(x)f_1(h(\lambda ))h&apos;(\lambda )\,d\lambda \\ \propto \int _\Pi f_{M_{h(\lambda )}}(x)f_1(h(\lambda ))h&apos;(\lambda
)\,d\lambda \\ \propto \int _\Pi f_{M_{h(\theta )}}(x)f_1(h(\theta ))h&apos;(\theta )\,d\theta .
\end{align*}
In the last line we have simply changed notation by replacing \(\lambda \)s with \(\theta \)s. Meanwhile, Bob’s model is equal to
</p>
<span class="hidden"> \(\seteqnumber{0}{5.}{1}\)</span>



<!--
                                                                                                                   Z
                                                                                                  fX1 (x) ∝             fMh(θ) (x)f2 (θ) dθ.
                                                                                                                    Π




-->



<p>


\begin{align*}
f_{X_1}(x) &amp;\propto \int _\Pi f_{M_{h(\theta )}}(x)f_2(\theta )\,d\theta .
\end{align*}
It follows that \(f_{X_1}(x)=f_{X_2}(x)\) if we have \(f_2(\theta )\propto f_1(h(\theta ))h&apos;(\theta )\). We will now show that this equation holds, for any strictly monotone function \(h\). Bob’s
parameter is \(\varphi =h(\theta )\), so we have
</p>
<span class="hidden"> \(\seteqnumber{0}{5.}{1}\)</span>



<!--
                                                                                                       "                    2 #
                                                                                                               d
                                                                                              2
                                                                                         f2 (θ) ∝ E              log(LMϕ (X))
                                                                                                              dϕ
                                                                                                       "                                  2 #
                                                                                                              d                 dϕ
                                                                                                  ∝E             log(LMϕ (X)) ×
                                                                                                              dθ                dθ
                                                                                                       "                                      2 #
                                                                                                              d
                                                                                                  ∝E             log(LMh(θ) (X)) × h0 (θ)
                                                                                                              dθ

                                                                                                  = f1 (h(θ))2 h0 (θ)2 .



-->



<p>


\begin{align*}
f_2(\theta )^2 &amp;\propto \E \l [\l (\frac {d}{d\varphi }\log (L_{M_{\varphi }}(X))\r )^2\r ] \\ &amp;\propto \E \l [\l (\frac {d}{d\theta }\log (L_{M_{\varphi }}(X))\times
\frac {d\varphi }{d\theta }\r )^2\r ] \\ &amp;\propto \E \l [\l (\frac {d}{d\theta }\log (L_{M_{h(\theta )}}(X))\times h&apos;(\theta )\r )^2\r ] \\ &amp;=f_1(h(\theta
))^2h&apos;(\theta )^2.
\end{align*}
To reach the second line we use the chain rule. Taking square roots, we obtain that \(f_{X_1}(x)=f_{X_2}(x)\) as required. &#x2003;&#x2003;&#x220E;
</p>

<p>
In the earlier half of the 20<sup>th</sup> the argument in Section <a href="Uninformative-priors.html#s:prior_philosophy">5.2.1</a> was taken quite seriously, and treated as a major philosophical reason
to question the reliability of Bayesian statistics. In particular, the objection was that if both Alice and Bob tried to use the same uninformative prior but used models that were parametrized differently then they
would obtain different results, despite having the same intentions and, from their own perspectives, the same methodology. Jeffreys showed that this difficulty could be entirely avoided with a particular choice of
prior.
</p>

<p>
These arguments took place before modern computers, when it was difficult to test how well Bayesian methods worked in practice (except for conjugate priors). We are now better able to test how much different
modelling errors matter. Statisticians today no longer attach much weight to this objection.
</p>

<p>
Starting from the ideas above and those in Remark <a href="Uninformative-priors.html#r:entropy">5.2.2</a>, there is a modern branch of statistics that investigates uninformative priors with particular
theoretical properties. A modern approach is to use a prior that tries to maximise the difference (in some sense) between the prior and posterior distribution, essentially seeking to maximise the influence of the data.
Priors with this property are known as reference priors. Their theory is beyond what we can cover here, but it turns out that if we have only one parameter and we model our data as i.i.d.&nbsp;samples then the
reference prior is the same as the prior proposed by Jeffreys – in more complicated cases, they are different. Let us investigate what the reference prior looks like for some particular choices of one-parameter model.
</p>
<div class="theorembodydefinition">

<ul class="list" style="list-style-type:none">



<a id="autoid-125"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Definition 5.3.2</span></span> <a id="autoid-126" ></a ><a id="d:reference_prior"></a> Suppose that \((M_\theta )\) is a family
of distributions with parameter space \(\Pi \sw \R \). The <em>reference prior</em> \(\Theta \) associated \((M_\theta )\) has density function given by
</p>
<span class="hidden"> \(\seteqnumber{0}{5.}{1}\)</span>



<!--
                                                                                                 "               2 #1/2
                                                                                                    d
                                                                                      fΘ (θ) ∝ E      log(LMθ (X))      (5.2)                              --><a id="eq:reference_prior_d1"></a><!--
                                                                                                   dθ
                                                                                                                   1/2
                                                                                                   d2
                                                                                                 
                                                                                             ∝ E − 2 log(LMθ (X))       (5.3)
                                                                                                                        .                                  --><a id="eq:reference_prior_d2"></a><!--
                                                                                                   dθ



-->



<p>


\begin{align}
f_{\Theta }(\theta ) &amp;\propto \E \l [\l (\frac {d}{d\theta }\log (L_{M_{\theta }}(X))\r )^2\r ]^{1/2} \label {eq:reference_prior_d1} \\ &amp;\propto \E \l [-\frac
{d^2}{d\theta ^2}\log (L_{M_{\theta }}(X))\r ]^{1/2}. \label {eq:reference_prior_d2}
\end{align}
where \(X\sim M_\theta \). Both forms <span class="textup">(<a href="Reference-priors.html#eq:reference_prior_d1">5.2</a>)</span> and <span class="textup">(<a
href="Reference-priors.html#eq:reference_prior_d2">5.3</a>)</span> are included on the reference sheets in Appendix <a href="Reference-Sheets.html#a:reference_sheets">A</a>. Equation <span
class="textup">(<a href="Reference-priors.html#eq:reference_prior_d2">5.3</a>)</span> is often easier to work with because it does not include a \((\cdot )^2\) term.
</p>

<p>
There are some caveats to this definition. The reference prior might be an improper prior, or if the expectation in <span class="textup">(<a
href="Reference-priors.html#eq:reference_prior_d1">5.2</a>)</span>/<span class="textup">(<a href="Reference-priors.html#eq:reference_prior_d2">5.3</a>)</span> is not finite then the
reference prior may not exist.
</p>


</li>

</ul>

</div>
<div class="theorembodyremark">

<ul class="list" style="list-style-type:none">



<a id="autoid-127"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Remark 5.3.3</span></span> <a id="autoid-128" ></a >\(\offsyl \) Equations <span class="textup">(<a
href="Reference-priors.html#eq:reference_prior_d1">5.2</a>)</span> and <span class="textup">(<a href="Reference-priors.html#eq:reference_prior_d2">5.3</a>)</span> are equivalent. To
deduce <span class="textup">(<a href="Reference-priors.html#eq:reference_prior_d2">5.3</a>)</span> from <span class="textup">(<a
href="Reference-priors.html#eq:reference_prior_d1">5.2</a>)</span>, use the partial differentiation identity \(\frac {\partial ^2}{\partial \theta ^2} \log f(x,\theta ) = \frac
{1}{f(x,\theta )}\frac {\partial ^2}{\partial \theta ^2} f(x,\theta ) - \big ( \frac {\partial }{\partial \theta } \log f(x,\theta )\big )^2\) and that \(\E \big [ \frac
{1}{f(X;\theta )}\frac {\partial ^2}{\partial \theta ^2}f(X, \theta ) \, \big | \, \theta \big ] = \frac {\partial ^2}{\partial \theta ^2} \int _{\mathbb {R}} f(x,\theta )\,dx =
0\). We omit the details.
</p>


</li>

</ul>

</div>
<div class="theorembodyexample">

<ul class="list" style="list-style-type:none">



<a id="autoid-129"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Example 5.3.4</span></span> <a id="autoid-130" ></a ><a id="ex:bernoulli_reference_prior"></a> For the Bernoulli model family
\((M_p)_{p\in [0,1]}\) where \(M_p\sim \Bern (p)\), the likelihood is
</p>
<span class="hidden"> \(\seteqnumber{0}{5.}{3}\)</span>



<!--
                                                                           
                                                                           
                                                                           p          for x = 0 and p ∈ [0, 1]       
                                                                                                                                       for p ∈ [0, 1]
                                                                           
                                                                           
                                                                                                                     px (1 − p)1−x
                                                                                                                      
                                                                  LMp (x) = 1 − p      for x = 1 and p ∈ [0, 1] = 
                                                                                                                  0                   otherwise
                                                                           
                                                                           
                                                                                       otherwise
                                                                           
                                                                           
                                                                           0



-->



<p>


\begin{align*}
L_{M_p}(x) \;=\; \begin{cases} p &amp; \text { for }x=0\text { and }p\in [0,1] \\ 1-p &amp; \text { for }x=1\text { and }p\in [0,1] \\ 0 &amp; \text { otherwise} \end {cases}
\;=\; \begin{cases} p^x(1-p)^{1-x} &amp; \text { for }p\in [0,1] \\ 0 &amp; \text { otherwise} \end {cases}
\end{align*}
for \(x\in \{0,1\}\). For the non-zero case, \(\frac {d}{dp}\log (L_{M_p}(x))=\frac {d}{dp}(x\log p + (1-x)\log (1-p))=\frac {x}{p}-\frac {1-x}{1-p}\) and so
</p>

<p>
\[\frac {d^2}{dp^2}\log (L_{M_p})(x)=\frac {-p}{x^2}-\frac {1-x}{(1-p)^2}.\]
</p>

<p>
Hence, from <span class="textup">(<a href="Reference-priors.html#eq:reference_prior_d2">5.3</a>)</span>, for \(p\in [0,1]\) the density function of the reference prior \(P\) is given by
</p>
<span class="hidden"> \(\seteqnumber{0}{5.}{3}\)</span>



<!--
                                                                                                                         1/2
                                                                                                        d2
                                                                                                   
                                                                                        fP (p) ∝ E − 2 log(LMp (X))
                                                                                                       dp
                                                                                                             1 − X 1/2
                                                                                                                   
                                                                                                     X
                                                                                               ∝E 2 +
                                                                                                     p     (1 − p)2
                                                                                                   E[X] 1 − E[X] 1/2
                                                                                                                      
                                                                                               ∝          +
                                                                                                     p2       (1 − p)2
                                                                                                           1 − p 1/2
                                                                                                                  
                                                                                                   p
                                                                                               ∝       +
                                                                                                   p2 (1 − p)2
                                                                                                              1/2
                                                                                                   1       1
                                                                                               ∝     +
                                                                                                   p 1−p
                                                                                              ∝ p−1/2 (1 − p)−1/2 .



-->



<p>


\begin{align*}
f_P(p) &amp;\propto \E \l [-\frac {d^2}{dp^2}\log (L_{M_{p}}(X))\r ]^{1/2} \\ &amp;\propto \E \l [\frac {X}{p^2}+\frac {1-X}{(1-p)^2}\r ]^{1/2} \\ &amp;\propto \l (\frac {\E
[X]}{p^2}+\frac {1-\E [X]}{(1-p)^2}\r )^{1/2} \\ &amp;\propto \l (\frac {p}{p^2}+\frac {1-p}{(1-p)^2}\r )^{1/2} \\ &amp;\propto \l (\frac {1}{p}+\frac {1}{1-p}\r )^{1/2} \\
&amp;\propto p^{-1/2}(1-p)^{-1/2}.
\end{align*}
Using Lemma <a href="Equality-in-distribution.html#l:eqd_pmf_pdf_ignore_consts">1.2.5</a> we recognize that \(P\sim \Beta (\frac 12,\frac 12)\).
</p>


</li>

</ul>

</div>

<p>
A useful fact is that the reference prior for \(M_\theta \) and \(M_\theta ^{\otimes n}\) are identical, in the sense that they are \(\propto \) to each other. This is shown in Exercise <a
href="Exercises-on-Chapter-ref-c-prior.html#ps:reference_prior_otimes"><b>5.8</b></a>.
</p>

</section>

</main>

</div>

<footer>

<p>
Copyright Nic Freeman, Sheffield University, last updated December 4, 2024
</p>

</footer>



<nav class="botnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

</body>
</html>
