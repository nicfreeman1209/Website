<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Nic Freeman" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="MAS364/61006 Bayesian Statistics, Sheffield University, November 27, 2024." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>MAS364/61006 â€” The posterior distribution</title>
<link rel="stylesheet" type="text/css" href="sans-serif-lwarp-sagebrush.css" />
<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
// \left, \right delimiters: https://github.com/mathjax/MathJax/issues/2535
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
  subequations: "0",
  section: "",
  loader: {
    load: ['[tex]/tagformat', '[tex]/textmacros'],
  },
  startup: {
    ready() {
      // These would be replaced by import commands if you wanted to make
      // a proper extension.
      const Configuration = MathJax._.input.tex.Configuration.Configuration;
      const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
      const Macro = MathJax._.input.tex.Symbol.Macro;
      const TexError = MathJax._.input.tex.TexError.default;
      const ParseUtil = MathJax._.input.tex.ParseUtil.default;
      const expandable = MathJax._.util.Options.expandable;

       // Insert the replacement string into the TeX string, and check
       // that there haven't been too many maxro substitutions (prevents
       // infinite loops).
       const useArgument = (parser, text) => {
         parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
         parser.i = 0;
         if (++parser.macroCount > parser.configuration.options.maxMacros) {
           throw new TexError('MaxMacroSub1',
           'MathJax maximum macro substitution count exceeded; ' +
           'is there a recursive macro call?');
         }
       }

       // Create the command map for:
       //     \ifstar, \ifnextchar, \ifblank, \ifstrequal, \gsub, \seteqnumber
       new CommandMap('Lwarp-macros', {
         ifstar: 'IfstarFunction',
         ifnextchar: 'IfnextcharFunction',
         ifblank: 'IfblankFunction',
         ifstrequal: 'IfstrequalFunction',
         gsubstitute: 'GsubstituteFunction',
         seteqnumber: 'SeteqnumberFunction'
       }, {
         // This function implements an ifstar macro.
         IfstarFunction(parser, name) {
            const resultstar = parser.GetArgument(name);
            const resultnostar = parser.GetArgument(name);
            const star = parser.GetStar();                 // true if there is a *
            useArgument(parser, star ? resultstar : resultnostar);
         },

         // This function implements an ifnextchar macro.
         IfnextcharFunction(parser, name) {
           let whichchar = parser.GetArgument(name);
           if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
             // $ syntax highlighting
             whichchar = String.fromCodePoint(parseInt(whichchar));
           }
           const resultnextchar = parser.GetArgument(name);
           const resultnotnextchar = parser.GetArgument(name);
           const gotchar = (parser.GetNext() === whichchar);
           useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
         },

         // This function implements an ifblank macro.
         IfblankFunction(parser, name) {
           const blankarg = parser.GetArgument(name);
           const resultblank = parser.GetArgument(name);
           const resultnotblank = parser.GetArgument(name);
           const isblank = (blankarg.trim() == "");
           useArgument(parser, isblank ? resultblank : resultnotblank);
         },

         // This function implements an ifstrequal macro.
         IfstrequalFunction(parser, name) {
           const strequalfirst = parser.GetArgument(name);
           const strequalsecond = parser.GetArgument(name);
           const resultequal = parser.GetArgument(name);
           const resultnotequal = parser.GetArgument(name);
           const isequal = (strequalfirst == strequalsecond);
           useArgument(parser, isequal ? resultequal : resultnotequal);
         },

         // This function implements a gsub macro.
         GsubstituteFunction(parser, name) {
           const gsubfirst = parser.GetArgument(name);
           const gsubsecond = parser.GetArgument(name);
           const gsubthird = parser.GetArgument(name);
           let gsubresult=gsubfirst.replace(gsubsecond, gsubthird);
           useArgument(parser, gsubresult);
         },

         // This function modifies the equation numbers.
         SeteqnumberFunction(parser, name) {
             // Get the macro parameters
             const star = parser.GetStar();                  // true if there is a *
             const optBrackets = parser.GetBrackets(name);   // contents of optional brackets
             const newsubequations = parser.GetArgument(name); // the subequations argument
             const neweqsection = parser.GetArgument(name); // the eq section argument
             const neweqnumber = parser.GetArgument(name);   // the eq number argument
             MathJax.config.subequations=newsubequations ;   // a string with boolean meaning
             MathJax.config.section=neweqsection ;           // a string with numeric meaning
             parser.tags.counter = parser.tags.allCounter = neweqnumber ;
         }

       });

       // Create the Lwarp-macros package
       Configuration.create('Lwarp-macros', {
         handler: {macro: ['Lwarp-macros']}
       });

       MathJax.startup.defaultReady();

       // For forward references:
       MathJax.startup.input[0].preFilters.add(({math}) => {
         if (math.inputData.recompile){
             MathJax.config.subequations = math.inputData.recompile.subequations;
             MathJax.config.section = math.inputData.recompile.section;
         }
       });
       MathJax.startup.input[0].postFilters.add(({math}) => {
         if (math.inputData.recompile){
             math.inputData.recompile.subequations = MathJax.config.subequations;
             math.inputData.recompile.section = MathJax.config.section;
         }
       });

         // For \left, \right with unicode-math:
         const {DelimiterMap} = MathJax._.input.tex.SymbolMap;
         const {Symbol} = MathJax._.input.tex.Symbol;
         const {MapHandler} = MathJax._.input.tex.MapHandler;
         const delimiter = MapHandler.getMap('delimiter');
         delimiter.add('\\lBrack', new Symbol('\\lBrack', '\u27E6'));
         delimiter.add('\\rBrack', new Symbol('\\rBrack', '\u27E7'));
         delimiter.add('\\lAngle', new Symbol('\\lAngle', '\u27EA'));
         delimiter.add('\\rAngle', new Symbol('\\rAngle', '\u27EB'));
         delimiter.add('\\lbrbrak', new Symbol('\\lbrbrak', '\u2772'));
         delimiter.add('\\rbrbrak', new Symbol('\\rbrbrak', '\u2773'));
         delimiter.add('\\lbag', new Symbol('\\lbag', '\u27C5'));
         delimiter.add('\\rbag', new Symbol('\\rbag', '\u27C6'));
         delimiter.add('\\llparenthesis', new Symbol('\\llparenthesis', '\u2987'));
         delimiter.add('\\rrparenthesis', new Symbol('\\rrparenthesis', '\u2988'));
         delimiter.add('\\llangle', new Symbol('\\llangle', '\u2989'));
         delimiter.add('\\rrangle', new Symbol('\\rrangle', '\u298A'));
         delimiter.add('\\Lbrbrak', new Symbol('\\Lbrbrak', '\u27EC'));
         delimiter.add('\\Rbrbrak', new Symbol('\\Rbrbrak', '\u27ED'));
         delimiter.add('\\lBrace', new Symbol('\\lBrace', '\u2983'));
         delimiter.add('\\rBrace', new Symbol('\\rBrace', '\u2984'));
         delimiter.add('\\lParen', new Symbol('\\lParen', '\u2985'));
         delimiter.add('\\rParen', new Symbol('\\rParen', '\u2986'));
         delimiter.add('\\lbrackubar', new Symbol('\\lbrackubar', '\u298B'));
         delimiter.add('\\rbrackubar', new Symbol('\\rbrackubar', '\u298C'));
         delimiter.add('\\lbrackultick', new Symbol('\\lbrackultick', '\u298D'));
         delimiter.add('\\rbracklrtick', new Symbol('\\rbracklrtick', '\u298E'));
         delimiter.add('\\lbracklltick', new Symbol('\\lbracklltick', '\u298F'));
         delimiter.add('\\rbrackurtick', new Symbol('\\rbrackurtick', '\u2990'));
         delimiter.add('\\langledot', new Symbol('\\langledot', '\u2991'));
         delimiter.add('\\rangledot', new Symbol('\\rangledot', '\u2992'));
         delimiter.add('\\lparenless', new Symbol('\\lparenless', '\u2993'));
         delimiter.add('\\rparengtr', new Symbol('\\rparengtr', '\u2994'));
         delimiter.add('\\Lparengtr', new Symbol('\\Lparengtr', '\u2995'));
         delimiter.add('\\Rparenless', new Symbol('\\Rparenless', '\u2996'));
         delimiter.add('\\lblkbrbrak', new Symbol('\\lblkbrbrak', '\u2997'));
         delimiter.add('\\rblkbrbrak', new Symbol('\\rblkbrbrak', '\u2998'));
         delimiter.add('\\lvzigzag', new Symbol('\\lvzigzag', '\u29D8'));
         delimiter.add('\\rvzigzag', new Symbol('\\rvzigzag', '\u29D9'));
         delimiter.add('\\Lvzigzag', new Symbol('\\Lvzigzag', '\u29DA'));
         delimiter.add('\\Rvzigzag', new Symbol('\\Rvzigzag', '\u29DB'));
         delimiter.add('\\lcurvyangle', new Symbol('\\lcurvyangle', '\u29FC'));
         delimiter.add('\\rcurvyangle', new Symbol('\\rcurvyangle', '\u29FD'));
         delimiter.add('\\Vvert', new Symbol('\\Vvert', '\u2980'));
   }     // ready
 },      // startup

 tex: {
   packages: {'[+]': ['tagformat', 'Lwarp-macros', 'textmacros']},
   tags: "ams",
        tagformat: {
            number: function (n) {
                if(MathJax.config.subequations==0)
                    return(MathJax.config.section + n);
                else
                    return(MathJax.config.section + String.fromCharCode(96+n));
            },
        },
 }
}
</script>

<script
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4222H8D03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4222H8D03');
</script>
<!-- Google tag (gtag.js) -->


</head>
<body>



<a id="notes-autopage-74"></a>
<nav class="topnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

<header>

<p>
last updated: November 27, 2024
</p>

</header>



<div class="bodyandsidetoc">
<div class="sidetoccontainer">



<nav class="sidetoc">



<div class="sidetoctitle">

<p>
<span class="sidetocthetitle">Bayesian Statistics</span>
</p>

<p>
Contents
</p>
</div>



<div class="sidetoccontents">

<p>
<a href="notes.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Introduction.html#autosec-5" class="tocchapter" >
<span class="sectionnumber">0</span>&#x2003;Introduction</a>
</p>



<p>
<a href="Introduction.html#autosec-6" class="tocsection" >
<span class="sectionnumber">0.1</span>&#x2003;Organization</a>
</p>



<p>
<a href="Outline-course.html#autosec-13" class="tocsection" >
<span class="sectionnumber">0.2</span>&#x2003;Outline of the course</a>
</p>



<p>
<a href="Conditioning.html#autosec-15" class="tocchapter" >
<span class="sectionnumber">1</span>&#x2003;Conditioning</a>
</p>



<p>
<a href="Conditioning.html#autosec-16" class="tocsection" >
<span class="sectionnumber">1.1</span>&#x2003;Random variables</a>
</p>



<p>
<a href="Equality-in-distribution.html#autosec-21" class="tocsection" >
<span class="sectionnumber">1.2</span>&#x2003;Equality in distribution</a>
</p>



<p>
<a href="Families-random-variables.html#autosec-31" class="tocsection" >
<span class="sectionnumber">1.3</span>&#x2003;Families of random variables</a>
</p>



<p>
<a href="Conditioning-on-location.html#autosec-35" class="tocsection" >
<span class="sectionnumber">1.4</span>&#x2003;Conditioning on location</a>
</p>



<p>
<a href="Conditioning-correlations.html#autosec-43" class="tocsection" >
<span class="sectionnumber">1.5</span>&#x2003;Conditioning and correlations</a>
</p>



<p>
<a href="Conditioning-on-events-with-zero-probability.html#autosec-50" class="tocsection" >
<span class="sectionnumber">1.6</span>&#x2003;Conditioning on events with zero probability</a>
</p>



<p>
<a href="Families-with-random-parameters.html#autosec-57" class="tocsection" >
<span class="sectionnumber">1.7</span>&#x2003;Families with random parameters</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conditioning.html#autosec-60" class="tocsection" >
<span class="sectionnumber">1.8</span>&#x2003;Exercises on Chapter 1</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-65" class="tocchapter" >
<span class="sectionnumber">2</span>&#x2003;Bayesian models: discrete data</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-66" class="tocsection" >
<span class="sectionnumber">2.1</span>&#x2003;Models with random parameters</a>
</p>



<p>
<a href="Discrete-Bayesian-models.html#autosec-70" class="tocsection" >
<span class="sectionnumber">2.2</span>&#x2003;Discrete Bayesian models</a>
</p>



<p>
<a href="The-posterior-distribution.html#autosec-75" class="tocsection" >
<span class="sectionnumber">2.3</span>&#x2003;The posterior distribution</a>
</p>



<p>
<a href="Bayesian-updates.html#autosec-83" class="tocsection" >
<span class="sectionnumber">2.4</span>&#x2003;Bayesian updates</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_discrete.html#autosec-87" class="tocsection" >
<span class="sectionnumber">2.5</span>&#x2003;Exercises on Chapter 2</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-90" class="tocchapter" >
<span class="sectionnumber">3</span>&#x2003;Bayesian models: continuous data</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-91" class="tocsection" >
<span class="sectionnumber">3.1</span>&#x2003;Continuous Bayesian models</a>
</p>



<p>
<a href="Notation-independent-data.html#autosec-97" class="tocsection" >
<span class="sectionnumber">3.2</span>&#x2003;Notation: independent data</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_continuous.html#autosec-107" class="tocsection" >
<span class="sectionnumber">3.3</span>&#x2003;Exercises on Chapter 3</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-110" class="tocchapter" >
<span class="sectionnumber">4</span>&#x2003;Conjugate priors</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-112" class="tocsection" >
<span class="sectionnumber">4.1</span>&#x2003;Notation: proportionality</a>
</p>



<p>
<a href="Two-more-examples-conjugate-pairs.html#autosec-122" class="tocsection" >
<span class="sectionnumber">4.2</span>&#x2003;Two more examples of conjugate pairs</a>
</p>



<p>
<a href="Conjugate-pairs-exponential-family.html#autosec-132" class="tocsection" >
<span class="sectionnumber">4.3</span>&#x2003;Conjugate pairs and the exponential family \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="What-if.html#autosec-137" class="tocsection" >
<span class="sectionnumber">4.4</span>&#x2003;What if?</a>
</p>



<p>
<a href="The-normal-distribution-with-unknown-mean-variance.html#autosec-150" class="tocsection" >
<span class="sectionnumber">4.5</span>&#x2003;The normal distribution with unknown mean and variance</a>
</p>



<p>
<a href="The-limitations-conjugate-pairs.html#autosec-158" class="tocsection" >
<span class="sectionnumber">4.6</span>&#x2003;The limitations of conjugate pairs</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conjugate_priors.html#autosec-160" class="tocsection" >
<span class="sectionnumber">4.7</span>&#x2003;Exercises on Chapter 4</a>
</p>



<p>
<a href="The-prior.html#autosec-163" class="tocchapter" >
<span class="sectionnumber">5</span>&#x2003;The prior</a>
</p>



<p>
<a href="The-prior.html#autosec-164" class="tocsection" >
<span class="sectionnumber">5.1</span>&#x2003;Elicitation</a>
</p>



<p>
<a href="Uninformative-priors.html#autosec-172" class="tocsection" >
<span class="sectionnumber">5.2</span>&#x2003;Uninformative priors</a>
</p>



<p>
<a href="Reference-priors.html#autosec-179" class="tocsection" >
<span class="sectionnumber">5.3</span>&#x2003;Reference priors</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-prior.html#autosec-185" class="tocsection" >
<span class="sectionnumber">5.4</span>&#x2003;Exercises on Chapter 5</a>
</p>



<p>
<a href="Discussion.html#autosec-188" class="tocchapter" >
<span class="sectionnumber">6</span>&#x2003;Discussion</a>
</p>



<p>
<a href="Discussion.html#autosec-189" class="tocsection" >
<span class="sectionnumber">6.1</span>&#x2003;Bayesian shorthand notation</a>
</p>



<p>
<a href="The-connection-maximum-likelihood.html#autosec-194" class="tocsection" >
<span class="sectionnumber">6.2</span>&#x2003;The connection to maximum likelihood</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-discussion.html#autosec-200" class="tocsection" >
<span class="sectionnumber">6.3</span>&#x2003;Exercises on Chapter 6</a>
</p>



<p>
<a href="Testing-parameter-estimation.html#autosec-203" class="tocchapter" >
<span class="sectionnumber">7</span>&#x2003;Testing and parameter estimation</a>
</p>



<p>
<a href="Testing-parameter-estimation.html#autosec-204" class="tocsection" >
<span class="sectionnumber">7.1</span>&#x2003;Hypothesis testing</a>
</p>



<p>
<a href="High-posterior-density-regions.html#autosec-212" class="tocsection" >
<span class="sectionnumber">7.2</span>&#x2003;High posterior density regions</a>
</p>



<p>
<a href="Point-estimates.html#autosec-221" class="tocsection" >
<span class="sectionnumber">7.3</span>&#x2003;Point estimates</a>
</p>



<p>
<a href="Comparison-classical-methods.html#autosec-226" class="tocsection" >
<span class="sectionnumber">7.4</span>&#x2003;Comparison to classical methods</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-tests.html#autosec-232" class="tocsection" >
<span class="sectionnumber">7.5</span>&#x2003;Exercises on Chapter 7</a>
</p>



<p>
<a href="Computational-methods.html#autosec-235" class="tocchapter" >
<span class="sectionnumber">8</span>&#x2003;Computational methods</a>
</p>



<p>
<a href="Computational-methods.html#autosec-236" class="tocsection" >
<span class="sectionnumber">8.1</span>&#x2003;Approximate Bayesian computation \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="Metropolis-Hastings.html#autosec-239" class="tocsection" >
<span class="sectionnumber">8.2</span>&#x2003;Metropolis-Hastings</a>
</p>



<p>
<a href="Markov-Chain-Monte-Carlo.html#autosec-253" class="tocsection" >
<span class="sectionnumber">8.3</span>&#x2003;Markov Chain Monte Carlo</a>
</p>



<p>
<a href="Gibbs-sampling.html#autosec-258" class="tocsection" >
<span class="sectionnumber">8.4</span>&#x2003;Gibbs sampling</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-computational.html#autosec-265" class="tocsection" >
<span class="sectionnumber">8.5</span>&#x2003;Exercises on Chapter 8</a>
</p>



<p>
<a href="Reference-Sheets.html#autosec-268" class="tocchapter" >
<span class="sectionnumber">A</span>&#x2003;Reference Sheets</a>
</p>



<p>
<a href="Advice-revision-exams.html#autosec-276" class="tocchapter" >
<span class="sectionnumber">B</span>&#x2003;Advice for revision/exams</a>
</p>



<p>
<a href="Solutions-exercises.html#autosec-280" class="tocchapter" >
<span class="sectionnumber">C</span>&#x2003;Solutions to exercises</a>
</p>



</div>

</nav>

</div>



<main class="bodycontainer">



<section class="textbody">

<h1>Bayesian Statistics</h1>

<!--MathJax customizations:-->
<div data-nosnippet
      style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\require {colortbl}\)

\(\let \LWRorigcolumncolor \columncolor \)

\(\renewcommand {\columncolor }[2][named]{\LWRorigcolumncolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigrowcolor \rowcolor \)

\(\renewcommand {\rowcolor }[2][named]{\LWRorigrowcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigcellcolor \cellcolor \)

\(\renewcommand {\cellcolor }[2][named]{\LWRorigcellcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\require {mathtools}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vcentcolon }{\mathrel {\unicode {x2236}}}\)

\(\renewcommand {\intertext }[2][]{\text {#2}\notag \\}\)

\(\newenvironment {fleqn}[1][]{}{}\)

\(\newenvironment {ceqn}{}{}\)

\(\newenvironment {darray}[2][c]{\begin {array}[#1]{#2}}{\end {array}}\)

\(\newcommand {\dmulticolumn }[3]{#3}\)

\(\newcommand {\LWRnrnostar }[1][0.5ex]{\\[#1]}\)

\(\newcommand {\nr }{\ifstar \LWRnrnostar \LWRnrnostar }\)

\(\newcommand {\mrel }[1]{\begin {aligned}#1\end {aligned}}\)

\(\newcommand {\underrel }[2]{\underset {#2}{#1}}\)

\(\newcommand {\medmath }[1]{#1}\)

\(\newcommand {\medop }[1]{#1}\)

\(\newcommand {\medint }[1]{#1}\)

\(\newcommand {\medintcorr }[1]{#1}\)

\(\newcommand {\mfrac }[2]{\frac {#1}{#2}}\)

\(\newcommand {\mbinom }[2]{\binom {#1}{#2}}\)

\(\newenvironment {mmatrix}{\begin {matrix}}{\end {matrix}}\)

\(\newcommand {\displaybreak }[1][]{}\)

\( \def \offsyl {(\oslash )} \def \msconly {(\Delta )} \)

\( \DeclareMathOperator {\var }{var} \DeclareMathOperator {\cov }{cov} \DeclareMathOperator {\Bin }{Bin} \DeclareMathOperator {\Geo }{Geometric} \DeclareMathOperator {\Beta
}{Beta} \DeclareMathOperator {\Unif }{Uniform} \DeclareMathOperator {\Gam }{Gamma} \DeclareMathOperator {\Normal }{N} \DeclareMathOperator {\Exp }{Exp} \DeclareMathOperator
{\Cauchy }{Cauchy} \DeclareMathOperator {\Bern }{Bernoulli} \DeclareMathOperator {\Poisson }{Poisson} \DeclareMathOperator {\Weibull }{Weibull} \DeclareMathOperator {\IGam
}{IGamma} \DeclareMathOperator {\NGam }{NGamma} \DeclareMathOperator {\ChiSquared }{ChiSquared} \DeclareMathOperator {\Pareto }{Pareto} \DeclareMathOperator {\NBin }{NegBin}
\DeclareMathOperator {\Studentt }{Student-t} \DeclareMathOperator *{\argmax }{arg\,max} \DeclareMathOperator *{\argmin }{arg\,min} \)

\( \def \to {\rightarrow } \def \iff {\Leftrightarrow } \def \ra {\Rightarrow } \def \sw {\subseteq } \def \mc {\mathcal } \def \mb {\mathbb } \def \sc {\setminus } \def \wt
{\widetilde } \def \v {\textbf } \def \E {\mb {E}} \def \P {\mb {P}} \def \R {\mb {R}} \def \C {\mb {C}} \def \N {\mb {N}} \def \Q {\mb {Q}} \def \Z {\mb {Z}} \def \B {\mb {B}}
\def \~{\sim } \def \-{\,;\,} \def \qed {$\blacksquare $} \CustomizeMathJax {\def \1{\unicode {x1D7D9}}} \def \cadlag {c\&grave;{a}dl\&grave;{a}g} \def \p {\partial } \def \l
{\left } \def \r {\right } \def \Om {\Omega } \def \om {\omega } \def \eps {\epsilon } \def \de {\delta } \def \ov {\overline } \def \sr {\stackrel } \def \Lp {\mc {L}^p} \def
\Lq {\mc {L}^p} \def \Lone {\mc {L}^1} \def \Ltwo {\mc {L}^2} \def \toae {\sr {\rm a.e.}{\to }} \def \toas {\sr {\rm a.s.}{\to }} \def \top {\sr {\mb {\P }}{\to }} \def \tod {\sr
{\rm d}{\to }} \def \toLp {\sr {\Lp }{\to }} \def \toLq {\sr {\Lq }{\to }} \def \eqae {\sr {\rm a.e.}{=}} \def \eqas {\sr {\rm a.s.}{=}} \def \eqd {\sr {\rm d}{=}} \def \approxd
{\sr {\rm d}{\approx }} \def \Sa {(S1)\xspace } \def \Sb {(S2)\xspace } \def \Sc {(S3)\xspace } \)

</div>

<!--
...... section The posterior distribution ......
-->
<h4 id="autosec-75"><span class="sectionnumber">2.3&#x2003;</span>The posterior distribution</h4>
<a id="notes-autopage-75"></a>
<a id="notes-autofile-13"></a>

<a id="s:bayes_discrete_posterior"></a>

<p>
There is one more important piece of terminology associated to \((X,\Theta )\).
</p>
<div class="theorembodydefinition">

<ul class="list" style="list-style-type:none">



<a id="autoid-51"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Definition 2.3.1</span></span> <a id="autoid-52" ></a ><a id="d:posterior_discrete"></a> Let \((X,\Theta )\) be a discrete
Bayesian model. For \(x\) such that \(\P [X=x]&gt;0\), the random variable \(\Theta |_{\{X=x\}}\) is known as the <em>posterior</em> of the model, and its distribution is known as the posterior distribution.
</p>


</li>

</ul>

</div>

<p>
It will take a bit of work to understand why \(\Theta |_{\{X=x\}}\) is important. Recall the prior \(\Theta \) is a random variable. The distribution of \(\Theta \), which we usually specify via its
p.d.f.&nbsp;\(f_\Theta (\theta )\), is chosen based on our initial beliefs about where the true value of the unknown parameter \(\theta \) might be. We then obtain some data \(x\), coming from reality. The
key idea is that \(\Theta |_{\{X=x\}}\) will often be a better choice for the distribution of \(\theta \) than our original choice \(\Theta \) was. This is because \(\Theta |_{\{X=x\}}\) incorporates
information from the data that we have. We can summarise this idea as:
</p>

<span class="hidden"> \(\seteqnumber{0}{2.}{6}\)</span>

<!--

               (model parameters)|{model = the data we have} = (better model parameters).           (2.7)                                                            --><a id="eq:bayes_heuristic"></a><!--

-->

<p>


\begin{equation}
\label {eq:bayes_heuristic} \text {(model parameters)}|_{\{\text {model }=\text { the data we have}\}} =\text {(better model parameters)}.
\end{equation}


</p>

<p>
Here \(|_{\{\ldots \}}\) denotes conditioning. We will use the theory that we developed in Chapter <a href="Conditioning.html#c:conditioning">1</a> to make sense of <span class="textup">(<a
href="The-posterior-distribution.html#eq:bayes_heuristic">2.7</a>)</span>.
</p>

<p>
The â€˜updateâ€™ of \(\Theta \) to \(\Theta |_{\{X=x\}}\) is known as a <em>Bayesian update</em>, and the whole process is known as <em>Bayesian learning</em>. The terms â€˜priorâ€™ and â€˜posteriorâ€™ are loose
synonyms for â€˜beforeâ€™ and â€˜afterâ€™, which is why they are used in Bayesian models.
</p>

<p>
All elements of the discrete family \((M_\theta )\) have the same range \(R\), so \(\P [M_\theta =x]&gt;0\) for all \(x\in R\). It follows that the range of \(\Theta |_{\{X=x\}}\) is the same as the range of
\(\Theta \). Checking carefully against the two ingredients at the top of Section <a href="Discrete-Bayesian-models.html#s:bayes_models_discrete">2.2</a>, this means that we can form a new discrete
Bayesian model, with the same family \((M_\theta )\), the same parameter space \(\Pi \), the same range \(R\) but with a new prior given by the probability density function \(f_{\Theta |_{\{X=x\}}}\).
</p>

<p>
With our updated prior, we might want to use our new model to sample data (for whatever purpose). For this we use the sampling p.d.f.&nbsp;<span class="textup">(<a
href="Discrete-Bayesian-models.html#eq:bayes_discrete_general_X_pmf">2.4</a>)</span>, but now applied to the model with prior \(f_{\Theta |_{\{X=x\}}}\). There is a special piece of terminology
for this:
</p>
<div class="theorembodydefinition">

<ul class="list" style="list-style-type:none">



<a id="autoid-53"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Definition 2.3.2</span></span> <a id="autoid-54" ></a >Let \((X,\Theta )\) be a discrete Bayesian model, with parameter space \(\Pi
\) and model family \((M_\theta )_{\theta \in \Pi }\). Let \(x\) be an item of data. The <em>predictive distribution</em> is the distribution of \(X&apos;\) where
</p>

<span class="hidden"> \(\seteqnumber{0}{2.}{7}\)</span>

<!--
                                 Z
                       0    0
                   P[X = x ] =        P[MÎ¸ = x0 ]fÎ˜|{X=x} (Î¸) dÎ¸.              (2.8)                                                          --><a id="eq:bayes_discrete_general_pred_pmf"></a><!--
                                 Rd

-->

<p>


\begin{equation}
\label {eq:bayes_discrete_general_pred_pmf} \P [X&apos;=x&apos;]=\int _{\R ^d}\P [M_\theta =x&apos;]f_{\Theta |_{\{X=x\}}}(\theta )\,d\theta .
\end{equation}


</p>

<p>
Here, \(X&apos;\) has the same range as \(X\).
</p>


</li>

</ul>

</div>
<div class="theorembodyexample">

<ul class="list" style="list-style-type:none">



<a id="autoid-55"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Example 2.3.3</span></span> <a id="autoid-56" ></a ><a id="ex:baby_bayes_part3"></a> Let us take the model from Example <a
href="Bayesian-models-discrete-data.html#ex:baby_bayes">2.1.1</a>. We noted in Example <a href="Discrete-Bayesian-models.html#ex:baby_bayes_part2">2.2.2</a> that this model was a discrete
Bayesian model. Recall that our model was intended to model the number of successes from a set of 10 independent but identical experiments, where each experiment has an unknown probability \(p\) of success.
</p>

<p>
The model family we used is \(M_p=\Bin (10,p)\), with only one parameter \(p\), so we take \(\theta =p\). The range of this family is \(R=\{0,1,\ldots ,10\}\). The parameter space is \(\Pi =[0,1]\), and
our prior was \(\Theta =P\sim \Beta (2,8)\), which has p.d.f.&nbsp;\(f_P(p)\) that we sketched in Example <a href="Bayesian-models-discrete-data.html#ex:baby_bayes">2.1.1</a>.
</p>

<p>
Suppose that we learn that a scientist has carried out the \(10\) experiments, and obtained \(x=4\) successes. We can use Lemma <a href="Conditioning-correlations.html#l:cond_corr">1.5.1</a> to
compute the posterior \(P|_{\{X=4\}}\), as follows. For \(B\sw \R \),
</p>
<span class="hidden"> \(\seteqnumber{0}{2.}{8}\)</span>



<!--

                                                                                              P[X = 4, P âˆˆ B]
                                                                                P P |{X=4} âˆˆ B =
                                                                                                      P[X = 4]
                                                                                                     10 R
                                                                                                 72 4 Bâˆ©[0,1] p1+4 (1 âˆ’ p)17âˆ’4 dp
                                                                                                       
                                                                                               =        (2.9)                                                  --><a id="eq:baby_bayes_inf_step"></a><!--
                                                                                                   72 10
                                                                                                         R
                                                                                                                    1+4 (1 âˆ’ p)17âˆ’4 dp
                                                                                                       4    [0,1] p
                                                                                                            5          13
                                                                                                 R
                                                                                                   Bâˆ©[0,1] p (1 âˆ’ p) dp
                                                                                               =
                                                                                                         B(6, 14)
                                                                                                 Z
                                                                                                               1
                                                                                               =                      p5 (1 âˆ’ p)13 dp
                                                                                                  Bâˆ©[0,1]  B(6,  14)
                                                                                                 Z
                                                                                               =    f(2.10)
                                                                                                      Beta(6,14) (p) dp                                      --><a id="eq:baby_bayes_posterior"></a><!--
                                                                                                     B




-->



<p>


\begin{align}
\P \l [P|_{\{X=4\}}\in B\r ] &amp;=\frac {\P [X=4, P\in B]}{\P [X=4]} \notag \\ &amp;=\frac {72\binom {10}{4}\int _{B\cap [0,1]}p^{1+4}(1-p)^{17-4}\,dp}{72\binom {10}{4}\int
_{[0,1]}p^{1+4}(1-p)^{17-4}\,dp} \label {eq:baby_bayes_inf_step}\\ &amp;=\frac {\int _{B\cap [0,1]}p^{5}(1-p)^{13}\,dp}{\mc {B}(6,14)} \notag \\ &amp;=\int _{B\cap [0,1]}\frac
{1}{\mc {B}(6,14)}p^{5}(1-p)^{13}\,dp \notag \\ &amp;=\int _B f_{\Beta (6,14)}(p)\,dp \label {eq:baby_bayes_posterior}
\end{align}
where \(\mc {B}(\alpha ,\beta )=\int _0^1 x^{\alpha -1}(1-x)^{\beta -1}\,dx\) is the Beta function, which gives the normalizing constant of the \(\Beta (\alpha ,\beta )\) distribution. To deduce
<span class="textup">(<a href="The-posterior-distribution.html#eq:baby_bayes_inf_step">2.9</a>)</span> we have used <span class="textup">(<a
href="Discrete-Bayesian-models.html#eq:baby_bayes_full">2.5</a>)</span> for the top and <span class="textup">(<a
href="Discrete-Bayesian-models.html#eq:baby_bayes_data">2.6</a>)</span> for the bottom, with \(x=4\). Note that a factor of \(72\binom {10}{4}\) cancels on the top and bottom.
</p>

<p>
From <span class="textup">(<a href="The-posterior-distribution.html#eq:baby_bayes_posterior">2.10</a>)</span> we can recognize \(P|_{\{X=4\}}\sim \Beta (6,14)\) as the posterior
distribution of \((X,P)\), given the data \(x=4\). Plotting the density functions of \(P\) and \(P|_{\{X=4\}}\) gives the following:
</p>
<div class="center">

<p>


<a href="beta_densities_1.png" target="_blank" ><img
      src="beta_densities_1.png"
      style="
      width:390pt;
      "
      class="inlineimage"
      alt="(image)"
></a>
</p>
</div>

<p>
The effect of incorporating the datapoint \(x=4\) is visible here. Updating our prior p.d.f.&nbsp;\(f_P\) to the posterior p.d.f.&nbsp;\(f_{P|_{\{X=4\}}}\) has resulting in the mass (i.e.&nbsp;the area
underneath the curve) moving rightwards, towards the value \(p=0.4\) that corresponds to having \(4/10\) successful experiments. The p.d.f.&nbsp;\(f_{P|_{\{X=4\}}}\) feels both the influence of the prior
\(f_P\), as well as the Bayesian update from our data.
</p>

<p>
Suppose that we are now given a second piece of data, which is that a second set of \(10\) experiments was done, with \(x=5\) successes. We can use the posterior \(\Beta (6,14)\) that we obtained before as our
new prior distribution, to incorporate our improved knowledge about the parameter \(\theta \). We keep the rest of our model as before, and do another Bayesian update to find a new posterior distribution.
Going through the same calculations (weâ€™ll omit the details) it turns out that the new posterior is \(\Beta (11,19)\). Including this into our plot we obtain:
</p>
<div class="center">

<p>


<a href="beta_densities_2.png" target="_blank" ><img
      src="beta_densities_2.png"
      style="
      width:390pt;
      "
      class="inlineimage"
      alt="(image)"
></a>
</p>
</div>

<p>
Weâ€™ve labelled our new posterior as \(f_{(P|_{\{X=4\}})|_{\{X=5\}}}\), to reflect the fact that weâ€™ve done two updates (this is rather lazy notation!). We can see the influence of the new data: our second data
point \(x=5\) again corresponds to a higher rate of success than our (updated) model anticipated, which again pulls the mass of the distribution rightwards.
</p>

<p>
Our model still feels the effect of our initial prior, in the sense that the mean of \(B(11,19)\) is \(11/30\approx 0.37\), which corresponds to a lower success rate than both of our data points. We only have two
data points, so it is perhaps best that the initial guess we were given has not been forgotten.
</p>

<p>
We can also see that the distributions are becoming less spread out with each update. This reflects our models becoming more confident (of the posterior distribution they suggest for \(\theta \)) as we feed them
more data. More precisely we can measure the standard deviations becoming smaller: from the reference sheet in Appendix <a href="Reference-Sheets.html#a:reference_sheets">A</a>, \(\Beta (\alpha
,\beta )\) has variance \(\frac {\alpha \beta }{(\alpha +\beta )^2(1+\alpha +\beta )}\), from which the sequence of standard deviations comes out as \(0.12\), \(0.10\) and \(0.087\), each rounded
to two significant figures.
</p>

<p>
Putting our final posterior \(\Beta (11,19)\) back into the same model family, we obtain from <span class="textup">(<a
href="The-posterior-distribution.html#eq:bayes_discrete_general_pred_pmf">2.8</a>)</span> that the predictive distribution given by our analysis is
</p>
<span class="hidden"> \(\seteqnumber{0}{2.}{10}\)</span>



<!--
                                                                                             Z 1
                                                                                  0    0
                                                                              P[X = x ] =       fBin(10,p) (x0 )fBeta(11,19) (p) dp
                                                                                               0
                                                                                             Z 1 
                                                                                                  10 x0                  0     1
                                                                                           =        0
                                                                                                      p (1 âˆ’ p)10âˆ’x                   p10 (1 âˆ’ p)18 dp
                                                                                              0   x                        B(11,  19)
                                                                                                       Z 1
                                                                                                1        10                0             0
                                                                                           =                        p10+x (1 âˆ’ p)28âˆ’x dp.
                                                                                             B(11, 19) x0        0




-->



<p>


\begin{align*}
\P [X&apos;=x&apos;] &amp;=\int _0^1 f_{\Bin (10,p)}(x&apos;)f_{\Beta (11,19)}(p)\,dp\\ &amp;=\int _0^1\binom {10}{x&apos;}p^{x&apos;}(1-p)^{10-x&apos;}\frac {1}{\mc
{B}(11,19)}p^{10}(1-p)^{18}\,dp \\ &amp;=\frac {1}{\mc {B}(11,19)}\binom {10}{x&apos;}\int _0^1 p^{10+x&apos;}(1-p)^{28-x&apos;}\,dp.
\end{align*}
for \(x&apos;=0,1,\ldots ,10\). Plotting this p.m.f.&nbsp;gives:
</p>
<div class="center">

<p>


<a href="beta_densities_pred.png" target="_blank" ><img
      src="beta_densities_pred.png"
      style="
      width:390pt;
      "
      class="inlineimage"
      alt="(image)"
></a>
</p>
</div>


</li>

</ul>

</div>

<p>
We can compare this figure to the sampling p.d.f.&nbsp;in Example <a href="Discrete-Bayesian-models.html#ex:baby_bayes_part2">2.2.2</a>, from before we did any Bayesian updates. As we would expect,
our estimate of the number of successful experiments now places more weight on larger values.
</p>

<p>
Calculating the distribution of \(P|_{\{X=4\}}\) in Example <a href="The-posterior-distribution.html#ex:baby_bayes_part3">2.3.3</a> was a bit complicated. For practical purposes we will need to find
easier ways of doing Bayesian updates. Weâ€™ll do that in Chapter <a href="Conjugate-priors.html#c:conjugate_priors">4</a>, but first weâ€™ll need to finish our development of the theory.
</p>

<p>
Once you become comfortable with Bayesian updates, it will be tempting to try and compare this new method of statistical inference to things you already know, and to wonder â€˜which is better?â€™. We will think
about this in Chapter <a href="Discussion.html#c:discussion">6</a>, but there is no simple answer.
</p>

<p>
In Example <a href="The-posterior-distribution.html#ex:baby_bayes_part3">2.3.3</a> weâ€™ve used several sketches to help us understand the distributions we came across. Exercise <a
href="Exercises-on-Chapter-ref-c-bayes_models_discrete.html#ps:dist_sketching_2"><b>2.1</b></a> provides you with template code for doing so yourself. You will find that code useful for several
other exercises too.
</p>

</section>

</main>

</div>

<footer>

<p>
Copyright Nic Freeman, Sheffield University, last updated November 27, 2024
</p>

</footer>



<nav class="botnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

</body>
</html>
