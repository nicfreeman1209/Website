<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Nic Freeman" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="MAS364/61006 Bayesian Statistics, Sheffield University, November 29, 2024." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>MAS364/61006 — Gibbs sampling</title>
<link rel="stylesheet" type="text/css" href="sans-serif-lwarp-sagebrush.css" />
<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
// \left, \right delimiters: https://github.com/mathjax/MathJax/issues/2535
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
  subequations: "0",
  section: "",
  loader: {
    load: ['[tex]/tagformat', '[tex]/textmacros'],
  },
  startup: {
    ready() {
      // These would be replaced by import commands if you wanted to make
      // a proper extension.
      const Configuration = MathJax._.input.tex.Configuration.Configuration;
      const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
      const Macro = MathJax._.input.tex.Symbol.Macro;
      const TexError = MathJax._.input.tex.TexError.default;
      const ParseUtil = MathJax._.input.tex.ParseUtil.default;
      const expandable = MathJax._.util.Options.expandable;

        // Insert the replacement string into the TeX string, and check
        // that there haven't been too many maxro substitutions (prevents
        // infinite loops).
        const useArgument = (parser, text) => {
          parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
          parser.i = 0;
          if (++parser.macroCount > parser.configuration.options.maxMacros) {
            throw new TexError('MaxMacroSub1',
            'MathJax maximum macro substitution count exceeded; ' +
            'is there a recursive macro call?');
          }
        }

        // Create the command map for:
        //     \ifstar, \ifnextchar, \ifblank, \ifstrequal, \gsub, \seteqnumber
        new CommandMap('Lwarp-macros', {
          ifstar: 'IfstarFunction',
          ifnextchar: 'IfnextcharFunction',
          ifblank: 'IfblankFunction',
          ifstrequal: 'IfstrequalFunction',
          gsubstitute: 'GsubstituteFunction',
          seteqnumber: 'SeteqnumberFunction'
        }, {
          // This function implements an ifstar macro.
          IfstarFunction(parser, name) {
             const resultstar = parser.GetArgument(name);
             const resultnostar = parser.GetArgument(name);
             const star = parser.GetStar();                 // true if there is a *
             useArgument(parser, star ? resultstar : resultnostar);
          },

          // This function implements an ifnextchar macro.
          IfnextcharFunction(parser, name) {
            let whichchar = parser.GetArgument(name);
            if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
              // $ syntax highlighting
              whichchar = String.fromCodePoint(parseInt(whichchar));
            }
            const resultnextchar = parser.GetArgument(name);
            const resultnotnextchar = parser.GetArgument(name);
            const gotchar = (parser.GetNext() === whichchar);
            useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
          },

          // This function implements an ifblank macro.
          IfblankFunction(parser, name) {
            const blankarg = parser.GetArgument(name);
            const resultblank = parser.GetArgument(name);
            const resultnotblank = parser.GetArgument(name);
            const isblank = (blankarg.trim() == "");
            useArgument(parser, isblank ? resultblank : resultnotblank);
          },

          // This function implements an ifstrequal macro.
          IfstrequalFunction(parser, name) {
            const strequalfirst = parser.GetArgument(name);
            const strequalsecond = parser.GetArgument(name);
            const resultequal = parser.GetArgument(name);
            const resultnotequal = parser.GetArgument(name);
            const isequal = (strequalfirst == strequalsecond);
            useArgument(parser, isequal ? resultequal : resultnotequal);
          },

          // This function implements a gsub macro.
          GsubstituteFunction(parser, name) {
            const gsubfirst = parser.GetArgument(name);
            const gsubsecond = parser.GetArgument(name);
            const gsubthird = parser.GetArgument(name);
            let gsubresult=gsubfirst.replace(gsubsecond, gsubthird);
            useArgument(parser, gsubresult);
          },

          // This function modifies the equation numbers.
          SeteqnumberFunction(parser, name) {
              // Get the macro parameters
              const star = parser.GetStar();                  // true if there is a *
              const optBrackets = parser.GetBrackets(name);   // contents of optional brackets
              const newsubequations = parser.GetArgument(name); // the subequations argument
              const neweqsection = parser.GetArgument(name); // the eq section argument
              const neweqnumber = parser.GetArgument(name);   // the eq number argument
              MathJax.config.subequations=newsubequations ;   // a string with boolean meaning
              MathJax.config.section=neweqsection ;           // a string with numeric meaning
              parser.tags.counter = parser.tags.allCounter = neweqnumber ;
          }

        });

        // Create the Lwarp-macros package
        Configuration.create('Lwarp-macros', {
          handler: {macro: ['Lwarp-macros']}
        });

        MathJax.startup.defaultReady();

        // For forward references:
        MathJax.startup.input[0].preFilters.add(({math}) => {
          if (math.inputData.recompile){
              MathJax.config.subequations = math.inputData.recompile.subequations;
              MathJax.config.section = math.inputData.recompile.section;
          }
        });
        MathJax.startup.input[0].postFilters.add(({math}) => {
          if (math.inputData.recompile){
              math.inputData.recompile.subequations = MathJax.config.subequations;
              math.inputData.recompile.section = MathJax.config.section;
          }
        });

          // For \left, \right with unicode-math:
          const {DelimiterMap} = MathJax._.input.tex.SymbolMap;
          const {Symbol} = MathJax._.input.tex.Symbol;
          const {MapHandler} = MathJax._.input.tex.MapHandler;
          const delimiter = MapHandler.getMap('delimiter');
          delimiter.add('\\lBrack', new Symbol('\\lBrack', '\u27E6'));
          delimiter.add('\\rBrack', new Symbol('\\rBrack', '\u27E7'));
          delimiter.add('\\lAngle', new Symbol('\\lAngle', '\u27EA'));
          delimiter.add('\\rAngle', new Symbol('\\rAngle', '\u27EB'));
          delimiter.add('\\lbrbrak', new Symbol('\\lbrbrak', '\u2772'));
          delimiter.add('\\rbrbrak', new Symbol('\\rbrbrak', '\u2773'));
          delimiter.add('\\lbag', new Symbol('\\lbag', '\u27C5'));
          delimiter.add('\\rbag', new Symbol('\\rbag', '\u27C6'));
          delimiter.add('\\llparenthesis', new Symbol('\\llparenthesis', '\u2987'));
          delimiter.add('\\rrparenthesis', new Symbol('\\rrparenthesis', '\u2988'));
          delimiter.add('\\llangle', new Symbol('\\llangle', '\u2989'));
          delimiter.add('\\rrangle', new Symbol('\\rrangle', '\u298A'));
          delimiter.add('\\Lbrbrak', new Symbol('\\Lbrbrak', '\u27EC'));
          delimiter.add('\\Rbrbrak', new Symbol('\\Rbrbrak', '\u27ED'));
          delimiter.add('\\lBrace', new Symbol('\\lBrace', '\u2983'));
          delimiter.add('\\rBrace', new Symbol('\\rBrace', '\u2984'));
          delimiter.add('\\lParen', new Symbol('\\lParen', '\u2985'));
          delimiter.add('\\rParen', new Symbol('\\rParen', '\u2986'));
          delimiter.add('\\lbrackubar', new Symbol('\\lbrackubar', '\u298B'));
          delimiter.add('\\rbrackubar', new Symbol('\\rbrackubar', '\u298C'));
          delimiter.add('\\lbrackultick', new Symbol('\\lbrackultick', '\u298D'));
          delimiter.add('\\rbracklrtick', new Symbol('\\rbracklrtick', '\u298E'));
          delimiter.add('\\lbracklltick', new Symbol('\\lbracklltick', '\u298F'));
          delimiter.add('\\rbrackurtick', new Symbol('\\rbrackurtick', '\u2990'));
          delimiter.add('\\langledot', new Symbol('\\langledot', '\u2991'));
          delimiter.add('\\rangledot', new Symbol('\\rangledot', '\u2992'));
          delimiter.add('\\lparenless', new Symbol('\\lparenless', '\u2993'));
          delimiter.add('\\rparengtr', new Symbol('\\rparengtr', '\u2994'));
          delimiter.add('\\Lparengtr', new Symbol('\\Lparengtr', '\u2995'));
          delimiter.add('\\Rparenless', new Symbol('\\Rparenless', '\u2996'));
          delimiter.add('\\lblkbrbrak', new Symbol('\\lblkbrbrak', '\u2997'));
          delimiter.add('\\rblkbrbrak', new Symbol('\\rblkbrbrak', '\u2998'));
          delimiter.add('\\lvzigzag', new Symbol('\\lvzigzag', '\u29D8'));
          delimiter.add('\\rvzigzag', new Symbol('\\rvzigzag', '\u29D9'));
          delimiter.add('\\Lvzigzag', new Symbol('\\Lvzigzag', '\u29DA'));
          delimiter.add('\\Rvzigzag', new Symbol('\\Rvzigzag', '\u29DB'));
          delimiter.add('\\lcurvyangle', new Symbol('\\lcurvyangle', '\u29FC'));
          delimiter.add('\\rcurvyangle', new Symbol('\\rcurvyangle', '\u29FD'));
          delimiter.add('\\Vvert', new Symbol('\\Vvert', '\u2980'));
    }     // ready
  },      // startup

  tex: {
    packages: {'[+]': ['tagformat', 'Lwarp-macros', 'textmacros']},
    tags: "ams",
         tagformat: {
             number: function (n) {
                 if(MathJax.config.subequations==0)
                     return(MathJax.config.section + n);
                 else
                     return(MathJax.config.section + String.fromCharCode(96+n));
             },
         },
  }
}
</script>

<script
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4222H8D03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4222H8D03');
</script>
<!-- Google tag (gtag.js) -->


</head>
<body>



<a id="notes-autopage-257"></a>
<nav class="topnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

<header>

<p>
last updated: November 29, 2024
</p>

</header>



<div class="bodyandsidetoc">
<div class="sidetoccontainer">



<nav class="sidetoc">



<div class="sidetoctitle">

<p>
<span class="sidetocthetitle">Bayesian Statistics</span>
</p>

<p>
Contents
</p>
</div>



<div class="sidetoccontents">

<p>
<a href="notes.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Introduction.html#autosec-5" class="tocchapter" >
<span class="sectionnumber">0</span>&#x2003;Introduction</a>
</p>



<p>
<a href="Introduction.html#autosec-6" class="tocsection" >
<span class="sectionnumber">0.1</span>&#x2003;Organization</a>
</p>



<p>
<a href="Outline-course.html#autosec-13" class="tocsection" >
<span class="sectionnumber">0.2</span>&#x2003;Outline of the course</a>
</p>



<p>
<a href="Conditioning.html#autosec-15" class="tocchapter" >
<span class="sectionnumber">1</span>&#x2003;Conditioning</a>
</p>



<p>
<a href="Conditioning.html#autosec-16" class="tocsection" >
<span class="sectionnumber">1.1</span>&#x2003;Random variables</a>
</p>



<p>
<a href="Equality-in-distribution.html#autosec-21" class="tocsection" >
<span class="sectionnumber">1.2</span>&#x2003;Equality in distribution</a>
</p>



<p>
<a href="Families-random-variables.html#autosec-31" class="tocsection" >
<span class="sectionnumber">1.3</span>&#x2003;Families of random variables</a>
</p>



<p>
<a href="Conditioning-on-location.html#autosec-35" class="tocsection" >
<span class="sectionnumber">1.4</span>&#x2003;Conditioning on location</a>
</p>



<p>
<a href="Conditioning-correlations.html#autosec-43" class="tocsection" >
<span class="sectionnumber">1.5</span>&#x2003;Conditioning and correlations</a>
</p>



<p>
<a href="Conditioning-on-events-with-zero-probability.html#autosec-50" class="tocsection" >
<span class="sectionnumber">1.6</span>&#x2003;Conditioning on events with zero probability</a>
</p>



<p>
<a href="Families-with-random-parameters.html#autosec-57" class="tocsection" >
<span class="sectionnumber">1.7</span>&#x2003;Families with random parameters</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conditioning.html#autosec-60" class="tocsection" >
<span class="sectionnumber">1.8</span>&#x2003;Exercises on Chapter 1</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-65" class="tocchapter" >
<span class="sectionnumber">2</span>&#x2003;Bayesian models: discrete data</a>
</p>



<p>
<a href="Bayesian-models-discrete-data.html#autosec-66" class="tocsection" >
<span class="sectionnumber">2.1</span>&#x2003;Models with random parameters</a>
</p>



<p>
<a href="Discrete-Bayesian-models.html#autosec-70" class="tocsection" >
<span class="sectionnumber">2.2</span>&#x2003;Discrete Bayesian models</a>
</p>



<p>
<a href="The-posterior-distribution.html#autosec-75" class="tocsection" >
<span class="sectionnumber">2.3</span>&#x2003;The posterior distribution</a>
</p>



<p>
<a href="Bayesian-updates.html#autosec-83" class="tocsection" >
<span class="sectionnumber">2.4</span>&#x2003;Bayesian updates</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_discrete.html#autosec-87" class="tocsection" >
<span class="sectionnumber">2.5</span>&#x2003;Exercises on Chapter 2</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-90" class="tocchapter" >
<span class="sectionnumber">3</span>&#x2003;Bayesian models: continuous data</a>
</p>



<p>
<a href="Bayesian-models-continuous-data.html#autosec-91" class="tocsection" >
<span class="sectionnumber">3.1</span>&#x2003;Continuous Bayesian models</a>
</p>



<p>
<a href="Notation-independent-data.html#autosec-97" class="tocsection" >
<span class="sectionnumber">3.2</span>&#x2003;Notation: independent data</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-bayes_models_continuous.html#autosec-107" class="tocsection" >
<span class="sectionnumber">3.3</span>&#x2003;Exercises on Chapter 3</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-110" class="tocchapter" >
<span class="sectionnumber">4</span>&#x2003;Conjugate priors</a>
</p>



<p>
<a href="Conjugate-priors.html#autosec-112" class="tocsection" >
<span class="sectionnumber">4.1</span>&#x2003;Notation: proportionality</a>
</p>



<p>
<a href="Two-more-examples-conjugate-pairs.html#autosec-122" class="tocsection" >
<span class="sectionnumber">4.2</span>&#x2003;Two more examples of conjugate pairs</a>
</p>



<p>
<a href="Conjugate-pairs-exponential-family.html#autosec-132" class="tocsection" >
<span class="sectionnumber">4.3</span>&#x2003;Conjugate pairs and the exponential family \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="What-if.html#autosec-137" class="tocsection" >
<span class="sectionnumber">4.4</span>&#x2003;What if?</a>
</p>



<p>
<a href="The-normal-distribution-with-unknown-mean-variance.html#autosec-150" class="tocsection" >
<span class="sectionnumber">4.5</span>&#x2003;The normal distribution with unknown mean and variance</a>
</p>



<p>
<a href="The-limitations-conjugate-pairs.html#autosec-158" class="tocsection" >
<span class="sectionnumber">4.6</span>&#x2003;The limitations of conjugate pairs</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-conjugate_priors.html#autosec-160" class="tocsection" >
<span class="sectionnumber">4.7</span>&#x2003;Exercises on Chapter 4</a>
</p>



<p>
<a href="The-prior.html#autosec-163" class="tocchapter" >
<span class="sectionnumber">5</span>&#x2003;The prior</a>
</p>



<p>
<a href="The-prior.html#autosec-164" class="tocsection" >
<span class="sectionnumber">5.1</span>&#x2003;Elicitation</a>
</p>



<p>
<a href="Uninformative-priors.html#autosec-172" class="tocsection" >
<span class="sectionnumber">5.2</span>&#x2003;Uninformative priors</a>
</p>



<p>
<a href="Reference-priors.html#autosec-179" class="tocsection" >
<span class="sectionnumber">5.3</span>&#x2003;Reference priors</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-prior.html#autosec-185" class="tocsection" >
<span class="sectionnumber">5.4</span>&#x2003;Exercises on Chapter 5</a>
</p>



<p>
<a href="Discussion.html#autosec-188" class="tocchapter" >
<span class="sectionnumber">6</span>&#x2003;Discussion</a>
</p>



<p>
<a href="Discussion.html#autosec-189" class="tocsection" >
<span class="sectionnumber">6.1</span>&#x2003;Bayesian shorthand notation</a>
</p>



<p>
<a href="The-connection-maximum-likelihood.html#autosec-194" class="tocsection" >
<span class="sectionnumber">6.2</span>&#x2003;The connection to maximum likelihood</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-discussion.html#autosec-200" class="tocsection" >
<span class="sectionnumber">6.3</span>&#x2003;Exercises on Chapter 6</a>
</p>



<p>
<a href="Testing-parameter-estimation.html#autosec-203" class="tocchapter" >
<span class="sectionnumber">7</span>&#x2003;Testing and parameter estimation</a>
</p>



<p>
<a href="Testing-parameter-estimation.html#autosec-204" class="tocsection" >
<span class="sectionnumber">7.1</span>&#x2003;Hypothesis testing</a>
</p>



<p>
<a href="High-posterior-density-regions.html#autosec-212" class="tocsection" >
<span class="sectionnumber">7.2</span>&#x2003;High posterior density regions</a>
</p>



<p>
<a href="Point-estimates.html#autosec-221" class="tocsection" >
<span class="sectionnumber">7.3</span>&#x2003;Point estimates</a>
</p>



<p>
<a href="Comparison-classical-methods.html#autosec-226" class="tocsection" >
<span class="sectionnumber">7.4</span>&#x2003;Comparison to classical methods</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-tests.html#autosec-232" class="tocsection" >
<span class="sectionnumber">7.5</span>&#x2003;Exercises on Chapter 7</a>
</p>



<p>
<a href="Computational-methods.html#autosec-235" class="tocchapter" >
<span class="sectionnumber">8</span>&#x2003;Computational methods</a>
</p>



<p>
<a href="Computational-methods.html#autosec-236" class="tocsection" >
<span class="sectionnumber">8.1</span>&#x2003;Approximate Bayesian computation \(\color {darkred}(\mathbf {\oslash })\)</a>
</p>



<p>
<a href="Metropolis-Hastings.html#autosec-239" class="tocsection" >
<span class="sectionnumber">8.2</span>&#x2003;Metropolis-Hastings</a>
</p>



<p>
<a href="Markov-Chain-Monte-Carlo.html#autosec-253" class="tocsection" >
<span class="sectionnumber">8.3</span>&#x2003;Markov Chain Monte Carlo</a>
</p>



<p>
<a href="Gibbs-sampling.html#autosec-258" class="tocsection" >
<span class="sectionnumber">8.4</span>&#x2003;Gibbs sampling</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-c-computational.html#autosec-265" class="tocsection" >
<span class="sectionnumber">8.5</span>&#x2003;Exercises on Chapter 8</a>
</p>



<p>
<a href="Reference-Sheets.html#autosec-268" class="tocchapter" >
<span class="sectionnumber">A</span>&#x2003;Reference Sheets</a>
</p>



<p>
<a href="Advice-revision-exams.html#autosec-276" class="tocchapter" >
<span class="sectionnumber">B</span>&#x2003;Advice for revision/exams</a>
</p>



<p>
<a href="Solutions-exercises.html#autosec-280" class="tocchapter" >
<span class="sectionnumber">C</span>&#x2003;Solutions to exercises</a>
</p>



</div>

</nav>

</div>



<main class="bodycontainer">



<section class="textbody">

<h1>Bayesian Statistics</h1>

<!--MathJax customizations:-->
<div data-nosnippet
      style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\require {colortbl}\)

\(\let \LWRorigcolumncolor \columncolor \)

\(\renewcommand {\columncolor }[2][named]{\LWRorigcolumncolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigrowcolor \rowcolor \)

\(\renewcommand {\rowcolor }[2][named]{\LWRorigrowcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\let \LWRorigcellcolor \cellcolor \)

\(\renewcommand {\cellcolor }[2][named]{\LWRorigcellcolor [#1]{#2}\LWRabsorbtwooptions }\)

\(\require {mathtools}\)

\(\newenvironment {crampedsubarray}[1]{}{}\)

\(\newcommand {\smashoperator }[2][]{#2\limits }\)

\(\newcommand {\SwapAboveDisplaySkip }{}\)

\(\newcommand {\LaTeXunderbrace }[1]{\underbrace {#1}}\)

\(\newcommand {\LaTeXoverbrace }[1]{\overbrace {#1}}\)

\(\newcommand {\LWRmultlined }[1][]{\begin {multline*}}\)

\(\newenvironment {multlined}[1][]{\LWRmultlined }{\end {multline*}}\)

\(\let \LWRorigshoveleft \shoveleft \)

\(\renewcommand {\shoveleft }[1][]{\LWRorigshoveleft }\)

\(\let \LWRorigshoveright \shoveright \)

\(\renewcommand {\shoveright }[1][]{\LWRorigshoveright }\)

\(\newcommand {\shortintertext }[1]{\text {#1}\notag \\}\)

\(\newcommand {\vcentcolon }{\mathrel {\unicode {x2236}}}\)

\(\renewcommand {\intertext }[2][]{\text {#2}\notag \\}\)

\(\newenvironment {fleqn}[1][]{}{}\)

\(\newenvironment {ceqn}{}{}\)

\(\newenvironment {darray}[2][c]{\begin {array}[#1]{#2}}{\end {array}}\)

\(\newcommand {\dmulticolumn }[3]{#3}\)

\(\newcommand {\LWRnrnostar }[1][0.5ex]{\\[#1]}\)

\(\newcommand {\nr }{\ifstar \LWRnrnostar \LWRnrnostar }\)

\(\newcommand {\mrel }[1]{\begin {aligned}#1\end {aligned}}\)

\(\newcommand {\underrel }[2]{\underset {#2}{#1}}\)

\(\newcommand {\medmath }[1]{#1}\)

\(\newcommand {\medop }[1]{#1}\)

\(\newcommand {\medint }[1]{#1}\)

\(\newcommand {\medintcorr }[1]{#1}\)

\(\newcommand {\mfrac }[2]{\frac {#1}{#2}}\)

\(\newcommand {\mbinom }[2]{\binom {#1}{#2}}\)

\(\newenvironment {mmatrix}{\begin {matrix}}{\end {matrix}}\)

\(\newcommand {\displaybreak }[1][]{}\)

\( \def \offsyl {(\oslash )} \def \msconly {(\Delta )} \)

\( \DeclareMathOperator {\var }{var} \DeclareMathOperator {\cov }{cov} \DeclareMathOperator {\Bin }{Bin} \DeclareMathOperator {\Geo }{Geometric} \DeclareMathOperator {\Beta
}{Beta} \DeclareMathOperator {\Unif }{Uniform} \DeclareMathOperator {\Gam }{Gamma} \DeclareMathOperator {\Normal }{N} \DeclareMathOperator {\Exp }{Exp} \DeclareMathOperator
{\Cauchy }{Cauchy} \DeclareMathOperator {\Bern }{Bernoulli} \DeclareMathOperator {\Poisson }{Poisson} \DeclareMathOperator {\Weibull }{Weibull} \DeclareMathOperator {\IGam
}{IGamma} \DeclareMathOperator {\NGam }{NGamma} \DeclareMathOperator {\ChiSquared }{ChiSquared} \DeclareMathOperator {\Pareto }{Pareto} \DeclareMathOperator {\NBin }{NegBin}
\DeclareMathOperator {\Studentt }{Student-t} \DeclareMathOperator *{\argmax }{arg\,max} \DeclareMathOperator *{\argmin }{arg\,min} \)

\( \def \to {\rightarrow } \def \iff {\Leftrightarrow } \def \ra {\Rightarrow } \def \sw {\subseteq } \def \mc {\mathcal } \def \mb {\mathbb } \def \sc {\setminus } \def \wt
{\widetilde } \def \v {\textbf } \def \E {\mb {E}} \def \P {\mb {P}} \def \R {\mb {R}} \def \C {\mb {C}} \def \N {\mb {N}} \def \Q {\mb {Q}} \def \Z {\mb {Z}} \def \B {\mb {B}}
\def \~{\sim } \def \-{\,;\,} \def \qed {$\blacksquare $} \CustomizeMathJax {\def \1{\unicode {x1D7D9}}} \def \cadlag {c\&grave;{a}dl\&grave;{a}g} \def \p {\partial } \def \l
{\left } \def \r {\right } \def \Om {\Omega } \def \om {\omega } \def \eps {\epsilon } \def \de {\delta } \def \ov {\overline } \def \sr {\stackrel } \def \Lp {\mc {L}^p} \def
\Lq {\mc {L}^p} \def \Lone {\mc {L}^1} \def \Ltwo {\mc {L}^2} \def \toae {\sr {\rm a.e.}{\to }} \def \toas {\sr {\rm a.s.}{\to }} \def \top {\sr {\mb {\P }}{\to }} \def \tod {\sr
{\rm d}{\to }} \def \toLp {\sr {\Lp }{\to }} \def \toLq {\sr {\Lq }{\to }} \def \eqae {\sr {\rm a.e.}{=}} \def \eqas {\sr {\rm a.s.}{=}} \def \eqd {\sr {\rm d}{=}} \def \approxd
{\sr {\rm d}{\approx }} \def \Sa {(S1)\xspace } \def \Sb {(S2)\xspace } \def \Sc {(S3)\xspace } \)

</div>

<!--
......     section Gibbs sampling ......
-->
<h4 id="autosec-258"><span class="sectionnumber">8.4&#x2003;</span>Gibbs sampling</h4>
<a id="notes-autopage-258"></a>
<a id="notes-autofile-41"></a>

<a id="s:gibbs"></a>

<p>
Recall that our parameter \(\theta \) may really be a vector of parameters, as in Section <a href="The-normal-distribution-with-unknown-mean-variance.html#s:normal_both_params">4.5</a> where we
considered the model \(M_{(\mu ,\sigma )}\sim \Normal (\mu ,\sigma ^2)\) with \(\theta =(\mu ,\sigma )\in \R \times (0,\infty )\). In this section we introduce a technique for handling models
with many parameters \(\theta =(\theta _1,\ldots ,\theta _d)\in \R ^d\). For those of you taking MAS364, this section is non-examinable and is included for interest only. For those of you taking
MAS61006, this section is on syllabus and will feed into your work next semester.
</p>

<p>
For \(d=1\) or \(d=2\) the MH algorithm as described in Section <a href="Markov-Chain-Monte-Carlo.html#s:mcmc">8.3</a> is effective. For much large \(d\), what tends to happen is that it takes a very long
time for the sequence \((y_m)\) generated by the MH algorithm to explore the parameter space \(\Pi \sw \R ^d\), which means that it takes longer to converge to (the distribution of) \(\Theta |_{\{X=x\}}\).
This happens simply because there is <em>a lot</em> of space to explore inside \(\R ^d\) when \(d\) is large; this phenomenon is often known as the curse of dimensionality.
</p>
<div class="theorembodyexample">

<ul class="list" style="list-style-type:none">



<a id="autoid-180"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Example 8.4.1</span></span> <a id="autoid-181" ></a >Imagine you have parked your car inside a multi-story car park and then forgotten
where you’ve parked it. If you know which level your car is on then you will only have to search on that level, and you will find your car in minutes. If you don’t know which level, it will take you <em>much</em>
longer. The first case is exploring \(d=2\), the second is \(d=3\). Actually, to make this example properly match the difference between \(d=2\) and \(d=3\), the car park should have the same number of floors as
there are parking spaces along the side-length of each floor! The problem only gets worse in \(d\geq 3\).
</p>


</li>

</ul>

</div>

<p>
One strategy for working around this problem is to update the parameters \((\theta _1,\ldots ,\theta _d)\) one at a time. That is, we would first change \(\theta _1\) while keeping \((\theta _2,\ldots
,\theta _d)\) fixed, then we would change \(\theta _2\) while keeping \((\theta _1,\theta _3,\ldots ,\theta _d)\) fixed, and so on. After updating \(\theta _d\) we would then return to \(\theta
_1\). It is helpful to introduce some notation for this: we write \(\theta _{-i}=(\theta _1,\ldots ,\theta _{i-1},\theta _{i+1},\ldots ,\theta _d)\) for the vector \(\theta \) with the \(\theta _i\)
term removed. We use the same notation for the random vector \(\Theta \) e.g.&nbsp;\(\Theta _{-i}\).
</p>
<div class="theorembodyremark">

<ul class="list" style="list-style-type:none">



<a id="autoid-182"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Remark 8.4.2</span></span> <a id="autoid-183" ></a ><a id="r:mh_batching"></a> In reality, instead of updating the \(\theta _i\)
one-by-one, it is common to update the parameters in small batches. For example we might update \((\theta _1,\ldots ,\theta _4)\) in one step, then \((\theta _5,\ldots ,\theta _8)\) in the next step,
and so on. It is helpful to put related parameters, with values that might strongly influence each other, within the same batch.
</p>


</li>

</ul>

</div>

<p>
When we update the parameters in turn, a common choice of proposal distribution is to set \(Q\sim \Theta _i|_{\{\Theta _{-i}=\theta _{-i},\,X=x\}}\) in the update for \(\theta _i\), where \(\theta
_{-i}\) are the values obtained from the previous update. This choice of proposal has the effect that, from <span class="textup">(<a href="Metropolis-Hastings.html#eq:mh_alpha">8.1</a>)</span>, we
end up with \(\alpha =1\) and all proposals are then accepted. When using proposals of this form, the MH algorithm is usually known as the <i>Gibbs sampler</i>.
</p>
<div class="theorembodydefinition">

<ul class="list" style="list-style-type:none">



<a id="autoid-184"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Definition 8.4.3</span></span> <a id="autoid-185" ></a ><a id="d:full_conditionals"></a> The distributions of \(\Theta
_{i}|_{\{\Theta _{-i}=\theta _{-i},\,X=x\}}\), for \(i=1,\ldots ,d\), are known as the <em>full conditional distributions</em>. From Lemma <a
href="Conditioning-on-events-with-zero-probability.html#l:rv_from_conditioning_abs_cts">1.6.1</a> the \(i^{th}\) full conditional has p.d.f.&nbsp;given by
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{11}\)</span>



<!--

                                                                                                                           fΘ|{X=x} (θ)
                                                                  fΘi |{Θ−i =θ−i , X=x} (θi ) = R
                                                                                                    Rd−1 fΘ|{X=x} (θ1 , . . . , θi−1 , θi , θi+1 , . . . , θd ) dθ−i

                                                                                            ∝ fΘ|{X=x} (θ)
                                                                                           (8.12)                                                                      --><a id="eq:full_conditionals"></a><!--



-->



<p>


\begin{align}
f_{\Theta _{i}|_{\{\Theta _{-i}=\theta _{-i},\,X=x\}}}(\theta _i) &amp;= \frac {f_{\Theta |_{\{X=x\}}}(\theta )} {\int _{\R ^{d-1}}f_{\Theta |_{\{X=x\}}}(\theta _1,\ldots ,\theta
_{i-1},\theta _i,\theta _{i+1},\ldots ,\theta _d)\,d\theta _{-i}} \notag \\ &amp;\propto f_{\Theta |_{\{X=x\}}}(\theta ) \label {eq:full_conditionals}
\end{align}
We can calculate \(f_{\Theta |_{\{X=x\}}}\) from Theorems <a href="Bayesian-updates.html#t:bayes_thm_discrete_data">2.4.1</a>/<a
href="Bayesian-models-continuous-data.html#t:bayes_thm_continuous_data">3.1.2</a>, which provides a strategy for calculating <span class="textup">(<a
href="Gibbs-sampling.html#eq:full_conditionals">8.12</a>)</span> analytically. Note that \(\propto \) in <span class="textup">(<a
href="Gibbs-sampling.html#eq:full_conditionals">8.12</a>)</span> treats \(\theta _{-i}\) and \(x\) as constants, and the only variable is \(\theta _i\).
</p>


</li>

</ul>

</div>
<div class="theorembodyremark">

<ul class="list" style="list-style-type:none">



<a id="autoid-186"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Remark 8.4.4</span></span> <a id="autoid-187" ></a ><a id="r:full_conditionals_shorthand"></a> The notation \(\Theta
_{i}|_{\{\Theta _{-i}=\theta _{-i},\,X=x\}}\) for the full conditionals is a bit unwieldy. In Bayesian shorthand we would write simply \(\theta _i|\theta _{-i},x\) which is much neater.
</p>


</li>

</ul>

</div>

<p>
The Gibbs sampler that results from these strategies is as follows.
</p>

<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> Choose an initial point \(y_0=(\theta _1^{(0)},\ldots ,\theta _d^{(0)})\in \Pi \).
</p>


</li>
<li>


<p>
<span class="listmarker">2.</span> For each \(i=1,\ldots ,d\), sample \(\tilde {y}\) from \(\Theta _{i}|_{\{\Theta _{-i}=\theta ^{(m)}_{-i},\,X=x\}}\) and set
</p>
<p>
\[y_{m+1}=(\theta _1^{(m)},\ldots ,\theta _{i-1}^{(m)},\tilde {y},\theta _{i+1}^{(m)},\ldots ,\theta _d^{(m)}).\]
</p>
<p>
Note that we increment the value of \(m\) each time that we increment \(i\). When reach \(i=d\), return to \(i=1\) and repeat.
</p>
<p>
Repeat this step until \(m\) is large enough that values taken by the \(y_m\) are no longer affected by the choice of \(y_0\).
</p>
</li>
<li>


<p>
<span class="listmarker">3.</span> The final value of \(y_m\) is now a sample of \(\Theta |_{\{X=x\}}\).
</p>
</li>
</ul>

<p>
Note that we need to take samples from the full conditionals \(\Theta _{i}|_{\{\Theta _{-i}=\theta ^{(m)}_{-i},\,X=x\}}\) in step 2. This isn’t always possible, and the Gibbs sampler is only helpful if we
can do that. It is often used in cases where the full conditionals turn out to be named distributions, or nearly one as in Example <a href="Gibbs-sampling.html#ex:radiocarbon">8.4.5</a> below.
</p>

<p>
For the MH algorithm we had Theorem <a href="Metropolis-Hastings.html#t:mh_convergence">8.2.2</a> to tell us that \(y_m\) was (approximately) a sample of \(\Theta |_{\{X=x\}}\), justified by the
discussion in Section <a href="Metropolis-Hastings.html#s:mh_heuristics">8.2.3</a>. It is possible to make similar arguments for the Gibbs algorithm above, but we won’t include them in our course.
</p>

<p>
If the full conditionals can’t be easily sampled from, then one strategy is to use the MH algorithm (run inside of step 2 above) to obtain samples of \(\Theta _{-i}|_{\{X=x\}}\). This technique is known as
<em>Metropolis-within-Gibbs</em>. In practice, once the parameters are divided up into batches, as described in Remark <a href="Gibbs-sampling.html#r:mh_batching">8.4.2</a>, some batches may be
amenable to Gibbs sampling, whilst others may require Metropolis-within-Gibbs. The details will depend on the model. Trial and error is often required to find the best combination of techniques. We won’t try to
write down algorithms of that complexity within these notes, but you should hopefully end the course with an understanding of how (and why) each piece of an algorithm like that would work.
</p>
<div class="theorembodyexample">

<ul class="list" style="list-style-type:none">



<a id="autoid-188"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Example 8.4.5</span></span> <a id="autoid-189" ></a ><a id="ex:radiocarbon"></a> This example comes from Sections
1.1.1/7.5.3/8.6.2 of the book ‘Bayesian Approach to Intrepreting Archaeological Data’ by Buck et al (1996). The data comes from radiocarbon dating, and is a vector \((x_1,x_2,\ldots ,x_n)\) of estimated ages
obtained (via carbon dating) from \(n\) different objects. We write \(\theta _i\) for the true age of object \(i\), which is unknown. Our model for the age of each object is \(x_i\sim \Normal (\theta
_i,v_i)\) and we assume that the estimation errors are independent, for each \(i\). For simplicity we will assume that the \(v_i\) are known parameters, so our model family has \(n\) parameters \(\theta
=(\theta _1,\ldots ,\theta _n)\). We thus have the model family
</p>

<p>
\[M_\theta =\Normal (\theta _1,v_1) \otimes \ldots \otimes \Normal (\theta _n,v_n).\]
</p>

<p>
From the historical context of the objects, it is known that \(\theta _1&lt;\theta _2&lt;\ldots &lt;\theta _n\), so we condition our model \(M_\theta \) on this event. We can use Exercise <a
href="Exercises-on-Chapter-ref-c-conditioning.html#ps:rv_from_conditioning_pve_abs_cts"><b>1.8</b></a> to do this conditioning, resulting in a new model family \(M&apos;_\theta \) given by
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{12}\)</span>



<!--
                                                                                                  
                                                                                                                   fMθ (x)
                                                                                                  
                                                                                                  
                                                                                                      P[N(θ1 ,v1 )<N(θ2 ,v2 )<...<N(θn ,vn )]     for θ1 < θ2 < . . . < θn
                                                                                    fMθ′ (x) =
                                                                                                  
                                                                                                  0
                                                                                                                                                 otherwise
                                                                                                  
                                                                                                   n
                                                                                                   Q
                                                                                                        i=1 fN(θi ,vi ) (xi )       for θ1 < θ2 < . . . < θn
                                                                                                  
                                                                                              ∝
                                                                                                  
                                                                                                  0
                                                                                                                                   otherwise
                                                                                                  
                                                                                                                            (θi −xi )2
                                                                                                                                        
                                                                                                  exp − 1 n
                                                                                                         P
                                                                                                  
                                                                                                                 2    i=1       vi           for θ1 < θ2 < . . . < θn
                                                                                              ∝
                                                                                                  
                                                                                                  0
                                                                                                                                            otherwise.


-->



<p>


\begin{align*}
f_{M&apos;_\theta }(x) &amp;= \begin{cases} \frac {f_{M_\theta }(x)}{\P [\Normal (\theta _1,v_1) &lt; \Normal (\theta _2,v_2)&lt; \ldots &lt; \Normal (\theta _n,v_n)]} &amp;
\text { for }\theta _1&lt;\theta _2&lt;\ldots &lt;\theta _n \\ 0 &amp; \text { otherwise} \end {cases} \\ &amp;\propto \begin{cases} \prod _{i=1}^n f_{\Normal (\theta
_i,v_i)}(x_i) &amp; \text { for }\theta _1&lt;\theta _2&lt;\ldots &lt;\theta _n \\ 0 &amp; \text { otherwise} \end {cases} \\ &amp;\propto \begin{cases} \exp \l (-\frac 12\sum
_{i=1}^n\frac {(\theta _i-x_i)^2}{v_i}\r ) &amp; \text { for }\theta _1&lt;\theta _2&lt;\ldots &lt;\theta _n \\ 0 &amp; \text { otherwise.} \end {cases}
\end{align*}
We use the Bayesian model \((X,\Theta )\) with model family \(M&apos;_{\theta }\) and the improper prior
</p>

<p>
\[f_\Theta (\theta )= \begin {cases} 1 &amp; \text { for }0&lt;\theta _1&lt;\theta _2&lt;\ldots &lt;\theta _n, \\ 0 &amp; \text { otherwise.} \end {cases}\]
</p>

<p>
By Theorem <a href="Bayesian-models-continuous-data.html#t:bayes_thm_continuous_data">3.1.2</a> we obtain that the posterior distribution has p.d.f.&nbsp;
</p>

<span class="hidden"> \(\seteqnumber{0}{8.}{12}\)</span>

<!--
                                
                                              (θi −xi )2
                                                          
                                exp − 1 n
                                       P
                                
                                      2   i=1     vi           for 0 < θ1 < θ2 < . . . < θn ,
               fΘ|{X=x} (θ) ∝                                                                                        (8.13)                                                          --><a id="eq:radiocarbon_post"></a><!--
                                
                                0
                                                              otherwise.

-->

<p>


\begin{equation}
\label {eq:radiocarbon_post} f_{\Theta |_{\{X=x\}}}(\theta ) \propto \begin{cases} \exp \l (-\frac 12\sum _{i=1}^n\frac {(\theta _i-x_i)^2}{v_i}\r ) &amp; \text { for
}0&lt;\theta _1&lt;\theta _2&lt;\ldots &lt;\theta _n, \\ 0 &amp; \text { otherwise.} \end {cases}
\end{equation}


</p>

<p>
This is the same density as \(M&apos;_\theta \), except now we treat \(\theta \) rather than \(x\) as the variable. The density is symmetric in \(x\) and \(\theta \) so we already know this distribution. It is
the distribution of \(\theta \sim \Normal (x_1,v_1)\otimes \ldots \otimes \Normal (x_n,v_n)\) conditioned on the event \(0&lt;\theta _1&lt;\theta _2&lt;\ldots &lt;\theta _n\). One way to
simulate samples of this distribution is via rejection sampling: simulate \(\theta \sim \Normal (x_1,v_1)\otimes \ldots \otimes \Normal (x_n,v_n)\) and reject the sample \(\theta \) until it satisfies
\(0&lt;\theta _1&lt;\theta _2&lt;\ldots &lt;\theta _n\). The trouble is that unless \(n\) is small, we will mostly end up rejecting the samples because the condition we have imposed is an unlikely one.
</p>

<p>
From <span class="textup">(<a href="Gibbs-sampling.html#eq:radiocarbon_post">8.13</a>)</span> and <span class="textup">(<a
href="Gibbs-sampling.html#eq:full_conditionals">8.12</a>)</span> we have full conditionals given by
</p>
<span class="hidden"> \(\seteqnumber{0}{8.}{13}\)</span>



<!--
                                                                                                                 
                                                                                                                                         (θj −xi )2
                                                                                                                                                     
                                                                                                                 exp − 1 n
                                                                                                                 
                                                                                                                                                          for θi ∈ (θi−1 , θi+1 ),
                                                                                                                        P
                                                                                                                                2    j=1     vi
                                                                                 fΘi |{Θ−i =θ−i , X=x} (θi ) ∝
                                                                                                                 
                                                                                                                 0
                                                                                                                                                         otherwise
                                                                                                                 
                                                                                                                                   2
                                                                                                                                    
                                                                                                                 exp − 1 (θi −xi )
                                                                                                                 
                                                                                                                 
                                                                                                                                2    vi          for θi ∈ (θi−1 , θi+1 ),
                                                                                                             ∝
                                                                                                                 
                                                                                                                 0
                                                                                                                                                otherwise


-->



<p>


\begin{align*}
f_{\Theta _{i}|_{\{\Theta _{-i}=\theta _{-i},\,X=x\}}}(\theta _i) &amp;\propto \begin{cases} \exp \l (-\frac 12\sum _{j=1}^n\frac {(\theta _j-x_i)^2}{v_i}\r ) &amp; \text { for
}\theta _i\in (\theta _{i-1},\theta _{i+1}), \\ 0 &amp; \text { otherwise} \end {cases} \\ &amp;\propto \begin{cases} \exp \l (-\frac 12\frac {(\theta _i-x_i)^2}{v_i}\r ) &amp;
\text { for }\theta _i\in (\theta _{i-1},\theta _{i+1}), \\ 0 &amp; \text { otherwise} \end {cases}
\end{align*}
(where we set \(\theta _0=0\) and \(\theta _{n+1}=\infty \) to make convenient notation). Note that \(\theta _i\) is the only variable here, and the second line follows because \(\theta _{-i}\) and \(x\)
are treated as constants. We recognize this full conditional distribution as that of \(\theta _i\sim N(x_i,v_i)\) conditioned on the event \(\theta _i\in (\theta _{i-1},\theta _{i+1})\). These full
conditionals are much easier to sample from: we use rejection sampling, sample \(\theta _i\sim \Normal (x_i,v_i)\) and reject until we obtain a sample for which \(\theta _i\in (\theta _{i-1},\theta
_{i+1})\). Hence, in this situation we have all the necessary ingredients to use a Gibbs sampler.
</p>


</li>

</ul>

</div>

</section>

</main>

</div>

<footer>

<p>
Copyright Nic Freeman, Sheffield University, last updated November 29, 2024
</p>

</footer>



<nav class="botnavigation"><a href="notes.html" class="linkhome" >
Home</a></nav>

</body>
</html>
