<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Nic Freeman" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="MAS352/452/6052 Stochastic Processes and Financial Mathematics, Sheffield University, June 7, 2021." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<!--[if lt IE 9]>
<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
<title>MASx52 â€” Conditional expectation and martingales</title>
<link rel="stylesheet" type="text/css" href="sans-serif-lwarp-sagebrush.css" />


<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
     subequations: "0",
     section: "",
     loader: {
         load: ['[tex]/tagFormat'],
     },
     startup: {
         ready() {
             //       These would be replaced by import commands if you wanted to make
             //       a proper extension.
             const Configuration = MathJax._.input.tex.Configuration.Configuration;
             const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
             const Macro = MathJax._.input.tex.Symbol.Macro;
             const TexError = MathJax._.input.tex.TexError.default;
             const ParseUtil = MathJax._.input.tex.ParseUtil.default;
             const expandable = MathJax._.util.Options.expandable;


             //       Insert the replacement string into the TeX string, and check
             //       that there haven't been too many maxro substitutions (prevents
             //       infinite loops).
             const useArgument = (parser, text) => {
                  parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
                  parser.i = 0;
                  if (++parser.macroCount > parser.configuration.options.maxMacros) {
                      throw new TexError('MaxMacroSub1',
                      'MathJax maximum macro substitution count exceeded; ' +
                      'is there a recursive macro call?');
                  }
             }


             //       Create the command map for \ifstar, \ifnextchar, \seteqnumber
             new CommandMap('ifstar-ifnextchar-setequnumber', {
                  ifstar: 'IfstarFunction',
                  ifnextchar: 'IfnextcharFunction',
                  seteqnumber: 'SeteqnumberFunction'
             }, {
                  //      This function implements an ifstar macro.
                  IfstarFunction(parser, name) {
                      const resultstar = parser.GetArgument(name);
                      const resultnostar = parser.GetArgument(name);
                      const star = parser.GetStar();                        // true if there is a *
                      useArgument(parser, star ? resultstar : resultnostar);
                  },


                  //      This function implements an ifnextchar macro.
                  IfnextcharFunction(parser, name) {
                      let whichchar = parser.GetArgument(name);
                      if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
                          // $ syntax highlighting
                          whichchar = String.fromCodePoint(parseInt(whichchar));
                      }
                      const resultnextchar = parser.GetArgument(name);
                      const resultnotnextchar = parser.GetArgument(name);
                      const gotchar = (parser.GetNext() === whichchar);
                      useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
                  },


                  //      This function modifies the equation numbers.
                  SeteqnumberFunction(parser, name) {
                          //   Get the macro parameters
                          const star = parser.GetStar();                       // true if there is a *
                          const optBrackets = parser.GetBrackets(name);        // contents of optional brackets
                          const newsubequations = parser.GetArgument(name);       // the subequations argument
                          const neweqsection = parser.GetArgument(name);       // the eq section argument
                          const neweqnumber = parser.GetArgument(name);        // the eq number argument
                          MathJax.config.subequations=newsubequations ;        // a string with boolean meaning
                          MathJax.config.section=neweqsection ;                // a string with numeric meaning
                          parser.tags.counter = parser.tags.allCounter = neweqnumber ;
                  }
             });


             //       Create the ifstar-ifnextchar-setequnumber package
             Configuration.create('ifstar-ifnextchar-setequnumber', {
                  handler: {macro: ['ifstar-ifnextchar-setequnumber']}
             });


             MathJax.startup.defaultReady();


             // For forward references:
             MathJax.startup.input[0].preFilters.add(({math}) => {
                  if (math.inputData.recompile){
                          MathJax.config.subequations = math.inputData.recompile.subequations;
                          MathJax.config.section = math.inputData.recompile.section;
                  }
             });
             MathJax.startup.input[0].postFilters.add(({math}) => {
                  if (math.inputData.recompile){
                          math.inputData.recompile.subequations = MathJax.config.subequations;
                          math.inputData.recompile.section = MathJax.config.section;
                  }
             });
         }       // ready
     },           // startup


     tex: {
         packages: {'[+]': ['tagFormat', 'ifstar-ifnextchar-setequnumber']},
         tags: "ams",
                  tagFormat: {
                          number: function (n) {
                               if(MathJax.config.subequations==0)
                                      return(MathJax.config.section + n);
                               else
                                      return(MathJax.config.section + String.fromCharCode(96+n));
                          },
                  },
     }
}
</script>


<script
         id="MathJax-script"
         src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
></script>


</head>
<body>



<a id="notes_1-autopage-81"></a>
<nav class="topnavigation" ><a href="notes_1.html" class="linkhome" >
Home</a></nav>

<header>

<p>
last updated: June 7, 2021
</p>

</header>



<div class="bodyandsidetoc" >
<div class="sidetoccontainer" >



<nav class="sidetoc" >



<div class="sidetoctitle" >

<p>
<span class="sidetocthetitle" >Stochastic Processes and Financial Mathematics<br />
(part one)</span>
</p>

<p>
Contents
</p>
</div>



<div class="sidetoccontents" >

<p>
<a href="notes_1.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Introduction.html#autosec-5" class="tocchapter" >
<span class="sectionnumber" >0</span>&#x2003;Introduction</a>
</p>



<p>
<a href="Introduction.html#autosec-6" class="tocsection" >
<span class="sectionnumber" >0.1</span>&#x2003;Organization</a>
</p>



<p>
<a href="Expectation-Arbitrage.html#autosec-13" class="tocchapter" >
<span class="sectionnumber" >1</span>&#x2003;Expectation and Arbitrage</a>
</p>



<p>
<a href="Expectation-Arbitrage.html#autosec-14" class="tocsection" >
<span class="sectionnumber" >1.1</span>&#x2003;Betting on coin tosses</a>
</p>



<p>
<a href="The-one-period-market.html#autosec-17" class="tocsection" >
<span class="sectionnumber" >1.2</span>&#x2003;The one-period market</a>
</p>



<p>
<a href="Arbitrage.html#autosec-22" class="tocsection" >
<span class="sectionnumber" >1.3</span>&#x2003;Arbitrage</a>
</p>



<p>
<a href="Modelling-discussion.html#autosec-32" class="tocsection" >
<span class="sectionnumber" >1.4</span>&#x2003;Modelling discussion</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-pricing.html#autosec-34" class="tocsection" >
<span class="sectionnumber" >1.5</span>&#x2003;Exercises on Chapter&nbsp;<a href="Expectation-Arbitrage.html#chap:pricing">1</a></a>
</p>



<p>
<a href="Probability-spaces-random-variables.html#autosec-38" class="tocchapter" >
<span class="sectionnumber" >2</span>&#x2003;Probability spaces and random variables</a>
</p>



<p>
<a href="Probability-spaces-random-variables.html#autosec-39" class="tocsection" >
<span class="sectionnumber" >2.1</span>&#x2003;Probability measures and \(\sigma \)-fields</a>
</p>



<p>
<a href="Random-variables.html#autosec-49" class="tocsection" >
<span class="sectionnumber" >2.2</span>&#x2003;Random variables</a>
</p>



<p>
<a href="Infinite.html#autosec-63" class="tocsection" >
<span class="sectionnumber" >2.3</span>&#x2003;Infinite \(\Omega \)</a>
</p>



<p>
<a href="Expectation.html#autosec-69" class="tocsection" >
<span class="sectionnumber" >2.4</span>&#x2003;Expectation</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-prob_meas.html#autosec-77" class="tocsection" >
<span class="sectionnumber" >2.5</span>&#x2003;Exercises on Chapter <a href="Probability-spaces-random-variables.html#chap:prob_meas">2</a></a>
</p>



<p>
<a href="Conditional-expectation-martingales.html#autosec-82" class="tocchapter" >
<span class="sectionnumber" >3</span>&#x2003;Conditional expectation and martingales</a>
</p>



<p>
<a href="Conditional-expectation-martingales.html#autosec-83" class="tocsection" >
<span class="sectionnumber" >3.1</span>&#x2003;Conditional expectation</a>
</p>



<p>
<a href="Properties-conditional-expectation.html#autosec-89" class="tocsection" >
<span class="sectionnumber" >3.2</span>&#x2003;Properties of conditional expectation</a>
</p>



<p>
<a href="Martingales.html#autosec-95" class="tocsection" >
<span class="sectionnumber" >3.3</span>&#x2003;Martingales</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-cond_exp.html#autosec-106" class="tocsection" >
<span class="sectionnumber" >3.4</span>&#x2003;Exercises on Chapter <a href="Conditional-expectation-martingales.html#chap:cond_exp">3</a></a>
</p>



<p>
<a href="Stochastic-processes.html#autosec-110" class="tocchapter" >
<span class="sectionnumber" >4</span>&#x2003;Stochastic processes</a>
</p>



<p>
<a href="Stochastic-processes.html#autosec-112" class="tocsection" >
<span class="sectionnumber" >4.1</span>&#x2003;Random walks</a>
</p>



<p>
<a href="Urn-processes.html#autosec-118" class="tocsection" >
<span class="sectionnumber" >4.2</span>&#x2003;Urn processes</a>
</p>



<p>
<a href="A-branching-process.html#autosec-123" class="tocsection" >
<span class="sectionnumber" >4.3</span>&#x2003;A branching process</a>
</p>



<p>
<a href="Other-stochastic-processes.html#autosec-127" class="tocsection" >
<span class="sectionnumber" >4.4</span>&#x2003;Other stochastic processes</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-stoch_procs.html#autosec-130" class="tocsection" >
<span class="sectionnumber" >4.5</span>&#x2003;Exercises on Chapter <a href="Stochastic-processes.html#chap:stoch_procs">4</a></a>
</p>



<p>
<a href="The-binomial-model.html#autosec-134" class="tocchapter" >
<span class="sectionnumber" >5</span>&#x2003;The binomial model</a>
</p>



<p>
<a href="The-binomial-model.html#autosec-135" class="tocsection" >
<span class="sectionnumber" >5.1</span>&#x2003;Arbitrage in the one-period model</a>
</p>



<p>
<a href="Hedging-in-one-period-model.html#autosec-143" class="tocsection" >
<span class="sectionnumber" >5.2</span>&#x2003;Hedging in the one-period model</a>
</p>



<p>
<a href="Types-financial-derivative.html#autosec-154" class="tocsection" >
<span class="sectionnumber" >5.3</span>&#x2003;Types of financial derivative</a>
</p>



<p>
<a href="The-binomial-model-definition.html#autosec-156" class="tocsection" >
<span class="sectionnumber" >5.4</span>&#x2003;The binomial model (definition)</a>
</p>



<p>
<a href="Portfolios-arbitrage-martingales.html#autosec-160" class="tocsection" >
<span class="sectionnumber" >5.5</span>&#x2003;Portfolios, arbitrage and martingales</a>
</p>



<p>
<a href="Hedging.html#autosec-169" class="tocsection" >
<span class="sectionnumber" >5.6</span>&#x2003;Hedging</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-bin_model.html#autosec-178" class="tocsection" >
<span class="sectionnumber" >5.7</span>&#x2003;Exercises on Chapter <a href="The-binomial-model.html#chap:bin_model">5</a></a>
</p>



<p>
<a href="Convergence-random-variables.html#autosec-183" class="tocchapter" >
<span class="sectionnumber" >6</span>&#x2003;Convergence of random variables</a>
</p>



<p>
<a href="Convergence-random-variables.html#autosec-184" class="tocsection" >
<span class="sectionnumber" >6.1</span>&#x2003;Modes of convergence</a>
</p>



<p>
<a href="The-monotone-convergence-theorem.html#autosec-190" class="tocsection" >
<span class="sectionnumber" >6.2</span>&#x2003;The monotone convergence theorem</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-rv_conv.html#autosec-195" class="tocsection" >
<span class="sectionnumber" >6.3</span>&#x2003;Exercises on Chapter <a href="Convergence-random-variables.html#chap:rv_conv">6</a></a>
</p>



<p>
<a href="Stochastic-processes-martingale-theory.html#autosec-200" class="tocchapter" >
<span class="sectionnumber" >7</span>&#x2003;Stochastic processes and martingale theory</a>
</p>



<p>
<a href="Stochastic-processes-martingale-theory.html#autosec-201" class="tocsection" >
<span class="sectionnumber" >7.1</span>&#x2003;The martingale transform</a>
</p>



<p>
<a href="Roulette.html#autosec-204" class="tocsection" >
<span class="sectionnumber" >7.2</span>&#x2003;Roulette</a>
</p>



<p>
<a href="The-martingale-convergence-theorem.html#autosec-210" class="tocsection" >
<span class="sectionnumber" >7.3</span>&#x2003;The martingale convergence theorem</a>
</p>



<p>
<a href="Long-term-behaviour-stochastic-processes.html#autosec-218" class="tocsection" >
<span class="sectionnumber" >7.4</span>&#x2003;Long term behaviour of stochastic processes</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#autosec-237" class="tocsection" >
<span class="sectionnumber" >7.5</span>&#x2003;Exercises on Chapter <a href="Stochastic-processes-martingale-theory.html#chap:stoch_procs_1">7</a></a>
</p>



<p>
<a href="Further-theory-stochastic-processes.html#autosec-242" class="tocchapter" >
<span class="sectionnumber" >8</span>&#x2003;Further theory of stochastic processes \((\Delta )\)</a>
</p>



<p>
<a href="Further-theory-stochastic-processes.html#autosec-243" class="tocsection" >
<span class="sectionnumber" >8.1</span>&#x2003;The dominated convergence theorem (\(\Delta \))</a>
</p>



<p>
<a href="The-optional-stopping-theorem.html#autosec-248" class="tocsection" >
<span class="sectionnumber" >8.2</span>&#x2003;The optional stopping theorem \((\Delta )\)</a>
</p>



<p>
<a href="Hitting-probabilities-random-walks.html#autosec-255" class="tocsection" >
<span class="sectionnumber" >8.3</span>&#x2003;Hitting probabilities of random walks \((\Delta )\)</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-stoch_procs_2.html#autosec-262" class="tocsection" >
<span class="sectionnumber" >8.4</span>&#x2003;Exercises on Chapter <a href="Further-theory-stochastic-processes.html#chap:stoch_procs_2">8</a> \((\Delta )\)</a>
</p>



<p>
<a href="Solutions-exercises.html#autosec-266" class="tocchapter" >
<span class="sectionnumber" >A</span>&#x2003;Solutions to exercises</a>
</p>



<p>
<a href="Formula-Sheet-part-one.html#autosec-283" class="tocchapter" >
<span class="sectionnumber" >B</span>&#x2003;Formula Sheet (part one)</a>
</p>



</div>

</nav>

</div>



<div class="bodycontainer" >



<section class="textbody" >

<h1>Stochastic Processes and Financial Mathematics<br />
(part one)</h1>

<!--MathJax customizations:-->



<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\DeclareMathOperator {\var }{var}\)

\(\DeclareMathOperator {\cov }{cov}\)

\(\newcommand {\nN }{n \in \mathbb {N}}\)

\(\newcommand {\Br }{{\cal B}(\R )}\)

\(\newcommand {\F }{{\cal F}}\)

\(\newcommand {\ds }{\displaystyle }\)

\(\newcommand {\st }{\stackrel {d}{=}}\)

\(\newcommand {\uc }{\stackrel {uc}{\rightarrow }}\)

\(\newcommand {\la }{\langle }\)

\(\newcommand {\ra }{\rangle }\)

\(\newcommand {\li }{\liminf _{n \rightarrow \infty }}\)

\(\newcommand {\ls }{\limsup _{n \rightarrow \infty }}\)

\(\newcommand {\limn }{\lim _{n \rightarrow \infty }}\)

\(\def \ra {\Rightarrow }\)

\(\def \to {\rightarrow }\)

\(\def \iff {\Leftrightarrow }\)

\(\def \sw {\subseteq }\)

\(\def \wt {\widetilde }\)

\(\def \mc {\mathcal }\)

\(\def \mb {\mathbb }\)

\(\def \sc {\setminus }\)

\(\def \v {\textbf }\)

\(\def \p {\partial }\)

\(\def \E {\mb {E}}\)

\(\def \P {\mb {P}}\)

\(\def \R {\mb {R}}\)

\(\def \C {\mb {C}}\)

\(\def \N {\mb {N}}\)

\(\def \Q {\mb {Q}}\)

\(\def \Z {\mb {Z}}\)

\(\def \B {\mb {B}}\)

\(\def \~{\sim }\)

\(\def \-{\,;\,}\)

\(\def \|{\,|\,}\)

\(\def \qed {$\blacksquare $}\)

\(\def \1{\unicode {x1D7D9}}\)

\(\def \cadlag {c\â€˜{a}dl\â€˜{a}g}\)

\(\def \p {\partial }\)

\(\def \l {\left }\)

\(\def \r {\right }\)

\(\def \F {\mc {F}}\)

\(\def \G {\mc {G}}\)

\(\def \H {\mc {H}}\)

\(\def \Om {\Omega }\)

\(\def \om {\omega }\)

</div>

<p>
<h3 id="autosec-82">Chapter&nbsp;<span class="sectionnumber" >3&#x2003;</span>Conditional expectation and martingales</h3>
<a id="notes_1-autopage-82"></a>
<a id="notes_1-autofile-12"></a>

<a id="chap:cond_exp"></a>

<p>
We will introduce conditional expectation, which provides us with a way to estimate random quantities based on only partial information. We will also introduce martingales, which are the mathematical way to
capture the concept of a fair game.
</p>
<h4 id="autosec-83"><span class="sectionnumber" >3.1&#x2003;</span>Conditional expectation</h4>
<a id="notes_1-autopage-83"></a>



<p>
Suppose \(X\) and \(Z\) are random variables that take on only finitely many values \(\{x_1,\ldots ,x_m\}\) and \(\{z_1,\ldots ,z_n\}\), respectively. In earlier courses, â€˜conditional expectationâ€™ was defined
as follows:
</p>

<span class="hidden" > \(\seteqnumber{0}{3.}{0}\)</span>



<!--



                                    P[X = xi | Z = zj ] = P[X = xi , Z = zj ]/P[Z = zj ]
                                                            X
                                         E[X | Z = zj ] =        xi P[X = xi | Z = zj ]
                                                             i
                                 Y = E[X | Z] where:         if \(Z(\om )=z_j\), then \(Y(\om )=\E [X\|Z=z_j]\)                                   --><a id="naivecondexp"></a><!--                                     (3.1)



-->



<p>


\begin{eqnarray}
\P [X=x_i\|Z=z_j] &amp;=&amp; \P [X=x_i,Z=z_j] / \P [Z=z_j] \notag \\ \E [X\|Z=z_j] &amp;=&amp; \sum _i x_i \P [X=x_i\|Z=z_j] \notag \\ Y = \E [X\|Z] \mbox { where:} &amp;&amp;
\mbox { if $Z(\om )=z_j$, then $Y(\om )=\E [X\|Z=z_j]$} \label {naivecondexp}
\end{eqnarray}


</p>

<p>
You might also have seen a second definition, using probability density functions, for continuous random variables. These definitions are problematic, for several reasons, chiefly (1) its not immediately clear how the
two definitions interact and (2) we donâ€™t want to be restricted to handling only discrete or only continuous random variables.
</p>

<p>
In this section, we define the conditional expectation of random variables using \(\sigma \)-fields. In this setting we are able to give a unified definition which is valid for general random variables. The definition is
originally due to Kolmogorov (in 1933), and is sometimes referred to as Kolmogorovâ€™s conditional expectation. It is one of the most important concepts in modern probability theory.
</p>

<p>
Conditional expectation is a mathematical tool with the following function. We have a probability space \((\Omega ,\mc {F},\P )\) and a random variable \(X:\Omega \to \R \). However, \(\mc {F}\) is large
and we want to work with a sub-\(\sigma \)-algebra \(\mc {G}\), instead. As a result, we want to have a random variable \(Y\) such that
</p>
<ul style="list-style-type:none">


<li>
<p>
1. \(Y\) is \(\mc {G}\)-measurable
</p>


</li>
<li>
<p>
2. \(Y\) is â€˜the bestâ€™ way to approximate \(X\) with a \(\mc {G}\)-measurable random variable
</p>
</li>
</ul>

<p>
The second statement on this wish-list does not fully make sense; there are many different ways in which we could compare \(X\) to a potential \(Y\).
</p>

<p>
Why might we want to do this? Imagine we are conducting an experiment in which we gradually gain information about the result \(X\). This corresponds to gradually seeing a larger and larger \(\mc {G}\), with
access to more and more information. At all times we want to keep a prediction of what the future looks like, based on the currently available information. This prediction is \(Y\).
</p>

<p>
It turns out there is <i>only one</i> natural way in which to realize our wish-list (which is convenient, and somewhat surprising). It is the following:
</p>
<div class="theorembodytheorem" >

<ul style="list-style-type:none">



<a id="autoid-50"></a>

<li>

<p>
<span class="theoremheaderplain" >Theorem 3.1.1 (Conditional Expectation)</span> <a id="autoid-51" ></a ><a id="thm:cond_exp"></a> Let \(X\) be an \(L^1\) random variable on \((\Om ,\F ,\P
)\). Let \(\G \) be a sub-\(\sigma \)-field of \(\F \). Then there exists a random variable \(Y\in L^1\) such that
</p>
<ul style="list-style-type:none">


<li>
<p>
1. \(Y\) is \(\G \)-measurable,
</p>


</li>
<li>
<p>
2. for every \(G\in \G \), we have \(\E [Y\1_G]=\E [X\1_G]\).
</p>
</li>
</ul>

<p>
Moreover, if \(Yâ€™\in L^1\) is a second random variable satisfying these conditions, \(\P [Y=Yâ€™]=1\).
</p>


</li>

</ul>

</div>

<p>
The first and second statements here correspond respectively to the items on our wish-list.
</p>
<div class="theorembodydefn" >

<ul style="list-style-type:none">



<a id="autoid-52"></a>

<li>

<p>
<span class="theoremheaderplain" >Definition 3.1.2</span> <a id="autoid-53" ></a >We refer to \(Y\) as (a version of) the <i>conditional expectation</i> of \(X\) given \(\mc {G}\). and we write
</p>

<p>
\[Y=\E [X\|\mc {G}].\]
</p>

<p>


</p>


</li>

</ul>

</div>

<p>
Since any two such \(Y\) are almost surely equal so we sometimes refer to \(Y\) simply as <i>the</i> conditional expectation of \(X\). This is a slight abuse of notation, but it is commonplace and harmless.
</p>

<p>
Proof of Theorem <a href="Conditional-expectation-martingales.html#thm:cond_exp">3.1.1</a> is beyond the scope of this course. Loosely speaking, there is an abstract recipe which constructs \(\E
[X|\mc {G}]\). It begins with the random variable \(X\), and then averages out over all the information that is not accessible to \(\mc {G}\), leaving only as much randomness as \(\mc {G}\) can support, resulting
in \(\E [X|\mc {G}]\). In this sense the map \(X\mapsto \E [X|\mc {G}]\) simplifies (i.e.&nbsp;reduces the amount of randomness in) \(X\) in a very particular way, to make it \(\mc {G}\) measurable.
</p>

<p>
It is important to remember that \(\E [X|\mc {G}]\) is (in general) a random variable. It is also important to remember that the two objects
</p>

<p>
\[\E [X|\mc {G}]\hspace {1pc}\text { and }\hspace {1pc}\E [X|Z=z]\]
</p>

<p>
are quite different. They are both useful. We will explore the connection between them in Section <a href="Conditional-expectation-martingales.html#naivecondecpsec">3.1</a>. Before doing so, let us
look at a basic example.
</p>

<p>
Let \(X_1,X_2\) be independent random variables such that \(\P [X_i=-1]=\P [X_i=1]=\frac {1}{2}\). Set \(\mc {F}=\sigma (X_1,X_2)\). We will show that
</p>

<span class="hidden" > \(\seteqnumber{0}{3.}{1}\)</span>

<!--



                                                        E[X1 + X2 |Ïƒ(X1 )] = X1 .                                                         (3.2)                            --><a id="eq:condexpexguess"></a><!--



-->

<p>


\begin{equation}
\label {eq:condexpexguess} \E [X_1+X_2|\sigma (X_1)]=X_1.
\end{equation}


</p>

<p>
To do so, we should check that \(X_1\) satisfies the two conditions in Theorem <a href="Conditional-expectation-martingales.html#thm:cond_exp">3.1.1</a>, with
</p>
<span class="hidden" > \(\seteqnumber{0}{3.}{2}\)</span>



<!--



                                                                                                     X = X1 + X2

                                                                                                     Y = X1

                                                                                                     G = Ïƒ(X1 ).



-->



<p>


\begin{align*}
X&amp;=X_1+X_2\\ Y&amp;=X_1\\ \mc {G}&amp;=\sigma (X_1).
\end{align*}
The first condition is immediate, since by Lemma <a href="Random-variables.html#XXmeas">2.2.5</a> \(X_1\) is \(\sigma (X_1)\)-measurable i.e.&nbsp;\(Y\in m\mc {G}\). To see the second condition, let
\(G\in \sigma (X_1)\). Then \(\1_G\in \sigma (X_1)\) by Lemma <a href="Expectation.html#lem:indicator_meas">2.4.2</a> and \(X_2\in \sigma (X_2)\), and these \(\sigma \)-fields are
independent, so \(\1_G\) and \(X_2\) are independent. Hence
</p>
<span class="hidden" > \(\seteqnumber{0}{3.}{2}\)</span>



<!--



                                                                                       E[(X1 + X2 )1G ] = E[X1 1G ] + E[1G X2 ]

                                                                                                        = E[X1 1G ] + E[1G ]E[X2 ]

                                                                                                        = E[X1 1G ] + P[G].0

                                                                                                        = E[X1 1G ].



-->



<p>


\begin{align*}
\E [(X_1+X_2)\1_G] &amp;=\E [X_1\1_G]+\E [1_G X_2]\\ &amp;=\E [X_1\1_G]+\E [1_G]\E [X_2]\\ &amp;=\E [X_1\1_G]+\P [G].0\\ &amp;=\E [X_1\1_G].
\end{align*}
This equation says precisely that \(\E [X\1_G]=\E [Y\1_G]\). We have now checked both conditions, so by Theorem <a href="Conditional-expectation-martingales.html#thm:cond_exp">3.1.1</a> we have
\(\E [X|\mc {G}]=Y\), meaning that \(\E [X_1+X_2|\sigma (X_1)]=X_1\), which proves our claim in <span class="textup" >(<a
href="Conditional-expectation-martingales.html#eq:condexpexguess">3.2</a>)</span>.
</p>

<p>
The intuition for this, which is plainly visible in our calculation, is that \(X_2\) is independent of \(\sigma (X_1)\) so, thinking of conditional expectation as an operation which averages out all randomness in
\(X=X_1+X_2\) that is not \(\mc {G}=\sigma (X_1)\) measurable, we would average out \(X_2\) completely i.e.&nbsp;\(\E [X_2]=0\).
</p>

<p>
We could equally think of \(X_1\) as being our best guess for \(X_1+X_2\), given only information in \(\sigma (X_1)\), since \(\E [X_2]=0\). In general, guessing \(\E [X|\mc {G}]\) is not so easy!
</p>
<h5 id="autosec-86">Relationship to the naive definition \((\star )\)</h5>
<a id="notes_1-autopage-86"></a>



<a id="naivecondecpsec"></a>

<p>
Conditional expectation extends the â€˜naiveâ€™ definition of <span class="textup" >(<a href="Conditional-expectation-martingales.html#naivecondexp">3.1</a>)</span>. Naturally, the â€˜newâ€™ conditional
expectation is much more general (and, moreover, it is what we require later in the course), but we should still take the time to relate it to the naive definition.
</p>
<div class="theorembodyremark" >

<ul style="list-style-type:none">



<a id="autoid-54"></a>

<li>

<p>
<span class="theoremheaderplain" >Remark 3.1.3</span> <a id="autoid-55" ></a >This subsection is marked with a \((\star )\), meaning that it is non-examinable. This is so as you can forget the old
definition and remember the new one!
</p>


</li>

</ul>

</div>

<p>
To see the connection, we focus on the case where \(X,Z\) are random variables with finite sets of values \(\{x_1,\ldots ,x_n\}\), \(\{z_1,\ldots ,z_m\}\). Let \(Y\) be the naive version of conditional
expectation defined in <span class="textup" >(<a href="Conditional-expectation-martingales.html#naivecondexp">3.1</a>)</span>. That is,
</p>

<p>
\[Y(\omega )=\sum \limits _{j}\1_{\{Z(\omega )=z_j\}}\E [X|Z=z_j].\]
</p>

<p>
We can use Theorem <a href="Conditional-expectation-martingales.html#thm:cond_exp">3.1.1</a> to check that, in fact, \(Y\) is a version of \(\E [X|\sigma (Z)]\). We want to check that \(Y\) satisfies
the two properties listed in Theorem <a href="Conditional-expectation-martingales.html#thm:cond_exp">3.1.1</a>.
</p>
<ul style="list-style-type:none">


<li>
<p>
â€¢ Since \(Z\) only takes finitely many values \(\{z_1,\ldots ,z_m\}\), from the above equation we have that \(Y\) only takes finitely many values. These values are \(\{y_1,\ldots , y_m\}\) where \(y_j=\E
[X|Z=z_j]\). We note
</p>
<span class="hidden" > \(\seteqnumber{0}{3.}{2}\)</span>


<!--



                                                                                      Y âˆ’1 (yj ) = {Ï‰ âˆˆ â„¦ ; Y (Ï‰) = E[X|Z = zj ]}

                                                                                              = {Ï‰ âˆˆ â„¦ ; Z(Ï‰) = zj }

                                                                                              = Z âˆ’1 (zj ) âˆˆ Ïƒ(Z).



-->


<p>


\begin{align*}
Y^{-1}(y_j)&amp;=\{\omega \in \Omega \-Y(\omega )=\E [X|Z=z_j]\}\\ &amp;=\{\omega \in \Omega \-Z(\omega )=z_j\}\\ &amp;=Z^{-1}(z_j)\in \sigma (Z).
\end{align*}
This is sufficient (although we will omit the details) to show that \(Y\) is \(\sigma (Z)\)-measurable.
</p>


</li>
<li>
<p>
â€¢ We can calculate
</p>
<span class="hidden" > \(\seteqnumber{0}{3.}{2}\)</span>


<!--



                                                                                E[Y 1{Z = zj }] = yj E[1{Z = zj }]

                                                                                                = yj P[Z = zj ]
                                                                                                    X
                                                                                                =         xi P[X = xi |Z = zj ]P[Zj = zj ]
                                                                                                     i
                                                                                                    X
                                                                                                =         xi P[X = xi and Z = zj ]
                                                                                                     i

                                                                                                          xi 1{Z=zj } P[X = xi and Z = zj ]
                                                                                                    X
                                                                                                =
                                                                                                    i,j

                                                                                                = E[X 1{Z=zj } ].



-->


<p>


\begin{align*}
\E [Y\1\{Z=z_j\}]&amp;=y_j\E [\1\{Z=z_j\}]\\ &amp;=y_j\P [Z=z_j]\\ &amp;=\sum \limits _i x_i\P [X=x_i|Z=z_j]\P [Z_j=z_j]\\ &amp;=\sum \limits _i x_i \P [X=x_i\text { and
}Z=z_j]\\ &amp;=\sum \limits _{i,j}x_i\1_{\{Z=z_j\}}\P [X=x_i\text { and }Z=z_j]\\ &amp;=\E [X\1_{\{Z=z_j\}}].
\end{align*}
Properly, to check that \(Y\) satisfies the second property in Theorem <a href="Conditional-expectation-martingales.html#thm:cond_exp">3.1.1</a>, we need to check \(\E [Y\1_G]=\E [X\1_G]\) for a
general \(G\in \sigma (Z)\) and not just \(G=\{Z=z_j\}\). However, for reasons beyond the scope of this course, in this case (thanks to the fact that \(Z\) is finite) its enough to consider only \(G\) of the form
\(\{Z=z_j\}\).
</p>
</li>
</ul>

<p>
Therefore, we have \(Y=\E [X|\sigma (Z)]\) almost surely. In this course we favour writing \(\E [X|\sigma (Z)]\) instead of \(\E [X|Z]\), to make it clear that we are looking at conditional expectation with
respect to a \(\sigma \)-field.
</p>

</section>

</div>

</div>

<footer>

<p>
Copyright Nic Freeman, Sheffield University, last updated June 7, 2021
</p>

</footer>



<nav class="botnavigation" ><a href="notes_1.html" class="linkhome" >
Home</a></nav>

</body>
</html>
