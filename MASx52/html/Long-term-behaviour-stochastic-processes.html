<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Nic Freeman" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="MAS352/61023 Stochastic Processes and Financial Mathematics, Sheffield University, April 22, 2025." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>MAS352/61023 â€” Long term behaviour of stochastic processes</title>
<link rel="stylesheet" type="text/css" href="sans-serif-lwarp-sagebrush.css" />
<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
// \left, \right delimiters: https://github.com/mathjax/MathJax/issues/2535
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
  subequations: "0",
  section: "",
  loader: {
    load: ['[tex]/tagformat', '[tex]/textmacros'],
  },
  startup: {
    ready() {
      // These would be replaced by import commands if you wanted to make
      // a proper extension.
      const Configuration = MathJax._.input.tex.Configuration.Configuration;
      const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
      const Macro = MathJax._.input.tex.Symbol.Macro;
      const TexError = MathJax._.input.tex.TexError.default;
      const ParseUtil = MathJax._.input.tex.ParseUtil.default;
      const expandable = MathJax._.util.Options.expandable;

        // Insert the replacement string into the TeX string, and check
        // that there haven't been too many maxro substitutions (prevents
        // infinite loops).
        const useArgument = (parser, text) => {
          parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
          parser.i = 0;
          if (++parser.macroCount > parser.configuration.options.maxMacros) {
            throw new TexError('MaxMacroSub1',
            'MathJax maximum macro substitution count exceeded; ' +
            'is there a recursive macro call?');
          }
        }

        // Create the command map for:
        //     \ifstar, \ifnextchar, \ifblank, \ifstrequal, \gsub, \seteqnumber
        new CommandMap('Lwarp-macros', {
          ifstar: 'IfstarFunction',
          ifnextchar: 'IfnextcharFunction',
          ifblank: 'IfblankFunction',
          ifstrequal: 'IfstrequalFunction',
          gsubstitute: 'GsubstituteFunction',
          seteqnumber: 'SeteqnumberFunction'
        }, {
          // This function implements an ifstar macro.
          IfstarFunction(parser, name) {
             const resultstar = parser.GetArgument(name);
             const resultnostar = parser.GetArgument(name);
             const star = parser.GetStar();                 // true if there is a *
             useArgument(parser, star ? resultstar : resultnostar);
          },

          // This function implements an ifnextchar macro.
          IfnextcharFunction(parser, name) {
            let whichchar = parser.GetArgument(name);
            if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
              // $ syntax highlighting
              whichchar = String.fromCodePoint(parseInt(whichchar));
            }
            const resultnextchar = parser.GetArgument(name);
            const resultnotnextchar = parser.GetArgument(name);
            const gotchar = (parser.GetNext() === whichchar);
            useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
          },

          // This function implements an ifblank macro.
          IfblankFunction(parser, name) {
            const blankarg = parser.GetArgument(name);
            const resultblank = parser.GetArgument(name);
            const resultnotblank = parser.GetArgument(name);
            const isblank = (blankarg.trim() == "");
            useArgument(parser, isblank ? resultblank : resultnotblank);
          },

          // This function implements an ifstrequal macro.
          IfstrequalFunction(parser, name) {
            const strequalfirst = parser.GetArgument(name);
            const strequalsecond = parser.GetArgument(name);
            const resultequal = parser.GetArgument(name);
            const resultnotequal = parser.GetArgument(name);
            const isequal = (strequalfirst == strequalsecond);
            useArgument(parser, isequal ? resultequal : resultnotequal);
          },

          // This function implements a gsub macro.
          GsubstituteFunction(parser, name) {
            const gsubfirst = parser.GetArgument(name);
            const gsubsecond = parser.GetArgument(name);
            const gsubthird = parser.GetArgument(name);
            let gsubresult=gsubfirst.replace(gsubsecond, gsubthird);
            useArgument(parser, gsubresult);
          },

          // This function modifies the equation numbers.
          SeteqnumberFunction(parser, name) {
              // Get the macro parameters
              const star = parser.GetStar();                  // true if there is a *
              const optBrackets = parser.GetBrackets(name);   // contents of optional brackets
              const newsubequations = parser.GetArgument(name); // the subequations argument
              const neweqsection = parser.GetArgument(name); // the eq section argument
              const neweqnumber = parser.GetArgument(name);   // the eq number argument
              MathJax.config.subequations=newsubequations ;   // a string with boolean meaning
              MathJax.config.section=neweqsection ;           // a string with numeric meaning
              parser.tags.counter = parser.tags.allCounter = neweqnumber ;
          }

        });

        // Create the Lwarp-macros package
        Configuration.create('Lwarp-macros', {
          handler: {macro: ['Lwarp-macros']}
        });

        MathJax.startup.defaultReady();

        // For forward references:
        MathJax.startup.input[0].preFilters.add(({math}) => {
          if (math.inputData.recompile){
              MathJax.config.subequations = math.inputData.recompile.subequations;
              MathJax.config.section = math.inputData.recompile.section;
          }
        });
        MathJax.startup.input[0].postFilters.add(({math}) => {
          if (math.inputData.recompile){
              math.inputData.recompile.subequations = MathJax.config.subequations;
              math.inputData.recompile.section = MathJax.config.section;
          }
        });

          // For \left, \right with unicode-math:
          const {DelimiterMap} = MathJax._.input.tex.SymbolMap;
          const {Symbol} = MathJax._.input.tex.Symbol;
          const {MapHandler} = MathJax._.input.tex.MapHandler;
          const delimiter = MapHandler.getMap('delimiter');
          delimiter.add('\\lBrack', new Symbol('\\lBrack', '\u27E6'));
          delimiter.add('\\rBrack', new Symbol('\\rBrack', '\u27E7'));
          delimiter.add('\\lAngle', new Symbol('\\lAngle', '\u27EA'));
          delimiter.add('\\rAngle', new Symbol('\\rAngle', '\u27EB'));
          delimiter.add('\\lbrbrak', new Symbol('\\lbrbrak', '\u2772'));
          delimiter.add('\\rbrbrak', new Symbol('\\rbrbrak', '\u2773'));
          delimiter.add('\\lbag', new Symbol('\\lbag', '\u27C5'));
          delimiter.add('\\rbag', new Symbol('\\rbag', '\u27C6'));
          delimiter.add('\\llparenthesis', new Symbol('\\llparenthesis', '\u2987'));
          delimiter.add('\\rrparenthesis', new Symbol('\\rrparenthesis', '\u2988'));
          delimiter.add('\\llangle', new Symbol('\\llangle', '\u2989'));
          delimiter.add('\\rrangle', new Symbol('\\rrangle', '\u298A'));
          delimiter.add('\\Lbrbrak', new Symbol('\\Lbrbrak', '\u27EC'));
          delimiter.add('\\Rbrbrak', new Symbol('\\Rbrbrak', '\u27ED'));
          delimiter.add('\\lBrace', new Symbol('\\lBrace', '\u2983'));
          delimiter.add('\\rBrace', new Symbol('\\rBrace', '\u2984'));
          delimiter.add('\\lParen', new Symbol('\\lParen', '\u2985'));
          delimiter.add('\\rParen', new Symbol('\\rParen', '\u2986'));
          delimiter.add('\\lbrackubar', new Symbol('\\lbrackubar', '\u298B'));
          delimiter.add('\\rbrackubar', new Symbol('\\rbrackubar', '\u298C'));
          delimiter.add('\\lbrackultick', new Symbol('\\lbrackultick', '\u298D'));
          delimiter.add('\\rbracklrtick', new Symbol('\\rbracklrtick', '\u298E'));
          delimiter.add('\\lbracklltick', new Symbol('\\lbracklltick', '\u298F'));
          delimiter.add('\\rbrackurtick', new Symbol('\\rbrackurtick', '\u2990'));
          delimiter.add('\\langledot', new Symbol('\\langledot', '\u2991'));
          delimiter.add('\\rangledot', new Symbol('\\rangledot', '\u2992'));
          delimiter.add('\\lparenless', new Symbol('\\lparenless', '\u2993'));
          delimiter.add('\\rparengtr', new Symbol('\\rparengtr', '\u2994'));
          delimiter.add('\\Lparengtr', new Symbol('\\Lparengtr', '\u2995'));
          delimiter.add('\\Rparenless', new Symbol('\\Rparenless', '\u2996'));
          delimiter.add('\\lblkbrbrak', new Symbol('\\lblkbrbrak', '\u2997'));
          delimiter.add('\\rblkbrbrak', new Symbol('\\rblkbrbrak', '\u2998'));
          delimiter.add('\\lvzigzag', new Symbol('\\lvzigzag', '\u29D8'));
          delimiter.add('\\rvzigzag', new Symbol('\\rvzigzag', '\u29D9'));
          delimiter.add('\\Lvzigzag', new Symbol('\\Lvzigzag', '\u29DA'));
          delimiter.add('\\Rvzigzag', new Symbol('\\Rvzigzag', '\u29DB'));
          delimiter.add('\\lcurvyangle', new Symbol('\\lcurvyangle', '\u29FC'));
          delimiter.add('\\rcurvyangle', new Symbol('\\rcurvyangle', '\u29FD'));
          delimiter.add('\\Vvert', new Symbol('\\Vvert', '\u2980'));
    }     // ready
  },      // startup

  tex: {
    packages: {'[+]': ['tagformat', 'Lwarp-macros', 'textmacros']},
    tags: "ams",
         tagformat: {
             number: function (n) {
                 if(MathJax.config.subequations==0)
                     return(MathJax.config.section + n);
                 else
                     return(MathJax.config.section + String.fromCharCode(96+n));
             },
         },
  }
}
</script>

<script
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4222H8D03"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4222H8D03');
</script>
<!-- Google tag (gtag.js) -->


</head>
<body>



<a id="notes_1-autopage-215"></a>
<nav class="topnavigation"><a href="notes_1.html" class="linkhome" >
Home</a></nav>

<header>

<p>
last updated: April 22, 2025
</p>

</header>



<div class="bodyandsidetoc">
<div class="sidetoccontainer">



<nav class="sidetoc">



<div class="sidetoctitle">

<p>
<span class="sidetocthetitle">Stochastic Processes and Financial Mathematics<br />
(part one)</span>
</p>

<p>
Contents
</p>
</div>



<div class="sidetoccontents">

<p>
<a href="notes_1.html" class="linkhome" >
Home</a>
</p>

</div>

</nav>

</div>



<main class="bodycontainer">



<section class="textbody">

<h1>Stochastic Processes and Financial Mathematics<br />
(part one)</h1>

<!--MathJax customizations:-->
<div data-nosnippet
      style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\DeclareMathOperator {\var }{var}\)

\(\DeclareMathOperator {\cov }{cov}\)

\(\def \ra {\Rightarrow }\)

\(\def \to {\rightarrow }\)

\(\def \iff {\Leftrightarrow }\)

\(\def \sw {\subseteq }\)

\(\def \wt {\widetilde }\)

\(\def \mc {\mathcal }\)

\(\def \mb {\mathbb }\)

\(\def \sc {\setminus }\)

\(\def \v {\textbf }\)

\(\def \p {\partial }\)

\(\def \E {\mb {E}}\)

\(\def \P {\mb {P}}\)

\(\def \R {\mb {R}}\)

\(\def \C {\mb {C}}\)

\(\def \N {\mb {N}}\)

\(\def \Q {\mb {Q}}\)

\(\def \Z {\mb {Z}}\)

\(\def \B {\mb {B}}\)

\(\def \~{\sim }\)

\(\def \-{\,;\,}\)

\(\def \|{\,|\,}\)

\(\def \qed {$\blacksquare $}\)

\(\def \1{\unicode {x1D7D9}}\)

\(\def \cadlag {c\&grave;{a}dl\&grave;{a}g}\)

\(\def \p {\partial }\)

\(\def \l {\left }\)

\(\def \r {\right }\)

\(\def \F {\mc {F}}\)

\(\def \G {\mc {G}}\)

\(\def \H {\mc {H}}\)

\(\def \Om {\Omega }\)

\(\def \om {\omega }\)

</div>

<!--
......     section Long term behaviour of stochastic processes ......
-->
<h4 id="autosec-216"><span class="sectionnumber">7.4&#x2003;</span>Long term behaviour of stochastic processes</h4>
<a id="notes_1-autopage-216"></a>
<a id="notes_1-autofile-34"></a>

<p>
Our next step is to use the martingale convergence theorem to look at the behaviour as \(t\to \infty \) of various stochastic processes. We will begin with Roulette, from Section <a
href="notes_1.html#??">??</a>, and then move on to the trio of stochastic processes (random walks, urns, branching processes) that we introduced in Chapter <a href="notes_1.html#??">??</a>.
</p>

<p>
One fact, from real analysis, that we will find useful is the following:
</p>
<div class="theorembodylemma">

<ul class="list" style="list-style-type:none">



<a id="autoid-156"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Lemma 7.4.1</span></span> <a id="autoid-157" ></a ><a id="l:Z_ev_const"></a> Let \((a_n)\) be an integer valued sequence, and
suppose that \(a_n\to a\) as \(n\to \infty \), where \(a\in \R \). Then \((a_n)\) is eventually equal to a constant: there exists \(N\in \N \) such that \(a_n=a\) for all \(n\geq N\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc">Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> Put \(\epsilon =\frac 13\) into the definition of a convergent real sequence, and we
obtain that there exists \(N\in \N \) such that \(|a_n-a|\leq \frac 13\) for all \(n\geq N\). Hence, for \(n\geq N\) we have
</p>
<span class="hidden"> \(\seteqnumber{0}{7.}{4}\)</span>



<!--



                                                                          |an âˆ’ an+1 | = |an âˆ’ a + a âˆ’ an+1 | â‰¤ |an âˆ’ a| + |a âˆ’ an+1 |

                                                                                                             â‰¤ 31 + 13

                                                                                                             = 23 .



-->



<p>


\begin{align*}
|a_n-a_{n+1}|=|a_n-a+a-a_{n+1}| &amp;\leq |a_n-a|+|a-a_{n+1}|\\ &amp;\leq \tfrac 13+\tfrac 13\\ &amp;=\tfrac 23.
\end{align*}
Since \(\frac 23&lt;1\), and \(a_n\) takes only integer values, this means that \(a_n=a_{n+1}\). Since this holds for all \(n\geq N\), we must have \(a_N=a_{N+1}=a_{N+2}=\ldots \), which means that
\(a_n\to a_N\) as \(N\to \infty \) (and hence \(a=a_N\)). &#x2003;&#x2003;&#x220E;
</p>
<!--
......   subsection Long term behaviour of Roulette ......
-->
<h5 id="autosec-218">Long term behaviour of Roulette</h5>
<a id="notes_1-autopage-218"></a>



<a id="s:roulette_long_term"></a>

<p>
Let us think about what happens to our Roulette player, from Section <a href="notes_1.html#??">??</a>.
</p>

<p>
Recall that our gambler bets an amount \(C_{n-1}\in \mc {F}_{n-1}\) on play \(n\). On each play, our gambler increases his wealth, by \(C_{n-1}\), with probability \(\frac {18}{37}\), or decreases his
wealth, by \(C_{n-1}\), with probability \(\frac {19}{37}\). We showed in Section <a href="notes_1.html#??">??</a> that his profit/loss after \(n\) plays was a supermartingale, \((C\circ M)_n.\) Thus, if
our gambler starts with an amount of money \(K\in \N \) at time \(0\), then at time \(n\) they have an amount of money given by
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{4}\)</span>

<!--



                                         Wn = K + (C â—¦ M )n .                                            (7.5)                                                   --><a id="eq:roulette_winnings"></a><!--

-->

<p>


\begin{equation}
\label {eq:roulette_winnings} W_n=K+(C\circ M)_n.
\end{equation}


</p>

<p>
Weâ€™ll assume that our gambler keeps betting until they run out of money, so we have \(C_n\geq 1\) and \(W_n\geq 0\) for all \(n\) before they run out of money (and, if and when they do run out, \(C_n=0\) for
all remaining \(n\)). Since money is a discrete quantity, we can assume that \(K\) and \(C_n\) are integers, hence \(W_n\) is also always an integer.
</p>

<p>
From Section <a href="notes_1.html#??">??</a> we know that \((C\circ M)_n\) is a supermartingale, hence \(W_n\) is also a supermartingale. Since \(W_n\geq 0\) we have \(\E [|W_n|]=\E [W_n]\leq \E
[W_0]\) so \((W_n)\) is uniformly bounded in \(L^1\). Hence, by the martingale convergence theorem, \(W_n\) is almost surely convergent.
</p>

<p>
By Lemma <a href="notes_1.html#??">??</a>, the only way that \(W_n\) can converge is if it becomes constant, eventually. Since each play results in a win (an increase) or a loss (a decrease) the only way
\(W_n\) can become eventually constant is if our gambler has lost all his money i.e.&nbsp;for some (random) \(N\in \N \), for all \(n\geq N\), we have \(W_n=0\). Thus:
</p>
<div class="theorembodylemma">

<ul class="list" style="list-style-type:none">



<a id="autoid-158"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Lemma 7.4.2</span></span> <a id="autoid-159" ></a >Almost surely, a roulette player will eventually lose all their money.
</p>


</li>

</ul>

</div>
<!--
......   subsection Long term behaviour of urn processes ......
-->
<h5 id="autosec-220">Long term behaviour of urn processes</h5>
<a id="notes_1-autopage-220"></a>



<a id="s:urn_long_term"></a>

<p>
We will look at the Po&#x0301;lya urn process introduced in Section <a href="notes_1.html#??">??</a>. Recall that we start our urn with \(2\) balls, one red and one black. Then, at each time
\(n=1,2,\ldots ,\) we draw a ball, uniformly at random, from the urn, and replace it alongside an additional ball of the same colour. Thus, at time \(n\) (which means: after the \(n^{th}\) draw is completed)
the urn contains \(n+2\) balls.
</p>

<p>
Recall also that we write \(B_n\) for the number of red balls in the urn at time \(n\), and
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{5}\)</span>

<!--


                                                            Bn
                                                    Mn =                                                         (7.6)                                                       --><a id="eq:urn_Mn2"></a><!--
                                                           n+2
-->

<p>


\begin{equation}
\label {eq:urn_Mn2} M_n=\frac {B_n}{n+2}
\end{equation}


</p>

<p>
for the fraction of red balls in the urn at time \(n\). We have shown in Section <a href="notes_1.html#??">??</a> that \(M_n\) is a martingale. Since \(M_n\in [0,1]\), we have \(\E [|M_n|]\leq 1\), hence
\((M_n)\) is uniformly bounded in \(L^1\) and the martingale convergence theorem applies. Therefore, there exists a random variable \(M_\infty \) such that \(M_n\stackrel {a.s.}{\to }M_\infty \). We
will show that:
</p>
<div class="theorembodyprop">

<ul class="list" style="list-style-type:none">



<a id="autoid-160"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Proposition 7.4.3</span></span> <a id="autoid-161" ></a ><a id="p:urn_limit"></a> \(M_\infty \) has the uniform distribution on
\([0,1]\).
</p>


</li>

</ul>

</div>
<div class="theorembodyremark">

<ul class="list" style="list-style-type:none">



<a id="autoid-162"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Remark 7.4.4</span></span> <a id="autoid-163" ></a >Results like Proposition <a href="notes_1.html#??">??</a> are extremely
useful, in stochastic modelling. It provides us with the following â€˜rule of thumbâ€™: if \(n\) is large, then the fraction of red balls in our urn is approximately a uniform distribution on \([0,1]\). Therefore, we can
approximate a complicated object (our urn) with a much simpler object (a uniform random variable).
</p>


</li>

</ul>

</div>

<p>
We now aim to prove Proposition <a href="notes_1.html#??">??</a>, which means we must find out the distribution of \(M_\infty \). In order to do so, we will use Lemma <a
href="notes_1.html#??">??</a>, which tells us that \(M_n\stackrel {d}{\to }M_\infty \), that is
</p>
<span class="hidden"> \(\seteqnumber{0}{7.}{6}\)</span>



<!--



                                                                                                P[Mn â‰¤ x] â†’ P[Mâˆž â‰¤ x]                               (7.7)                         --><a id="eq:urn_Mconvd"></a><!--



-->



<p>


\begin{align}
\label {eq:urn_Mconvd} \P [M_n\leq x]\to \P [M_\infty \leq x]
\end{align}
for all \(x\), except possibly those for which \(\P [M_\infty =x]&gt;0\). We will begin with a surprising lemma that tells us the distribution of \(B_n\). Then, using <span class="textup">(<a
href="notes_1.html#??">??</a>)</span>, we will be able to find the distribution of \(M_n\), from which <span class="textup">(<a href="notes_1.html#??">??</a>)</span> will then tell us the distribution
of \(M_\infty \).
</p>
<div class="theorembodylemma">

<ul class="list" style="list-style-type:none">



<a id="autoid-164"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Lemma 7.4.5</span></span> <a id="autoid-165" ></a ><a id="l:urn_Bn_unif"></a> For all \(k=1,\ldots ,n+1\), it holds that \(\P
[B_n=k]=\frac {1}{n+1}\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc">Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> Let \(A\) be the event that the first \(k\) balls drawn are red, and the next \(j\) balls
drawn are black. Then,
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{7}\)</span>

<!--


                                                          12      k  1  2        j
                                                 P[A] =      ...           ...       .                                                          (7.8)                         --><a id="eq:urn_rb_draws"></a><!--
                                                          23     k+1k+2k+3     j+k+1
-->

<p>


\begin{equation}
\label {eq:urn_rb_draws} \P [A]=\frac {1}{2}\frac {2}{3}\ldots \frac {k}{k+1}\frac {1}{k+2}\frac {2}{k+3}\ldots \frac {j}{j+k+1}.
\end{equation}


</p>

<p>
Here, each fraction corresponds (in order) to the probability of getting a red/black ball (as appropriate) on the corresponding draw, given the results of previous draws. For example, \(\frac 12\) is the probability
that the first draw results in a red ball, after which the urn contains \(2\) red balls and \(1\) black ball, so \(\frac 23\) is the probability that the second draw results in a red ball, and so on. From <span
class="textup">(<a href="notes_1.html#??">??</a>)</span> we have \(\P [A]=\frac {j!k!}{(j+k+1)!}\).
</p>

<p>
Here is the clever part: we note that drawing \(k\) red balls and \(j\) black balls, in the first \(j+k\) draws but in a different order, would have the <i>same</i> probability. We would simply obtain the
numerators in <span class="textup">(<a href="notes_1.html#??">??</a>)</span> in a different order. There are \(\binom {j+k}{k}\) possible different orders (i.e.&nbsp;we must choose \(k\) time-points
from \(j+k\) times at which to pick the red balls). Hence, the probability that we draw \(k\) red and \(j\) black in the first \(j+k\) draws is
</p>

<p>
\[\binom {j+k}{k}\frac {j!k!}{(j+k+1)!}=\frac {(j+k)!}{k!(j+k-k)!}\frac {j!k!}{(j+k+1)!}=\frac {1}{j+k+1}.\]
</p>

<p>
We set \(j=n-k\), to obtain the probability of drawing (and thus adding) \(k\) red balls within the first \(j+k=n\) draws. Hence \(\P [B_n=k+1]=\frac {1}{n+1}\) for all \(k=0,1,\ldots ,n\). Setting
\(k&apos;=k+1\), we recover the statement of the lemma. &#x2003;&#x2003;&#x220E;
</p>

<p>
<span class="textsc">Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span>[Of Proposition <a href="notes_1.html#??">??</a>.] Now that we know the distribution
of \(B_n\), we can use <span class="textup">(<a href="notes_1.html#??">??</a>)</span> to find out the distribution of \(M_n\). Lemma <a href="notes_1.html#??">??</a> tells us that \(B_n\) is
uniformly distribution on the set \(\{1,\ldots ,n+1\}\). Hence \(M_n\) is uniform on \(\{\frac {1}{n+2},\frac {2}{n+2},\ldots ,\frac {n+1}{n+2}\}\). This gives us that, for \(x\in (0,1)\),
</p>
<span class="hidden"> \(\seteqnumber{0}{7.}{8}\)</span>



<!--



                                                                                                          1
                                                                                           P[Mn â‰¤ x] =       Ã— âŒŠx(n + 2)âŒ‹.
                                                                                                         n+1



-->



<p>


\begin{align*}
\P [M_n\leq x]=\frac {1}{n+1} \times \lfloor x(n+2) \rfloor .
\end{align*}
Here, \(\lfloor x(n+2) \rfloor \), which denotes the integer part of \(x(n+2)\), is equal to the number of elements of \(\{\frac {1}{n+2},\frac {2}{n+2},\ldots ,\frac {n+1}{n+2}\}\) that are \(\leq
x\). Since \(x(n+2)-1\leq \lfloor x(n+2)\rfloor \leq x(n+2)\) we obtain that
</p>

<p>
\[\frac {x(n+2)-1}{n+1}\leq \P [M_n\leq x]\leq \frac {x(n+2)}{n+1}\]
</p>

<p>
and the sandwich rule tells us that \(\lim _{n\to \infty }\P [M_n\leq x]=x\). By <span class="textup">(<a href="notes_1.html#??">??</a>)</span>, this means that
</p>

<p>
\[\P [M_\infty \leq x]=x\quad \text { for all }x\in (0,1).\]
</p>

<p>
Therefore, \(M_\infty \) has a uniform distribution on \((0,1)\). This proves Proposition <a href="notes_1.html#??">??</a>. &#x2003;&#x2003;&#x220E;
</p>
<!--
......   subsubsection Extensions and applications of urn processes ......
-->
<h6 id="autosec-224">Extensions and applications of urn processes</h6>
<a id="notes_1-autopage-224"></a>



<p>
We could change the rules of our urn process, to create a new kind of urn â€“ for example whenever we draw a red ball we could add two new red balls, rather than just one. Urn processes are typically very â€˜sensitiveâ€™,
meaning that a small change in the process, or its initial conditions, can have a big effect on the long term behaviour. You can investigate some examples of this in exercises <a href="notes_1.html#??">??</a>,
<a href="notes_1.html#??">??</a> and <a href="notes_1.html#??">??</a>.
</p>

<p>
Urn processes are often used in models in which the â€˜next stepâ€™ of the process depends on sampling from its current state. Recall that in random walks we have \(S_{n+1}=S_n+X_{n+1}\), where \(X_{n+1}\) is
independent of \(S_n\); so for random walks the next step of the process is independent of its current state. By contrast, in Po&#x0301;lyaâ€™s urn, whether the next ball we add is red (or black) depends on the
current state of the urn; it depends on which colour ball we draw.
</p>

<p>
For example, we might look at people choosing which restaurant they have dinner at. Consider two restaurants, say <i>Cafe&#x0301; Rouge</i> (which is red) and <i>Le Chat Noir</i> (which is black). We think
of customers in Cafe&#x0301; Rouge as red balls, and customers in Le Chat Noir as black balls. A newly arriving customer (i.e.&nbsp;a new ball that we add to the urn) choosing which restaurant to visit is more
likely, but not certain, to choose the restaurant which currently has the most customers.
</p>

<p>
Other examples include the growth of social networks (people tend to befriend people who already have many friends), machine learning (used in techniques for becoming successively more confident about partially
learned information), and maximal safe dosage estimation in clinical trials (complicated reasons). Exercise <a href="notes_1.html#??">??</a> features an example of an urn process that is the basis for modern
models of evolution (successful organisms tend to have more descendants, who are themselves more likely to inherit genes that will make them successful).
</p>
<!--
......     subsection Long term behaviour of Galton-Watson processes ......
-->
<h5 id="autosec-225">Long term behaviour of Galton-Watson processes</h5>
<a id="notes_1-autopage-225"></a>



<a id="s:gw_long_term"></a>

<p>
The martingale convergence theorem can tell us about the long term behaviour of stochastic processes. In this section we focus on the Galton-Watson process, which we introduced in Section <a
href="notes_1.html#??">??</a>.
</p>

<p>
Let us recall the notation from Section <a href="notes_1.html#??">??</a>. Let \(X^n_i\), where \(n,i\ge 1\), be i.i.d.&nbsp;nonnegative integer-valued random variables with common distribution \(G\).
Define a sequence \((Z_n)\) by \(Z_0=1\) and
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{8}\)</span>

<!--

                                                ï£±
                                                ï£² X n+1 + . . . + X n+1 ,   if \(Z_n&gt;0\)
                                                       1            Zn
                                       Zn+1 =                                                                                     (7.9)                                  --><a id="eq:gw_iterative_defn"></a><!--
                                                ï£³ 0,                        if \(Z_n=0\)

-->

<p>


\begin{equation}
\label {eq:gw_iterative_defn} Z_{n+1} = \left \{ \begin{array}{ll} X^{n+1}_1 + \ldots + X^{n+1}_{Z_n}, &amp; \mbox { if $Z_n&gt;0$} \\ 0, &amp; \mbox { if $Z_n=0$} \end {array}
\right .
\end{equation}


</p>

<p>
Then \((Z_n)\) is the Galton-Watson process. In Section <a href="notes_1.html#??">??</a> we showed that, writing \(\mu =\E [G]\),
</p>

<p>
\[M_n=\frac {Z_n}{\mu ^n}\]
</p>

<p>
was a martingale with mean \(\E [M_n]=1\).
</p>

<p>
We now look to describe the long term behaviour of the process \(Z_n\), meaning that we want to know how \(Z_n\) behaves as \(n\to \infty \). Weâ€™ll consider three cases: \(\mu &lt;1\), \(\mu =1\), and
\(\mu &gt;1\). Before we start, its important to note that, if \(Z_N=0\) for any \(N\in \N \), then \(Z_n=0\) for all \(n\geq N\). When this happens, it is said that the process <i>dies out</i>.
</p>

<p>
Weâ€™ll need the martingale convergence theorem. We have that \(M_n\) is a martingale, with expected value \(1\), and since \(M_n\geq 0\) we have \(\E [|M_n|]=1\). Hence, \((M_n)\) is uniformly bounded in
\(L^1\) and by the martingale convergence theorem (Theorem <a href="notes_1.html#??">??</a>) we have that the almost sure limit
</p>

<p>
\[\lim \limits _{n\to \infty }M_n=M_\infty \]
</p>

<p>
exists. Since \(M_n\geq 0\), we have \(M_\infty \in [0,\infty )\).
</p>

<p>
For the rest of this section, weâ€™ll assume that the offspring distribution \(G\) is not deterministic. Obviously, if \(G\) was deterministic and equal to say, \(c\), then we would simply have \(Z_n=c^n\) for all \(n\).
</p>
<div class="theorembodylemma">

<ul class="list" style="list-style-type:none">



<a id="autoid-166"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Lemma 7.4.6</span></span> <a id="autoid-167" ></a ><a id="l:gw_crit"></a> Suppose that \(\mu =1\). Then \(\P [Z_n\text {
dies out}]=1\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc">Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> In this case \(M_n=Z_n\). So, we have \(Z_n\to M_\infty \) almost surely. The offspring
distribution is not deterministic, so for as long as \(Z_n\neq 0\) the value of \(Z_n\) will continue to change over time. Each such change in value is of magnitude at least \(1\), hence by Lemma <a
href="notes_1.html#??">??</a> the only way \(Z_n\) can converge is if \(Z_n\) is eventually zero. Therefore, since \(Z_n\) does converge, in this case we must have \(\P [Z_n\text { dies out}]=1\) (and
\(M_\infty =0\)). &#x2003;&#x2003;&#x220E;
</p>
<div class="theorembodylemma">

<ul class="list" style="list-style-type:none">



<a id="autoid-168"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Lemma 7.4.7</span></span> <a id="autoid-169" ></a ><a id="l:gw_subcrit"></a> Suppose that \(\mu &lt;1\). Then \(\P
[Z_n\text { dies out}]=1\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc">Sketch of Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> Recall our graphical representation of the Galton-Watson process in Section <a
href="notes_1.html#??">??</a>. Hereâ€™s the key idea: when \(\mu &lt;1\), on average we expect each individual to have less children than when \(\mu =1\). Therefore, if the Galton-Watson process dies out
when \(\mu =1\) (as is the case, from Lemma <a href="notes_1.html#??">??</a>), it should also die out when \(\mu &lt;1\).
</p>

<p>
Our idea is not quite a proof, because the size of the Galton-Watson process \(Z_n\) is random, and not necessarily equal to its expected size \(\E [Z_n]=\mu ^n\). To make the idea into a proof we will need to
find two Galton-Watson processes, \(Z_n\) and \(\wt {Z}_n\), such that \(0\leq Z_n\leq \wt {Z}_n\), with \(\mu &lt;1\) in \(Z_n\) and \(\mu =1\) in \(\wt {Z}_n\). Then, when \(\wt {Z}_n\) becomes
extinct, so does \(Z_n\). This type of argument is known as a <i>coupling</i>, meaning that we use one stochastic process to control another. See exercise <a href="notes_1.html#??">??</a> for how to do it.
&#x2003;&#x2003;&#x220E;
</p>
<div class="theorembodylemma">

<ul class="list" style="list-style-type:none">



<a id="autoid-170"></a>
<li>
<p>
<span class="listmarker"> <span class="theoremheaderplain">Lemma 7.4.8</span></span> <a id="autoid-171" ></a ><a id="l:gw_supercrit"></a> Suppose that \(\mu &gt;1\) and \(\sigma
^2&lt;\infty \). Then \(\P [Z_n\to \infty ]&gt;0\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc">Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> The first step of the argument is to show that, for all \(n\in \N \),
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{9}\)</span>

<!--


                                                      2                    Ïƒ2
                                                   E[Mn+1 ] = E[Mn2 ] +        .                                                 (7.10)                                --><a id="eq:gw_2nd_iterate"></a><!--
                                                                          Âµn+2
-->

<p>


\begin{equation}
\label {eq:gw_2nd_iterate} \E [M_{n+1}^2]=\E [M_n^2]+\frac {\sigma ^2}{\mu ^{n+2}}.
\end{equation}


</p>

<p>
You can find this calculation as exercise <a href="notes_1.html#??">??</a>. It is similar to the calculation that we did to find \(\E [M_n]\) in Section <a href="notes_1.html#??">??</a>, but a bit harder
because of the square.
</p>

<p>
By iterating <span class="textup">(<a href="notes_1.html#??">??</a>)</span> and noting that \(\E [M_0]=1\), we obtain that
</p>

<p>
\[\E [M_{n+1}^2]=1+\sum _{i=1}^n\frac {\sigma ^2}{\mu ^{i+2}}.\]
</p>

<p>
Hence,
</p>

<p>
\[\E [M_{n+1}^2]\leq 1+\frac {\sigma ^2}{\mu ^2}\sum _{i=1}^\infty \frac {1}{\mu ^i},\]
</p>

<p>
which is finite because \(\mu &gt;1\). Therefore, \((M_n)\) is uniformly bounded in \(L^2\), and the second martingale convergence theorem applies. In particular, this gives us that
</p>

<p>
\[\E [M_n]\to \E [M_\infty ].\]
</p>

<p>
Noting that \(\E [M_n]=1\) for all \(n\), we obtain that \(\E [M_\infty ]=1\). Hence, \(\P [M_\infty &gt;0]&gt;0\). On the event that \(M_\infty &gt;0\), we have \(M_n=\frac {Z_n}{\mu ^n}\to
M_\infty &gt;0\). Since \(\mu ^n\to \infty \), this means that when \(M_\infty &gt;0\) we must also have \(Z_n\to \infty \). Hence, \(\P [Z_n\to \infty ]&gt;0\). &#x2003;&#x2003;&#x220E;
</p>

<p>
The behaviour \(Z_n\to \infty \) is often called â€˜explosionâ€™, reflecting the fact that (when it happens) each generation tends to contain more and more individuals than the previous one. The case of \(\mu
&gt;1\) and \(\sigma ^2=\infty \) behaves in the same way as Lemma <a href="notes_1.html#??">??</a>, but the proof is more difficult and we donâ€™t study it in this course.
</p>
<!--
......   subsubsection Extensions and applications of the Galton-Watson process ......
-->
<h6 id="autosec-229">Extensions and applications of the Galton-Watson process</h6>
<a id="notes_1-autopage-229"></a>



<p>
The Galton-Watson process can be extended in many ways. For example, we might vary the offspring distribution used in each generation, or add a mechanism that allows individuals to produce their children
gradually across multiple time steps. The general term for such processes is â€˜branching processesâ€™. Most branching processes display the same type of long-term behaviour as we have uncovered in this section: if the
offspring production is too low (on average) then they are sure to die out, but, if the offspring production is high enough that dying out is not a certainty then (instead) there is a chance of explosion to \(\infty \).
</p>

<p>
Branching processes are the basis of stochastic models in which existing objects reproduce, or break up, into several new objects. Examples are the spread of contagious disease, crushing rocks, nuclear fission,
tumour growth, and so on. In Chapter <a href="notes_1.html#??">??</a> (which is part of MAS61023 only) we will use branching processes to model contagion of unpaid debts in banking networks.
</p>

<p>
Branching processes are used by biologists to model population growth, and they are good models for populations that are rapidly increasing in size. (For populations that have reached a roughly constant size,
models based on urn processes, such as that of exercise <a href="notes_1.html#??">??</a>, are more effective.)
</p>
<!--
......   subsection Long term behaviour of random walks             ......
-->
<h5 id="autosec-230">Long term behaviour of random walks \(\offsyl \)</h5>
<a id="notes_1-autopage-230"></a>



<a id="s:rw_long_term"></a>

<p>
We now consider the long term behaviour of random walks. This section wonâ€™t include proofs, and for that reason it is marked with a \(\offsyl \) and is off syllabus. We will cover this chapter in lectures, because
it contain interesting information that provides intuition for (on-syllabus) results in future chapters. For those of you taking MAS61023 a full set of proofs, using some new techniques, are included in your
independent reading in Chapters <a href="notes_1.html#??">??</a> and <a href="notes_1.html#??">??</a>. However, <i>some parts</i> of the results discussed below can be proved using the techniques
weâ€™ve already studied; exercises of this type are on-syllabus for everyone, and youâ€™ll see some at the end of this chapter.
</p>

<p>
Firstly, take \(S_n\) to be the simple symmetric random walk. It turns out that \(S_n\) will oscillate as \(n\to \infty \), and that the magnitude of the largest oscillations will tend to infinity as \(n\to \infty
\) (almost surely). So, our picture of the long-term behaviour of the symmetric random walk looks like:
</p>
<div class="center">

<p>


<a href="long_term_ssrw.jpg" target="_blank" ><img
      src="long_term_ssrw.jpg"
      style="
      width:304pt;
      "
      class="inlineimage"
      alt="(A symmetric random walk oscillating over a long time)"
></a>
</p>
</div>

<p>
Note that we draw the picture as a continuous line, for convenience, but in fact the random walk is jumping between integer values.
</p>

<p>
Next, let \(S_n\) be the asymmetric random walk, with \(p&gt;q\), so the walk drifts upwards. The asymmetric random walk also experiences oscillations growing larger and larger, but the drift upwards is strong
enough that, in fact \(S_n\stackrel {a.s.}{\to }\infty \) as \(n\to \infty \). So, our picture of the long-term behaviour of the asymmetric random walk looks like:
</p>
<div class="center">

<p>


<a href="long_term_asrw.jpg" target="_blank" ><img
      src="long_term_asrw.jpg"
      style="
      width:304pt;
      "
      class="inlineimage"
      alt="(An asymmetric random walk drifting upwards over a long time)"
></a>
</p>
</div>

<p>
Of course, if \(q&lt;p\) then \(S_n\) would drift downwards, and then \(S_n\stackrel {a.s.}{\to }-\infty \).
</p>
<!--
......    subsubsection Extensions and applications of random walks ......
-->
<h6 id="autosec-233">Extensions and applications of random walks</h6>
<a id="notes_1-autopage-233"></a>



<p>
Random walks can be extended in many ways, such as by adding an environment that influences the behaviour of the walk (e.g.&nbsp;reflection upwards from the origin as in exercise <a
href="notes_1.html#??">??</a>, slower movements when above \(0\), etc), or by having random walkers that walk around a graph (\(\Z \), in our case above). More complex extensions involve random walks
that are influenced by their own history, for example by having a preference to move into sites that they have not yet visited. In addition, many physical systems can be modelled by systems of several random walks,
that interact with each other, for example a setup with multiple random walks happening at the same time (but started from different points in space) in which, whenever random walkers meet, both of them
suddenly vanish.
</p>

<p>
Random walks are the basis of essentially all stochastic modelling that involves particles moving around randomly in space. For example, atoms in gases and liquids, animal movement, heat diffusion, conduction of
electricity, transportation networks, internet traffic, and so on.
</p>

<p>
In Chapters <a href="notes_1.html#??">??</a> and <a href="notes_1.html#??">??</a> we will use stock price models that are based on â€˜Brownian motionâ€™, which is itself introduced in Chapter <a
href="notes_1.html#??">??</a> and is the continuous analogue of the symmetric random walk (i.e.&nbsp;no discontinuities). Weâ€™ll come back to the idea of atoms in gases and liquids in Section <a
href="notes_1.html#??">??</a>, and weâ€™ll also briefly look at heat diffusion in Section <a href="notes_1.html#??">??</a>.
</p>

</section>

</main>

</div>

<footer>

<p>
Copyright Nic Freeman, Sheffield University, last updated April 22, 2025
</p>

</footer>



<nav class="botnavigation"><a href="notes_1.html" class="linkhome" >
Home</a></nav>

</body>
</html>
