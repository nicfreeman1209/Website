<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Nic Freeman" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="MAS352/452/6052 Stochastic Processes and Financial Mathematics, Sheffield University, January 5, 2022." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<!--[if lt IE 9]>
<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
<title>MASx52 â€” Long term behaviour of stochastic processes</title>
<link rel="stylesheet" type="text/css" href="sans-serif-lwarp-sagebrush.css" />


<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
     subequations: "0",
     section: "",
     loader: {
         load: ['[tex]/tagFormat'],
     },
     startup: {
         ready() {
             //       These would be replaced by import commands if you wanted to make
             //       a proper extension.
             const Configuration = MathJax._.input.tex.Configuration.Configuration;
             const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
             const Macro = MathJax._.input.tex.Symbol.Macro;
             const TexError = MathJax._.input.tex.TexError.default;
             const ParseUtil = MathJax._.input.tex.ParseUtil.default;
             const expandable = MathJax._.util.Options.expandable;


             //       Insert the replacement string into the TeX string, and check
             //       that there haven't been too many maxro substitutions (prevents
             //       infinite loops).
             const useArgument = (parser, text) => {
                  parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
                  parser.i = 0;
                  if (++parser.macroCount > parser.configuration.options.maxMacros) {
                      throw new TexError('MaxMacroSub1',
                      'MathJax maximum macro substitution count exceeded; ' +
                      'is there a recursive macro call?');
                  }
             }


             //       Create the command map for \ifstar, \ifnextchar, \seteqnumber
             new CommandMap('ifstar-ifnextchar-setequnumber', {
                  ifstar: 'IfstarFunction',
                  ifnextchar: 'IfnextcharFunction',
                  seteqnumber: 'SeteqnumberFunction'
             }, {
                  //      This function implements an ifstar macro.
                  IfstarFunction(parser, name) {
                      const resultstar = parser.GetArgument(name);
                      const resultnostar = parser.GetArgument(name);
                      const star = parser.GetStar();                        // true if there is a *
                      useArgument(parser, star ? resultstar : resultnostar);
                  },


                  //      This function implements an ifnextchar macro.
                  IfnextcharFunction(parser, name) {
                      let whichchar = parser.GetArgument(name);
                      if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
                          // $ syntax highlighting
                          whichchar = String.fromCodePoint(parseInt(whichchar));
                      }
                      const resultnextchar = parser.GetArgument(name);
                      const resultnotnextchar = parser.GetArgument(name);
                      const gotchar = (parser.GetNext() === whichchar);
                      useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
                  },


                  //      This function modifies the equation numbers.
                  SeteqnumberFunction(parser, name) {
                          //   Get the macro parameters
                          const star = parser.GetStar();                       // true if there is a *
                          const optBrackets = parser.GetBrackets(name);        // contents of optional brackets
                          const newsubequations = parser.GetArgument(name);       // the subequations argument
                          const neweqsection = parser.GetArgument(name);       // the eq section argument
                          const neweqnumber = parser.GetArgument(name);        // the eq number argument
                          MathJax.config.subequations=newsubequations ;        // a string with boolean meaning
                          MathJax.config.section=neweqsection ;                // a string with numeric meaning
                          parser.tags.counter = parser.tags.allCounter = neweqnumber ;
                  }
             });


             //       Create the ifstar-ifnextchar-setequnumber package
             Configuration.create('ifstar-ifnextchar-setequnumber', {
                  handler: {macro: ['ifstar-ifnextchar-setequnumber']}
             });


             MathJax.startup.defaultReady();


             // For forward references:
             MathJax.startup.input[0].preFilters.add(({math}) => {
                  if (math.inputData.recompile){
                          MathJax.config.subequations = math.inputData.recompile.subequations;
                          MathJax.config.section = math.inputData.recompile.section;
                  }
             });
             MathJax.startup.input[0].postFilters.add(({math}) => {
                  if (math.inputData.recompile){
                          math.inputData.recompile.subequations = MathJax.config.subequations;
                          math.inputData.recompile.section = MathJax.config.section;
                  }
             });
         }       // ready
     },           // startup


     tex: {
         packages: {'[+]': ['tagFormat', 'ifstar-ifnextchar-setequnumber']},
         tags: "ams",
                  tagFormat: {
                          number: function (n) {
                               if(MathJax.config.subequations==0)
                                      return(MathJax.config.section + n);
                               else
                                      return(MathJax.config.section + String.fromCharCode(96+n));
                          },
                  },
     }
}
</script>


<script
         id="MathJax-script"
         src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
></script>


</head>
<body>



<a id="notes_1-autopage-216"></a>
<nav class="topnavigation" ><a href="notes_1.html" class="linkhome" >
Home</a></nav>

<header>

<p>
last updated: January 5, 2022
</p>

</header>



<div class="bodyandsidetoc" >
<div class="sidetoccontainer" >



<nav class="sidetoc" >



<div class="sidetoctitle" >

<p>
<span class="sidetocthetitle" >Stochastic Processes and Financial Mathematics<br />
(part one)</span>
</p>

<p>
Contents
</p>
</div>



<div class="sidetoccontents" >

<p>
<a href="notes_1.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Introduction.html#autosec-4" class="tocchapter" >
<span class="sectionnumber" >0</span>&#x2003;Introduction</a>
</p>



<p>
<a href="Introduction.html#autosec-5" class="tocsection" >
<span class="sectionnumber" >0.1</span>&#x2003;Organization</a>
</p>



<p>
<a href="Expectation-Arbitrage.html#autosec-12" class="tocchapter" >
<span class="sectionnumber" >1</span>&#x2003;Expectation and Arbitrage</a>
</p>



<p>
<a href="Expectation-Arbitrage.html#autosec-13" class="tocsection" >
<span class="sectionnumber" >1.1</span>&#x2003;Betting on coin tosses</a>
</p>



<p>
<a href="The-one-period-market.html#autosec-16" class="tocsection" >
<span class="sectionnumber" >1.2</span>&#x2003;The one-period market</a>
</p>



<p>
<a href="Arbitrage.html#autosec-21" class="tocsection" >
<span class="sectionnumber" >1.3</span>&#x2003;Arbitrage</a>
</p>



<p>
<a href="Modelling-discussion.html#autosec-31" class="tocsection" >
<span class="sectionnumber" >1.4</span>&#x2003;Modelling discussion</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-pricing.html#autosec-33" class="tocsection" >
<span class="sectionnumber" >1.5</span>&#x2003;Exercises on Chapter&nbsp;<a href="Expectation-Arbitrage.html#chap:pricing">1</a></a>
</p>



<p>
<a href="Probability-spaces-random-variables.html#autosec-37" class="tocchapter" >
<span class="sectionnumber" >2</span>&#x2003;Probability spaces and random variables</a>
</p>



<p>
<a href="Probability-spaces-random-variables.html#autosec-38" class="tocsection" >
<span class="sectionnumber" >2.1</span>&#x2003;Probability measures and \(\sigma \)-fields</a>
</p>



<p>
<a href="Random-variables.html#autosec-48" class="tocsection" >
<span class="sectionnumber" >2.2</span>&#x2003;Random variables</a>
</p>



<p>
<a href="Infinite.html#autosec-62" class="tocsection" >
<span class="sectionnumber" >2.3</span>&#x2003;Infinite \(\Omega \)</a>
</p>



<p>
<a href="Expectation.html#autosec-68" class="tocsection" >
<span class="sectionnumber" >2.4</span>&#x2003;Expectation</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-prob_meas.html#autosec-76" class="tocsection" >
<span class="sectionnumber" >2.5</span>&#x2003;Exercises on Chapter <a href="Probability-spaces-random-variables.html#chap:prob_meas">2</a></a>
</p>



<p>
<a href="Conditional-expectation-martingales.html#autosec-81" class="tocchapter" >
<span class="sectionnumber" >3</span>&#x2003;Conditional expectation and martingales</a>
</p>



<p>
<a href="Conditional-expectation-martingales.html#autosec-82" class="tocsection" >
<span class="sectionnumber" >3.1</span>&#x2003;Conditional expectation</a>
</p>



<p>
<a href="Properties-conditional-expectation.html#autosec-88" class="tocsection" >
<span class="sectionnumber" >3.2</span>&#x2003;Properties of conditional expectation</a>
</p>



<p>
<a href="Martingales.html#autosec-94" class="tocsection" >
<span class="sectionnumber" >3.3</span>&#x2003;Martingales</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-cond_exp.html#autosec-105" class="tocsection" >
<span class="sectionnumber" >3.4</span>&#x2003;Exercises on Chapter <a href="Conditional-expectation-martingales.html#chap:cond_exp">3</a></a>
</p>



<p>
<a href="Stochastic-processes.html#autosec-109" class="tocchapter" >
<span class="sectionnumber" >4</span>&#x2003;Stochastic processes</a>
</p>



<p>
<a href="Stochastic-processes.html#autosec-111" class="tocsection" >
<span class="sectionnumber" >4.1</span>&#x2003;Random walks</a>
</p>



<p>
<a href="Urn-processes.html#autosec-117" class="tocsection" >
<span class="sectionnumber" >4.2</span>&#x2003;Urn processes</a>
</p>



<p>
<a href="A-branching-process.html#autosec-122" class="tocsection" >
<span class="sectionnumber" >4.3</span>&#x2003;A branching process</a>
</p>



<p>
<a href="Other-stochastic-processes.html#autosec-126" class="tocsection" >
<span class="sectionnumber" >4.4</span>&#x2003;Other stochastic processes</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-stoch_procs.html#autosec-129" class="tocsection" >
<span class="sectionnumber" >4.5</span>&#x2003;Exercises on Chapter <a href="Stochastic-processes.html#chap:stoch_procs">4</a></a>
</p>



<p>
<a href="The-binomial-model.html#autosec-133" class="tocchapter" >
<span class="sectionnumber" >5</span>&#x2003;The binomial model</a>
</p>



<p>
<a href="The-binomial-model.html#autosec-134" class="tocsection" >
<span class="sectionnumber" >5.1</span>&#x2003;Arbitrage in the one-period model</a>
</p>



<p>
<a href="Hedging-in-one-period-model.html#autosec-142" class="tocsection" >
<span class="sectionnumber" >5.2</span>&#x2003;Hedging in the one-period model</a>
</p>



<p>
<a href="Types-financial-derivative.html#autosec-153" class="tocsection" >
<span class="sectionnumber" >5.3</span>&#x2003;Types of financial derivative</a>
</p>



<p>
<a href="The-binomial-model-definition.html#autosec-155" class="tocsection" >
<span class="sectionnumber" >5.4</span>&#x2003;The binomial model (definition)</a>
</p>



<p>
<a href="Portfolios-arbitrage-martingales.html#autosec-159" class="tocsection" >
<span class="sectionnumber" >5.5</span>&#x2003;Portfolios, arbitrage and martingales</a>
</p>



<p>
<a href="Hedging.html#autosec-168" class="tocsection" >
<span class="sectionnumber" >5.6</span>&#x2003;Hedging</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-bin_model.html#autosec-177" class="tocsection" >
<span class="sectionnumber" >5.7</span>&#x2003;Exercises on Chapter <a href="The-binomial-model.html#chap:bin_model">5</a></a>
</p>



<p>
<a href="Convergence-random-variables.html#autosec-182" class="tocchapter" >
<span class="sectionnumber" >6</span>&#x2003;Convergence of random variables</a>
</p>



<p>
<a href="Convergence-random-variables.html#autosec-183" class="tocsection" >
<span class="sectionnumber" >6.1</span>&#x2003;Modes of convergence</a>
</p>



<p>
<a href="The-monotone-convergence-theorem.html#autosec-189" class="tocsection" >
<span class="sectionnumber" >6.2</span>&#x2003;The monotone convergence theorem</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-rv_conv.html#autosec-194" class="tocsection" >
<span class="sectionnumber" >6.3</span>&#x2003;Exercises on Chapter <a href="Convergence-random-variables.html#chap:rv_conv">6</a></a>
</p>



<p>
<a href="Stochastic-processes-martingale-theory.html#autosec-199" class="tocchapter" >
<span class="sectionnumber" >7</span>&#x2003;Stochastic processes and martingale theory</a>
</p>



<p>
<a href="Stochastic-processes-martingale-theory.html#autosec-200" class="tocsection" >
<span class="sectionnumber" >7.1</span>&#x2003;The martingale transform</a>
</p>



<p>
<a href="Roulette.html#autosec-203" class="tocsection" >
<span class="sectionnumber" >7.2</span>&#x2003;Roulette</a>
</p>



<p>
<a href="The-martingale-convergence-theorem.html#autosec-209" class="tocsection" >
<span class="sectionnumber" >7.3</span>&#x2003;The martingale convergence theorem</a>
</p>



<p>
<a href="Long-term-behaviour-stochastic-processes.html#autosec-217" class="tocsection" >
<span class="sectionnumber" >7.4</span>&#x2003;Long term behaviour of stochastic processes</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#autosec-236" class="tocsection" >
<span class="sectionnumber" >7.5</span>&#x2003;Exercises on Chapter <a href="Stochastic-processes-martingale-theory.html#chap:stoch_procs_1">7</a></a>
</p>



<p>
<a href="Further-theory-stochastic-processes.html#autosec-241" class="tocchapter" >
<span class="sectionnumber" >8</span>&#x2003;Further theory of stochastic processes \((\Delta )\)</a>
</p>



<p>
<a href="Further-theory-stochastic-processes.html#autosec-242" class="tocsection" >
<span class="sectionnumber" >8.1</span>&#x2003;The dominated convergence theorem \((\Delta )\)</a>
</p>



<p>
<a href="The-optional-stopping-theorem.html#autosec-247" class="tocsection" >
<span class="sectionnumber" >8.2</span>&#x2003;The optional stopping theorem \((\Delta )\)</a>
</p>



<p>
<a href="Hitting-probabilities-random-walks.html#autosec-254" class="tocsection" >
<span class="sectionnumber" >8.3</span>&#x2003;Hitting probabilities of random walks \((\Delta )\)</a>
</p>



<p>
<a href="Exercises-on-Chapter-ref-chap-stoch_procs_2.html#autosec-261" class="tocsection" >
<span class="sectionnumber" >8.4</span>&#x2003;Exercises on Chapter <a href="Further-theory-stochastic-processes.html#chap:stoch_procs_2">8</a> \((\Delta )\)</a>
</p>



<p>
<a href="Solutions-exercises-part-one.html#autosec-265" class="tocchapter" >
<span class="sectionnumber" >A</span>&#x2003;Solutions to exercises (part one)</a>
</p>



<p>
<a href="Formula-Sheet-part-one.html#autosec-282" class="tocchapter" >
<span class="sectionnumber" >B</span>&#x2003;Formula Sheet (part one)</a>
</p>



</div>

</nav>

</div>



<div class="bodycontainer" >



<section class="textbody" >

<h1>Stochastic Processes and Financial Mathematics<br />
(part one)</h1>

<!--MathJax customizations:-->



<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\DeclareMathOperator {\var }{var}\)

\(\DeclareMathOperator {\cov }{cov}\)

\(\newcommand {\nN }{n \in \mathbb {N}}\)

\(\newcommand {\Br }{{\cal B}(\R )}\)

\(\newcommand {\F }{{\cal F}}\)

\(\newcommand {\ds }{\displaystyle }\)

\(\newcommand {\st }{\stackrel {d}{=}}\)

\(\newcommand {\uc }{\stackrel {uc}{\rightarrow }}\)

\(\newcommand {\la }{\langle }\)

\(\newcommand {\ra }{\rangle }\)

\(\newcommand {\li }{\liminf _{n \rightarrow \infty }}\)

\(\newcommand {\ls }{\limsup _{n \rightarrow \infty }}\)

\(\newcommand {\limn }{\lim _{n \rightarrow \infty }}\)

\(\def \ra {\Rightarrow }\)

\(\def \to {\rightarrow }\)

\(\def \iff {\Leftrightarrow }\)

\(\def \sw {\subseteq }\)

\(\def \wt {\widetilde }\)

\(\def \mc {\mathcal }\)

\(\def \mb {\mathbb }\)

\(\def \sc {\setminus }\)

\(\def \v {\textbf }\)

\(\def \p {\partial }\)

\(\def \E {\mb {E}}\)

\(\def \P {\mb {P}}\)

\(\def \R {\mb {R}}\)

\(\def \C {\mb {C}}\)

\(\def \N {\mb {N}}\)

\(\def \Q {\mb {Q}}\)

\(\def \Z {\mb {Z}}\)

\(\def \B {\mb {B}}\)

\(\def \~{\sim }\)

\(\def \-{\,;\,}\)

\(\def \|{\,|\,}\)

\(\def \qed {$\blacksquare $}\)

\(\def \1{\unicode {x1D7D9}}\)

\(\def \cadlag {c\â€˜{a}dl\â€˜{a}g}\)

\(\def \p {\partial }\)

\(\def \l {\left }\)

\(\def \r {\right }\)

\(\def \F {\mc {F}}\)

\(\def \G {\mc {G}}\)

\(\def \H {\mc {H}}\)

\(\def \Om {\Omega }\)

\(\def \om {\omega }\)

</div>

<p>
<h4 id="autosec-217"><span class="sectionnumber" >7.4&#x2003;</span>Long term behaviour of stochastic processes</h4>
<a id="notes_1-autopage-217"></a>
<a id="notes_1-autofile-34"></a>

<p>
Our next step is to use the martingale convergence theorem to look at the behaviour as \(t\to \infty \) of various stochastic processes. We will begin with Roulette, from Section <a
href="Roulette.html#sec:roulette">7.2</a>, and then move on to the trio of stochastic processes (random walks, urns, branching processes) that we introduced in Chapter <a
href="Stochastic-processes.html#chap:stoch_procs">4</a>.
</p>

<p>
One fact, from real analysis, that we will find useful is the following:
</p>
<div class="theorembodylemma" >

<ul style="list-style-type:none">



<a id="autoid-156"></a>

<li>

<p>
<span class="theoremheaderplain" >Lemma 7.4.1</span> <a id="autoid-157" ></a ><a id="lem:Z_ev_const"></a> Let \((a_n)\) be an integer valued sequence, and suppose that \(a_n\to a\) as \(n\to
\infty \). Then \((a_n)\) is eventually equal to a constant: there exists \(N\in \N \) such that \(a_n=a\) for all \(n\geq N\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc" >Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> Put \(\epsilon =\frac 13\) into the definition of a convergent real sequence, and we
obtain that there exists \(N\in \N \) such that \(|a_n-a|\leq \frac 13\) for all \(n\geq N\). Hence, for \(n\geq N\) we have
</p>
<span class="hidden" > \(\seteqnumber{0}{7.}{4}\)</span>



<!--



                                                                            |an âˆ’ an+1 | = |an âˆ’ a + a âˆ’ an+1 | â‰¤ |an âˆ’ a| + |a âˆ’ an+1 |
                                                                                                                   1       1
                                                                                                               â‰¤   3   +   3

                                                                                                               = 23 .



-->



<p>


\begin{align*}
|a_n-a_{n+1}|=|a_n-a+a-a_{n+1}| &amp;\leq |a_n-a|+|a-a_{n+1}|\\ &amp;\leq \tfrac 13+\tfrac 13\\ &amp;=\tfrac 23.
\end{align*}
Since \(\frac 23&lt;1\), and \(a_n\) takes only integer values, this means that \(a_n=a_{n+1}\). Since this holds for all \(n\geq N\), we must have \(a_N=a_{N+1}=a_{N+2}=\ldots \), which means that
\(a_n\to a_N\) as \(N\to \infty \) (and hence \(a=a_N\)). &#x2003;&#x2003;&#x220E;
</p>
<h5 id="autosec-219">Long term behaviour of Roulette</h5>
<a id="notes_1-autopage-219"></a>



<a id="sec:roulette_long_term"></a>

<p>
Let us think about what happens to our Roulette player, from Section <a href="Roulette.html#sec:roulette">7.2</a>.
</p>

<p>
Recall that our gambler bets an amount \(C_{n-1}\in \mc {F}_{n-1}\) on play \(n\). On each play, our gambler increases his wealth, by \(C_{n-1}\), with probability \(\frac {18}{37}\), or decreases his
wealth, by \(C_{n-1}\), with probability \(\frac {19}{37}\). We showed in Section <a href="Roulette.html#sec:roulette">7.2</a> that his profit/loss after \(n\) plays was a supermartingale, \((C\circ
M)_n.\) Thus, if our gambler starts with an amount of money \(K\in \N \) at time \(0\), then at time \(n\) they have an amount of money given by
</p>

<p>
\[W_n=K+(C\circ M)_n.\]
</p>

<p>
Weâ€™ll assume that our gambler never stops playing, unless they run out of money, so we have \(C_n\geq 1\) and \(W_n\geq 0\) for all \(n\). Since money is a discrete quantity, we can assume that \(K\) and
\(C_n\) are integers, hence \(W_n\) is also always an integer.
</p>

<p>
From Section <a href="Roulette.html#sec:roulette">7.2</a> we know that \((C\circ M)_n\) is a supermartingale, hence \(W_n\) is also a supermartingale. Since \(W_n\geq 0\) we have \(\E [|W_n|]=\E
[W_n]\leq \E [W_0]\) so \((W_n)\) is bounded in \(L^1\). Hence, by the martingale convergence theorem, \(W_n\) is almost surely convergent.
</p>

<p>
By Lemma <a href="Long-term-behaviour-stochastic-processes.html#lem:Z_ev_const">7.4.1</a>, the only way that \(W_n\) can converge is if it becomes constant, eventually. Since each play results in a
win (an increase) or a loss (a decrease) the only way \(W_n\) can become eventually constant is if our gambler has lost all his money i.e.&nbsp;for some (random) \(N\in \N \), for all \(n\geq N\), we have
\(W_n=0\). Thus:
</p>
<div class="theorembodylemma" >

<ul style="list-style-type:none">



<a id="autoid-158"></a>

<li>

<p>
<span class="theoremheaderplain" >Lemma 7.4.2</span> <a id="autoid-159" ></a >Almost surely, a roulette player will eventually lose all their money.
</p>


</li>

</ul>

</div>
<h5 id="autosec-221">Long term behaviour of urn processes</h5>
<a id="notes_1-autopage-221"></a>



<a id="sec:urn_long_term"></a>

<p>
We will look at the Po&#x0301;lya urn process introduced in Section <a href="Urn-processes.html#sec:urn">4.2</a>. Recall that we start our urn with \(2\) balls, one red and one black. Then, at each time
\(n=1,2,\ldots ,\) we draw a ball, uniformly at random, from the urn, and replace it alongside an additional ball of the same colour. Thus, at time \(n\) (which means: after the \(n^{th}\) draw is completed)
the urn contains \(n+2\) balls.
</p>

<p>
Recall also that we write \(B_n\) for the number of red balls in the urn at time \(n\), and
</p>

<span class="hidden" > \(\seteqnumber{0}{7.}{4}\)</span>

<!--


                                                            Bn
                                                    Mn =                                                         (7.5)                                                       --><a id="eq:urn_Mn2"></a><!--
                                                           n+2


-->

<p>


\begin{equation}
\label {eq:urn_Mn2} M_n=\frac {B_n}{n+2}
\end{equation}


</p>

<p>
for the fraction of red balls in the urn at time \(n\). We have shown in Section <a href="Urn-processes.html#sec:urn">4.2</a> that \(M_n\) is a martingale. Since \(M_n\in [0,1]\), we have \(\E
[|M_n|]\leq 1\), hence \((M_n)\) is bounded in \(L^1\) and the martingale convergence theorem applies. Therefore, there exists a random variable \(M_\infty \) such that \(M_n\stackrel {a.s.}{\to
}M_\infty \). We will show that:
</p>
<div class="theorembodyprop" >

<ul style="list-style-type:none">



<a id="autoid-160"></a>

<li>

<p>
<span class="theoremheaderplain" >Proposition 7.4.3</span> <a id="autoid-161" ></a ><a id="prop:urn_limit"></a> \(M_\infty \) has the uniform distribution on \([0,1]\).
</p>


</li>

</ul>

</div>
<div class="theorembodyremark" >

<ul style="list-style-type:none">



<a id="autoid-162"></a>

<li>

<p>
<span class="theoremheaderplain" >Remark 7.4.4</span> <a id="autoid-163" ></a >Results like Proposition <a href="Long-term-behaviour-stochastic-processes.html#prop:urn_limit">7.4.3</a>
are extremely useful, in stochastic modelling. It provides us with the following â€˜rule of thumbâ€™: if \(n\) is large, then the fraction of red balls in our urn is approximately a uniform distribution on \([0,1]\).
Therefore, we can approximate a complicated object (our urn) with a much simpler object (a uniform random variable).
</p>


</li>

</ul>

</div>

<p>
We now aim to prove Proposition <a href="Long-term-behaviour-stochastic-processes.html#prop:urn_limit">7.4.3</a>, which means we must find out the distribution of \(M_\infty \). In order to do so,
we will use Lemma <a href="Convergence-random-variables.html#lem:conv_modes">6.1.2</a>, which tells us that \(M_n\stackrel {d}{\to }M_\infty \), that is
</p>
<span class="hidden" > \(\seteqnumber{0}{7.}{5}\)</span>



<!--



                                                                                                P[Mn â‰¤ x] â†’ P[Mâˆž â‰¤ x]                               (7.6)                          --><a id="eq:urn_Mconvd"></a><!--



-->



<p>


\begin{align}
\label {eq:urn_Mconvd} \P [M_n\leq x]\to \P [M_\infty \leq x]
\end{align}
for all \(x\). We will begin with a surprising lemma that tells us the distribution of \(B_n\). Then, using <span class="textup" >(<a
href="Long-term-behaviour-stochastic-processes.html#eq:urn_Mn2">7.5</a>)</span>, we will be able to find the distribution of \(M_n\), from which <span class="textup" >(<a
href="Long-term-behaviour-stochastic-processes.html#eq:urn_Mconvd">7.6</a>)</span> will then tell us the distribution of \(M_\infty \).
</p>
<div class="theorembodylemma" >

<ul style="list-style-type:none">



<a id="autoid-164"></a>

<li>

<p>
<span class="theoremheaderplain" >Lemma 7.4.5</span> <a id="autoid-165" ></a ><a id="lem:urn_Bn_unif"></a> For all \(k=1,\ldots ,n+1\), it holds that \(\P [B_n=k]=\frac {1}{n+1}\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc" >Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> Let \(A\) be the event that the first \(k\) balls drawn are red, and the next \(j\) balls
drawn are black. Then,
</p>

<span class="hidden" > \(\seteqnumber{0}{7.}{6}\)</span>

<!--


                                                          12      k  1  2        j
                                                 P[A] =      ...           ...       .                                                          (7.7)                         --><a id="eq:urn_rb_draws"></a><!--
                                                          23     k+1k+2k+3     j+k+1


-->

<p>


\begin{equation}
\label {eq:urn_rb_draws} \P [A]=\frac {1}{2}\frac {2}{3}\ldots \frac {k}{k+1}\frac {1}{k+2}\frac {2}{k+3}\ldots \frac {j}{j+k+1}.
\end{equation}


</p>

<p>
Here, each fraction corresponds (in order) to the probability of getting a red/black ball (as appropriate) on the corresponding draw, given the results of previous draws. For example, \(\frac 12\) is the probability
that the first draw results in a red ball, after which the urn contains \(2\) red balls and \(1\) black ball, so \(\frac 23\) is the probability that the second draw results in a red ball, and so on. From <span
class="textup" >(<a href="Long-term-behaviour-stochastic-processes.html#eq:urn_rb_draws">7.7</a>)</span> we have \(\P [A]=\frac {j!k!}{(j+k+1)!}\).
</p>

<p>
Here is the clever part: we note that drawing \(k\) red balls and \(j\) black balls, in the first \(j+k\) draws but in a different order, would have the <i>same</i> probability. We would simply obtain the
numerators in <span class="textup" >(<a href="Long-term-behaviour-stochastic-processes.html#eq:urn_rb_draws">7.7</a>)</span> in a different order. There are \(\binom {j+k}{k}\) possible
different orders (i.e.&nbsp;we must choose \(k\) time-points from \(j+k\) times at which to pick the red balls). Hence, the probability that we draw \(k\) red and \(j\) black in the first \(j+k\) draws is
</p>

<p>
\[\binom {j+k}{k}\frac {j!k!}{(j+k+1)!}=\frac {(j+k)!}{k!(j+k-k)!}\frac {j!k!}{(j+k+1)!}=\frac {1}{j+k+1}.\]
</p>

<p>
We set \(j=n-k\), to obtain the probability of drawing (and thus adding) \(k\) red balls within the first \(j+k=n\) draws. This gives \(\P [B_n=k+1]=\frac {1}{n+1}\) for all \(k=0,1,\ldots ,n\). Hence \(\P
[B_n=k]=\frac {1}{n+1}\) for all \(k=1,1,\ldots ,n+1\). &#x2003;&#x2003;&#x220E;
</p>

<p>
<span class="textsc" >Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span>[Of Proposition <a
href="Long-term-behaviour-stochastic-processes.html#prop:urn_limit">7.4.3</a>.] Now that we know the distribution of \(B_n\), we can use <span class="textup" >(<a
href="Long-term-behaviour-stochastic-processes.html#eq:urn_Mn2">7.5</a>)</span> to find out the distribution of \(M_n\). Lemma <a
href="Long-term-behaviour-stochastic-processes.html#lem:urn_Bn_unif">7.4.5</a> tells us that \(B_n\) is uniformly distribution on the set \(\{1,\ldots ,n+1\}\). Hence \(M_n\) is uniform on
\(\{\frac {1}{n+2},\frac {2}{n+2},\ldots ,\frac {n+1}{n+2}\}\). This gives us that, for \(x\in (0,1)\),
</p>
<span class="hidden" > \(\seteqnumber{0}{7.}{7}\)</span>



<!--



                                                                                                          1
                                                                                           P[Mn â‰¤ x] =       Ã— bx(n + 2)c.
                                                                                                         n+1



-->



<p>


\begin{align*}
\P [M_n\leq x]=\frac {1}{n+1} \times \lfloor x(n+2) \rfloor .
\end{align*}
Here, \(\lfloor x(n+2) \rfloor \), which denotes the integer part of \(x(n+2)\), is equal to the number of elements of \(\{\frac {1}{n+2},\frac {2}{n+2},\ldots ,\frac {n+1}{n+2}\}\) that are \(\leq
x\). Since \(x(n+2)-1\leq \lfloor x(n+2)\rfloor \leq x(n+2)\) we obtain that
</p>

<p>
\[\frac {x(n+2)-1}{n+1}\leq \P [M_n\leq x]\leq \frac {x(n+2)}{n+1}\]
</p>

<p>
and the sandwich rule tells us that \(\lim _{n\to \infty }\P [M_n\leq x]=x\). By <span class="textup" >(<a
href="Long-term-behaviour-stochastic-processes.html#eq:urn_Mconvd">7.6</a>)</span>, this means that
</p>

<p>
\[\P [M_\infty \leq x]=x\quad \text { for all }x\in (0,1).\]
</p>

<p>
Therefore, \(M_\infty \) has a uniform distribution on \((0,1)\). This proves Proposition <a href="Long-term-behaviour-stochastic-processes.html#prop:urn_limit">7.4.3</a>.
&#x2003;&#x2003;&#x220E;
</p>
<h6 id="autosec-225">Extensions and applications of urn processes</h6>
<a id="notes_1-autopage-225"></a>



<p>
We could change the rules of our urn process, to create a new kind of urn â€“ for example whenever we draw a red ball we could add two new red balls, rather than just one. Urn processes are typically very â€˜sensitiveâ€™,
meaning that a small change in the process, or its initial conditions, can have a big effect on the long term behaviour. You can investigate some examples of this in exercises <a
href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#ps:urn_mean_revert"><b>7.7</b></a>, <a href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#ps:urn_moran"><b>7.8</b></a>
and <a href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#ps:urn_initial_conds"><b>7.9</b></a>.
</p>

<p>
Urn processes are often used in models in which the â€˜next stepâ€™ of the process depends on sampling from its current state. Recall that in random walks we have \(S_{n+1}=S_n+X_{n+1}\), where \(X_{n+1}\) is
independent of \(S_n\); so for random walks the next step of the process is independent of its current state. By contrast, in Po&#x0301;lyaâ€™s urn, whether the next ball we add is red (or black) depends on the
current state of the urn; it depends on which colour ball we draw.
</p>

<p>
For example, we might look at people choosing which restaurant they have dinner at. Consider two restaurants, say <i>Cafe&#x0301; Rouge</i> (which is red) and <i>Le Chat Noir</i> (which is black). We think
of customers in Cafe&#x0301; Rouge as red balls, and customers in Le Chat Noir as black balls. A newly arriving customer (i.e.&nbsp;a new ball that we add to the urn) choosing which restaurant to visit is more
likely, but not certain, to choose the restaurant which currently has the most customers.
</p>

<p>
Other examples include the growth of social networks (people tend to befriend people who already have many friends), machine learning (used in techniques for becoming successively more confident about partially
learned information), and maximal safe dosage estimation in clinical trials (complicated reasons). Exercise <a href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#ps:urn_moran"><b>7.8</b></a>
features an example of an urn process that is the basis for modern models of evolution (successful organisms tend to have more descendants, who are themselves more likely to inherit genes that will make them
successful).
</p>
<h5 id="autosec-226">Long term behaviour of Galton-Watson processes</h5>
<a id="notes_1-autopage-226"></a>



<a id="sec:gw_long_term"></a>

<p>
The martingale convergence theorem can tell us about the long term behaviour of stochastic processes. In this section we focus on the Galton-Watson process, which we introduced in Section <a
href="A-branching-process.html#sec:gw">4.3</a>.
</p>

<p>
Let us recall the notation from Section <a href="A-branching-process.html#sec:gw">4.3</a>. Let \(X^n_i\), where \(n,i\ge 1\), be i.i.d.&nbsp;nonnegative integer-valued random variables with common
distribution \(G\). Define a sequence \((Z_n)\) by \(Z_0=1\) and
</p>

<span class="hidden" > \(\seteqnumber{0}{7.}{7}\)</span>

<!--

                                                ï£±
                                                ï£² X n+1 + . . . + X n+1 ,   if \(Z_n&gt;0\)
                                                     1             Zn
                                       Zn+1   =                                                                                    (7.8)                                  --><a id="eq:gw_iterative_defn"></a><!--
                                                ï£³ 0,                        if \(Z_n=0\)


-->

<p>


\begin{equation}
\label {eq:gw_iterative_defn} Z_{n+1} = \left \{ \begin{array}{ll} X^{n+1}_1 + \ldots + X^{n+1}_{Z_n}, &amp; \mbox { if $Z_n&gt;0$} \\ 0, &amp; \mbox { if $Z_n=0$} \end {array}
\right .
\end{equation}


</p>

<p>
Then \((Z_n)\) is the Galton-Watson process. In Section <a href="A-branching-process.html#sec:gw">4.3</a> we showed that, writing \(\mu =\E [G]\),
</p>

<p>
\[M_n=\frac {Z_n}{\mu ^n}\]
</p>

<p>
was a martingale with mean \(\E [M_n]=1\).
</p>

<p>
We now look to describe the long term behaviour of the process \(Z_n\), meaning that we want to know how \(Z_n\) behaves as \(n\to \infty \). Weâ€™ll consider three cases: \(\mu &lt;1\), \(\mu =1\), and
\(\mu &gt;1\). Before we start, its important to note that, if \(Z_N=0\) for any \(N\in \N \), then \(Z_n=0\) for all \(n\geq N\). When this happens, it is said that the process <i>dies out</i>.
</p>

<p>
Weâ€™ll need the martingale convergence theorem. We have that \(M_n\) is a martingale, with expected value \(1\), and since \(M_n\geq 0\) we have \(\E [|M_n|]=1\). Hence, \((M_n)\) is bounded in \(L^1\) and
by the martingale convergence theorem (Theorem <a href="The-martingale-convergence-theorem.html#thm:mart_conv">7.3.4</a>) we have that the almost sure limit
</p>

<p>
\[\lim \limits _{n\to \infty }M_n=M_\infty \]
</p>

<p>
exists. Since \(M_n\geq 0\), we have \(M_\infty \in [0,\infty )\).
</p>

<p>
For the rest of this section, weâ€™ll assume that the offspring distribution \(G\) is not deterministic. Obviously, if \(G\) was deterministic and equal to say, \(c\), then we would simply have \(Z_n=c^n\) for all \(n\).
</p>
<div class="theorembodylemma" >

<ul style="list-style-type:none">



<a id="autoid-166"></a>

<li>

<p>
<span class="theoremheaderplain" >Lemma 7.4.6</span> <a id="autoid-167" ></a ><a id="lem:gw_crit"></a> Suppose that \(\mu =1\). Then \(\P [Z_n\text { dies out}]=1\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc" >Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> In this case \(M_n=Z_n\). So, we have \(Z_n\to M_\infty \) almost surely. The offspring
distribution is not deterministic, so for as long as \(Z_n\neq 0\) the value of \(Z_n\) will continue to change over time. Each such change in value is of magnitude at least \(1\), hence by Lemma <a
href="Long-term-behaviour-stochastic-processes.html#lem:Z_ev_const">7.4.1</a> the only way \(Z_n\) can converge is if \(Z_n\) is eventually zero. Therefore, since \(Z_n\) does converge, in this case we
must have \(\P [Z_n\text { dies out}]=1\) (and \(M_\infty =0\)). &#x2003;&#x2003;&#x220E;
</p>
<div class="theorembodylemma" >

<ul style="list-style-type:none">



<a id="autoid-168"></a>

<li>

<p>
<span class="theoremheaderplain" >Lemma 7.4.7</span> <a id="autoid-169" ></a ><a id="lem:gw_subcrit"></a> Suppose that \(\mu &lt;1\). Then \(\P [Z_n\text { dies out}]=1\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc" >Sketch of Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> Recall our graphical representation of the Galton-Watson process in Section <a
href="A-branching-process.html#sec:gw">4.3</a>. Hereâ€™s the key idea: when \(\mu &lt;1\), on average we expect each individual to have less children than when \(\mu =1\). Therefore, if the Galton-Watson
process dies out when \(\mu =1\) (as is the case, from Lemma <a href="Long-term-behaviour-stochastic-processes.html#lem:gw_crit">7.4.6</a>), it should also die out when \(\mu &lt;1\).
</p>

<p>
Our idea is not quite a proof, because the size of the Galton-Watson process \(Z_n\) is random, and not necessarily equal to its expected size \(\E [Z_n]=\mu ^n\). To make the idea into a proof we will need to
find two Galton-Watson processes, \(Z_n\) and \(\wt {Z}_n\), such that \(0\leq Z_n\leq \wt {Z}_n\), with \(\mu &lt;1\) in \(Z_n\) and \(\mu =1\) in \(\wt {Z}_n\). Then, when \(\wt {Z}_n\) becomes
extinct, so does \(Z_n\). This type of argument is known as a <i>coupling</i>, meaning that we use one stochastic process to control another. See exercise <a
href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#ps:gw_subcrit"><b>7.13</b></a> for how to do it. &#x2003;&#x2003;&#x220E;
</p>
<div class="theorembodylemma" >

<ul style="list-style-type:none">



<a id="autoid-170"></a>

<li>

<p>
<span class="theoremheaderplain" >Lemma 7.4.8</span> <a id="autoid-171" ></a ><a id="lem:gw_supercrit"></a> Suppose that \(\mu &gt;1\) and \(\sigma ^2&lt;\infty \). Then \(\P [Z_n\to
\infty ]&gt;0\).
</p>


</li>

</ul>

</div>

<p>
<span class="textsc" >Proof:</span><span style="width:5.38533pt; display:inline-block"><!----></span> The first step of the argument is to show that, for all \(n\in \N \),
</p>

<span class="hidden" > \(\seteqnumber{0}{7.}{8}\)</span>

<!--


                                                       2                    Ïƒ2
                                                    E[Mn+1 ] = E[Mn2 ] +        .                                                 (7.9)                                --><a id="eq:gw_2nd_iterate"></a><!--
                                                                           Âµn+2


-->

<p>


\begin{equation}
\label {eq:gw_2nd_iterate} \E [M_{n+1}^2]=\E [M_n^2]+\frac {\sigma ^2}{\mu ^{n+2}}.
\end{equation}


</p>

<p>
You can find this calculation as exercise <a href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#ps:gw_var"><b>7.11</b></a>. It is similar to the calculation that we did to find \(\E [M_n]\) in
Section <a href="A-branching-process.html#sec:gw">4.3</a>, but a bit harder because of the square.
</p>

<p>
By iterating <span class="textup" >(<a href="Long-term-behaviour-stochastic-processes.html#eq:gw_2nd_iterate">7.9</a>)</span> and noting that \(\E [M_0]=1\), we obtain that
</p>

<p>
\[\E [M_{n+1}^2]=1+\sum _{i=1}^n\frac {\sigma ^2}{\mu ^{i+2}}.\]
</p>

<p>
Hence,
</p>

<p>
\[\E [M_{n+1}^2]\leq 1+\frac {\sigma ^2}{\mu ^2}\sum _{i=1}^\infty \frac {1}{\mu ^i},\]
</p>

<p>
which is finite because \(\mu &gt;1\). Therefore, \((M_n)\) is bounded in \(L^2\), and the second martingale convergence theorem applies. In particular, this gives us that
</p>

<p>
\[\E [M_n]\to \E [M_\infty ].\]
</p>

<p>
Noting that \(\E [M_n]=1\) for all \(n\), we obtain that \(\E [M_\infty ]=1\). Hence, \(\P [M_\infty &gt;0]&gt;0\). On the event that \(M_\infty &gt;0\), we have \(M_n=\frac {Z_n}{\mu ^n}\to
M_\infty &gt;0\). Since \(\mu ^n\to \infty \), this means that when \(M_\infty &gt;0\) we must also have \(Z_n\to \infty \). Hence, \(\P [Z_n\to \infty ]&gt;0\). &#x2003;&#x2003;&#x220E;
</p>

<p>
The behaviour \(Z_n\to \infty \) is often called â€˜explosionâ€™, reflecting the fact that (when it happens) each generation tends to contain more and more individuals than the previous one. The case of \(\mu
&gt;1\) and \(\sigma ^2=\infty \) behaves in the same way as Lemma <a href="Long-term-behaviour-stochastic-processes.html#lem:gw_supercrit">7.4.8</a>, but the proof is more difficult and we
donâ€™t study it in this course.
</p>
<h6 id="autosec-230">Extensions and applications of the Galton-Watson process</h6>
<a id="notes_1-autopage-230"></a>



<p>
The Galton-Watson process can be extended in many ways. For example, we might vary the offspring distribution used in each generation, or add a mechanism that allows individuals to produce their children
gradually across multiple time steps. The general term for such processes is â€˜branching processesâ€™. Most branching processes display the same type of long-term behaviour as we have uncovered in this section: if the
offspring production is too low (on average) then they are sure to die out, but, if the offspring production is high enough that dying out is not a certainty then (instead) there is a chance of explosion to \(\infty \).
</p>

<p>
Branching processes are the basis of stochastic models in which existing objects reproduce, or break up, into several new objects. Examples are the spread of contagious disease, crushing rocks, nuclear fission,
tumour growth, and so on. In Chapter <a href="Financial-networks.html#chap:fin_net">17</a> (which is part of MAS452/6052 only) we will use branching processes to model contagion of unpaid debts in
banking networks.
</p>

<p>
Branching processes are used by biologists to model population growth, and they are good models for populations that are rapidly increasing in size. (For populations that have reached a roughly constant size,
models based on urn processes, such as that of exercise <a href="Exercises-on-Chapter-ref-chap-stoch_procs_1.html#ps:urn_moran"><b>7.8</b></a>, are more effective.)
</p>
<h5 id="autosec-231">Long term behaviour of random walks \((\star )\)</h5>
<a id="notes_1-autopage-231"></a>



<a id="sec:rw_long_term"></a>

<p>
We now consider the long term behaviour of random walks. This section is marked with a \((\star )\) and is off syllabus, because we wonâ€™t prove any of it. However, it will be covered in lectures, since it does
contain interesting information that provides intuition for (on-syllabus) results in future chapters.
</p>

<p>
Firstly, take \(S_n\) to be the simple symmetric random walk. It turns out that \(S_n\) will oscillate as \(n\to \infty \), and that the magnitude of the largest oscillations will tend to infinity as \(n\to \infty
\) (almost surely). So, our picture of the long-term behaviour of the symmetric random walk looks like:
</p>
<div class="center" >

<p>


<a href="long_term_ssrw.jpg" target="_blank" ><img
      src="long_term_ssrw.jpg"
      style="
      width:304pt;
      "
      class="inlineimage"
      alt="(A symmetric random walk oscillating over a long time)"
></a>
</p>
</div>

<p>
Note that we draw the picture as continuous line, for convenience, but in fact the random walk is jumping between integer values.
</p>

<p>
Next, let \(S_n\) be the asymmetric random walk, with \(p&gt;q\), so the walk drifts upwards. The asymmetric random walk also experiences oscillations growing larger and larger, but the drift upwards is strong
enough that, in fact \(S_n\stackrel {a.s.}{\to }\infty \) as \(n\to \infty \). So, our picture of the long-term behaviour of the asymmetric random walk looks like:
</p>
<div class="center" >

<p>


<a href="long_term_asrw.jpg" target="_blank" ><img
      src="long_term_asrw.jpg"
      style="
      width:304pt;
      "
      class="inlineimage"
      alt="(An asymmetric random walk drifting upwards over a long time)"
></a>
</p>
</div>

<p>
Of course, if \(q&lt;p\) then \(S_n\) would drift downwards, and then \(S_n\stackrel {a.s.}{\to }-\infty \)
</p>

<p>
In both cases, it is possible to show that \(S_n\) is not bounded in \(L^1\) (even if we compensate for drift) and the martingale convergence theorem does not apply. Different techniques, which we wonâ€™t study, are
needed here.
</p>
<h6 id="autosec-234">Extensions and applications of random walks</h6>
<a id="notes_1-autopage-234"></a>



<p>
Random walks can be extended in many ways, such as by adding an environment that influences the behaviour of the walk (e.g.&nbsp;reflection upwards from the origin as in exercise <a
href="Exercises-on-Chapter-ref-chap-stoch_procs.html#ps:rw_local_time_mart"><b>4.4</b></a>, slower movements when above \(0\), etc), or by having random walkers that walk around a graph (\(\Z
\), in our case above). More complex extensions involve random walks that are influenced by their own history, for example by having a preference to move into sites that they have not yet visited. In addition, many
physical systems can be modelled by systems of several random walks, that interact with each other, for example a setup with multiple random walks happening at the same time (but started from different points in
space) in which, whenever random walkers meet, both of them suddenly vanish.
</p>

<p>
Random walks are the basis of essentially all stochastic modelling that involves particles moving around randomly in space. For example, atoms in gases and liquids, animal movement, heat diffusion, conduction of
electricity, transportation networks, internet traffic, and so on.
</p>

<p>
In Chapters <a href="The-Black-Scholes-model.html#chap:bs">14</a> and <a href="Application-extension-Black-Scholes-model.html#chap:bs_extensions">15</a> we will use stock price models
that are based on â€˜Brownian motionâ€™, which is itself introduced in Chapter <a href="Brownian-motion.html#chap:bm">10</a> and is the continuous analogue of the symmetric random walk (i.e.&nbsp;no
discontinuities). Weâ€™ll come back to the idea of atoms in gases and liquids in Section <a href="Brownian-motion.html#sec:bm_limit">10.1</a>, and weâ€™ll also briefly look at heat diffusion in Section <a
href="Brownian-motion-heat-equation.html#sec:heat">10.3</a>.
</p>

</section>

</div>

</div>

<footer>

<p>
Copyright Nic Freeman, Sheffield University, last updated January 5, 2022
</p>

</footer>



<nav class="botnavigation" ><a href="notes_1.html" class="linkhome" >
Home</a></nav>

</body>
</html>
